{"meta":{"title":"TangShusen","subtitle":null,"description":null,"author":"TangShusen","url":"https://tangshusen.me"},"pages":[{"title":"分类","date":"2018-10-27T16:30:26.000Z","updated":"2018-11-11T14:43:48.261Z","comments":true,"path":"categories/index.html","permalink":"https://tangshusen.me/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-27T16:34:16.000Z","updated":"2018-11-10T16:18:46.450Z","comments":true,"path":"tags/index.html","permalink":"https://tangshusen.me/tags/index.html","excerpt":"","text":""},{"title":"About me","date":"2018-11-11T14:41:04.000Z","updated":"2019-01-06T10:00:39.760Z","comments":true,"path":"about/index.html","permalink":"https://tangshusen.me/about/index.html","excerpt":"","text":"计算机研一小硕一枚Email: tangshusen96@gmail.com"}],"posts":[{"title":"统计学习理论之VC维究竟是什么","slug":"vc-dimension","date":"2018-12-09T04:23:52.000Z","updated":"2018-12-30T09:16:22.473Z","comments":true,"path":"2018/12/09/vc-dimension/","link":"","permalink":"https://tangshusen.me/2018/12/09/vc-dimension/","excerpt":"学习机器学习不可避免的会接触到VC维，它在机器学习领域是一个很基础但很重要的概念，它给机器学习提供了坚实的理论基础。但直到在我写这篇博客之前，我对VC的理解还只停留在它能刻画假设空间的复杂度这样浅显的层次。本文就来理一理VC维(Vapnik–Chervonenkis dimension)的来龙去脉，搞清楚其本质。","text":"学习机器学习不可避免的会接触到VC维，它在机器学习领域是一个很基础但很重要的概念，它给机器学习提供了坚实的理论基础。但直到在我写这篇博客之前，我对VC的理解还只停留在它能刻画假设空间的复杂度这样浅显的层次。本文就来理一理VC维(Vapnik–Chervonenkis dimension)的来龙去脉，搞清楚其本质。 1. 可学习的条件既然说VC维给机器学习提供了坚实的理论基础，那么就有必要来看看机器学习算法可学习的条件是什么。 1.1 学习的过程一个基本的机器学习过程如图1.1所示(本文图片若无特别说明即来自于台大机器学习基石课程课件，Coursera课程地址)。解释一下下图中的一些概念：$\\mathcal{A}$ 表示学习算法，$f$ 表示学习的目标假设(可以是一个函数，也可以是一个分布)，$\\mathcal{H}$ 表示假设空间，$g$ 表示我们求解的用来预测的假设，$g$ 是属于 $\\mathcal{H}$ 的。机器学习的过程就是：通过算法 $\\mathcal{A}$，在假设空间 $\\mathcal{H}$ 中，根据训练样本集 $\\mathcal{D}$，选择最好的假设作为 $g$ 使 $g$ 近似于 $f$。 图1.1 图1.1中的 $E_{out}(g)$ 和 $E_{in}(g)$ 是两个重要的概念： $E_{out}(g)$，学到的假设 $g$ 在除了训练样本外的其他所有样本(out-of-sample)上的损失，称为期望误差，也称泛化误差。 $E_{in}(g)$，学到的假设 $g$ 在训练样本(in-of-sample)上的损失，称为经验误差。 我们的目标是选择最好的假设作为 $g$ 使 $g$ 近似于 $f$，而 $E_{out}(f) = 0$，也即我们的目标是使 $E_{out}(g) \\approx 0$。但我们是没法获得训练样本外的其他所有样本的，那也就没法计算 $E_{out}(g)$ 了，这该怎么办呢？ 1.2 Hoeffding不等式在回答1.1最后的问题之前，先来看看Hoeffding不等式。来看图1.2所述的问题: 设瓶子里的橙色球占比为 $\\mu$，从瓶子中随机抽取出N个样本，这N个样本中橙色球占比是 $\\nu$。我们可以将 $\\mu$ 看作1.1节中的$E_{out}(g)$，将 $\\nu$ 看作是 $E_{in}(g)$，我们现在并不知道 $\\mu$ 和 $E_{out}(g)$，只知道 $\\nu$ 和 $E_{in}(g)$，我们可以从 $\\nu$ 推断出关于 $\\mu$ 的什么吗？ 可以将 $\\nu$ 看作是样本期望，$\\mu$ 则是总体期望。 图1.2 直觉上，如果我们有更多的样本(抽出很多的球)，则 $\\nu$ 应该越来越接近总体期望 $\\mu$。事实上，这里可以用hoeffding不等式表示如下：$$\\mathbb{P}[|\\nu - \\mu| &gt; \\epsilon] \\leq 2 \\exp \\left(-2 \\epsilon^2 N \\right) \\tag{1.2.1}$$ 从hoeffding不等式可以看出，当N越来越大时，$\\nu$ 和 $\\mu$ 之差大于 $\\epsilon$ 的概率的上界越来越接近0，所以样本期望 $\\nu$ 越来越接近总体期望 $\\mu$，即 $\\nu$ 和 $\\mu$ 概率近似相等(probably approximately correct, PAC)了。 1.3 可学习的条件有了1.2节的铺垫，我们就可以来回答1.1节的问题了。 对于任意固定的假设 $h$，当训练样本量N足够大，类比于1.2节的例子，可以通过样本集上的经验误差 $E_{in}(h)$ 推测总体的期望误差 $E_{out}(h)$。基于hoeffding不等式，我们得到下面式子：$$\\mathbb{P}[|E_{in}(h) - E_{out}(h)| &gt; \\epsilon] \\leq 2 \\exp(-2 \\epsilon^2 N) \\tag{1.3.1}$$ 根据上面不等式，我们可以推断，当N足够大时，$E_{in}(h)$ 和 $E_{out}(h)$ 将非常接近。 注意在上面推导中，我们是针对某一个特定的假设 $h$。在我们的假设空间 $\\mathcal{H}$ 中，往往有很多个假设(甚至于无穷多个)。那么对于假设空间 $\\mathcal{H}$ 中的任意的假设 $h$，$E_{in}(h)$ 和 $E_{out}(h)$ 之差大于 $\\epsilon$ 的概率的上界会是什么呢？ 发生概率很小的事件在很多次实验中发生概率就会变得很大。例如连续丢5次硬币，事件”五次都是正面朝上”的概率是 $\\frac 1 {32}$。但是如果100个人做这个实验，事件”五次都是正面朝上”的发生的概率就是 $1 - ({\\frac {31} {32}})^{100} &gt; 0.95$。所以对于特定的假设 $h$，$E_{in}(h)$ 和 $E_{out}(h)$ 很接近，但是对于 $\\mathcal{H}$ 中任意的假设这就不一定了。 这里假定 $\\mathcal{H}$ 中有 $M$ 个假设 $h_1,h_2,…h_M$，则有如下推导:$$\\mathbb{P}[\\mathbf{E}(h_1)&gt; \\epsilon \\cup \\mathbf{E}(h_2)&gt; \\epsilon \\space … \\cup \\mathbf{E}(h_M)&gt; \\epsilon] \\\\\\leq \\mathbb{P}[\\mathbf{E}(h_1)&gt; \\epsilon] + \\mathbb{P}[\\mathbf{E}(h_2)&gt; \\epsilon] \\space … + \\mathbb{P}[\\mathbf{E}(h_M)&gt; \\epsilon] \\\\\\leq 2M\\exp(-2 \\epsilon^2 N) \\tag{1.3.2}$$其中 $\\mathbf{E}(h_i) = |E_{in}(h_i) - E_{out}(h_i)|$。 根据式 $(1.3.2)$ 知$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 2M \\exp(-2 \\epsilon^2 N) \\tag{1.3.3}$$ 上面式子的含义就是：在假设空间 $\\mathcal{H}$ 中，对于任意一个假设 $g$，$E_{in}(g)$ 和 $E_{out}(g)$ 之差大于 $\\epsilon$ 的概率的上界是 $2M \\exp(−2 \\epsilon^2 N)$。注意这个上界与训练样本数 $N$ 和假设空间假设数 $M$ 密切相关。 本文的所有讨论都是围绕式(1.3.3)进行的!!! 所以，根据式 $(1.3.3)$，我们就知道了可学习的两个核心条件是: 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。再结合条件2即达到了 $E_{out}(g) \\approx 0$ 的目标。 假设空间 $\\mathcal{H}$ 中假设数 $M$ 是有限的且训练样本数 $N$ 足够大。此时可保证式(1.3.3)右边上界趋于0，即学习算法 $\\mathcal{A}$ 从 $\\mathcal{H}$ 选出的任意假设 $g$ 都满足 $E_{in}(g) \\approx E_{out}(g)$。 上面这两个核心条件，也正好对应着train和test这两个过程: train过程希望经验误差$E_{in}(g)$ 尽可能小； test过程希望在真实环境中的期望误差$E_{out}(g)$也尽可能小，即$E_{out}(g)$接近于$E_{in}(g)$。 所以我们不应该只关心如何利用学习算法找到使 $E_{in}(g)$ 很小的 $g$。因为如果想让学习可行，也要保证$E_{out}(g)$接近于$E_{in}(g)$。 来分析一下 $M$ 的大小对于两个条件的满足情况： 当 $M$ 较小时，由式$(1.3.3)$知条件2很容易满足，但是由于可选的 $g$ 的数目 $M$ 较小，所以条件1不容易满足； 当 $M$ 较大时，由于可选的 $g$ 的数目 $M$ 较大，所以条件1很容易满足，但是条件2不容易满足。 由此可见，假设数 $M$ 在这两个核心条件中有着重要作用，应该合理选取。但是往往一个假设空间(如二维平面的所有直线)的假设数是很大的甚至是无穷的，此时式$(1.3.3)$中的上界就成了无穷大没有任何约束意义，也即不满足条件2，学习变得不可行，这该怎么办呢？ 2. VC维2.1 有效假设数在式$(1.3.2)$的推导中，我们用到了这样一个概率不等式:$$\\mathbb{P}(A_1 \\cup A_2 \\space … \\cup A_M) \\leq \\sum_{i=1}^M\\mathbb{P}(A_i) \\tag{2.1.1}$$我们知道，当 $A_i$ 相互独立时上式取等号。但事实上，假设空间里的 $h_i$ 之间并不是完全独立的，它们是有很大的重叠的，也就是在 $M$ 个假设中，有很多假设都可以归为同一类。 下面用二维假设空间为例解释一下上述重叠性。我们知道二维假设空间的所有假设数(即直线条数)为 $\\infty$，但是如图2.1所示，可以将这些假设分为两类，一类是把x1判断为正例，另一类是把x1判断为负例。 图2.1 那如果在平面上有两个不同的数据点x1,x2，这样的话，假设空间 $\\mathcal{H}$ 中的无数条直线可以分为4类。那依次类推，3个数据点情况下，$\\mathcal{H}$ 中最多有8类(当三个点在同一直线上时只有6类)。4个数据点时，$\\mathcal{H}$ 中最多有14类(注意不是16类)，如下图所示。 图2.2 从上面的分析可知，虽然假设空间假设数 $M$ 一般非常大(甚至无穷)，但在特定的样本集上，有效的假设数目是有限的，也即式$(1.3.3)$中的 $M$ 是有限的，所以可以重写式$(1.3.3)$如下:$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 2\\cdot \\text{effective}(M) \\exp(-2 \\epsilon^2 N) \\tag{2.1.2}$$ 2.2 对分和增长函数为了探究式$(2.1.2)$中的 $\\text{effective}(M)$ ，先引入对分(dichotomy) 的概念: 对于假设空间 $\\mathcal{H} = \\lbrace h: \\mathcal{X} \\to \\lbrace+1,-1\\rbrace \\rbrace$，我们称$$h(X_1, X_2,…,X_N) = (h(X_1), h(X_2),…,h(X_n)) \\in \\lbrace+1,-1 \\rbrace ^N$$为一个对分，即一个对分表示样本的一种标记结果，$\\mathcal{H}(X_1, X_2,…,X_N)$ 表示假设空间 $\\mathcal{H}$ 在训练集 $\\mathcal{D}$ 上的所有对分。 例如，若 $N = 4$且数据为二维时，参见图2.2，有如下表格: 假设空间 $\\mathcal{H}$ $\\mathcal{H}(X_1, X_2,X_3,X_4)$ 所有元素 平面上的所有直线 {+1,+1,+1,+1}, {+1,+1,+1,-1}… 元素个数 $\\infty$ 最大为14 (不会超过 $2^N$) 我们知道， $\\mathcal{H}(X_1, X_2,…,X_N)$ 的元素个数(即 $|\\mathcal{H}(X_1, X_2,…,X_N)|$ )是取决于具体的数据集 $\\mathcal{D}$ 的，例如当 $N=3$ 时且三个点不在一条直线时对分数为8，而在一条直线时对分数是6。为了去掉对具体 $\\mathcal{D}$ 的依赖性，我们引入 增长函数(growth function): 假设空间 $\\mathcal{H}$ 的增长函数 $m_{\\mathcal{H}}(N)$ 为$$m_{\\mathcal{H}}(N) = \\underset{X_1,X2,…,X_N \\in \\mathcal{X}}{max} |\\mathcal{H}(X_1, X_2,…,X_N)|$$增长函数 $m_{\\mathcal{H}}(N)$ 表示假设空间 $\\mathcal{H}$ 对个任意 $N$ 个样本所能赋予标记的的最大可能结果数，其上界为 $2^N$ 。 显然，$m_{\\mathcal{H}}(N)$ 越大，$\\mathcal{H}$ 的表示能力越强。因此，增长函数描述了假设空间 $\\mathcal{H}$ 的表示能力，由此反映出假设空间的复杂度。既然如此，那我们可不可以用 $m_{\\mathcal{H}}(N)$ 直接替换掉式$(2.1.2)$ 中的 $\\text{effective}(M)$ 呢，即$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\overset{?}{\\leq} 2 m_{\\mathcal{H}}(N) \\exp(-2 \\epsilon^2 N) \\tag{2.2.1}$$我们将在在2.3节回答这个问题。 2.3 VC界2.3.1 打散(shatter)在介绍VC维界(VC bound)之前，先引入打散(shatter)的概念, 当假设空间 $\\mathcal{H}$ 作用于大小为 $N$ 的样本集 $\\mathcal{D}$ 时，产生的对分数量等于 $2^N$ 即 $m_{\\mathcal{H}}(N)=2^N$ 时，就称 $\\mathcal{D}$ 被 $\\mathcal{H}$ 打散了。 shatter的原意是打碎，在此指 $N$ 个点的所有(碎片般的)可能情形都被 $\\mathcal{H}$ 产生了。 图2.3 如上图所示，二维空间上的的三个点(不在一条直线上)可以被平面上所有直线这个假设空间打碎,此时 $m_{\\mathcal{H}}(3)= 8 = 2^3$。但如下图所示的四个点就不能被这个假设空间打碎了，可知此时 $m_{\\mathcal{H}}(4)=14 \\neq 2^4$。 图2.4 2.3.2 break point尽管增长函数把假设数从无穷缩小到 $2^N$，但是这个量级还是太大了，很难保证式$(1.3.3)$右边这个上界趋于0，所以能不能把量级再缩小一点? 为了回答这个问题，先给出break point的定义: 对于假设空间 $\\mathcal{H}$ 的增长函数 $m_{\\mathcal{H}}(N)$ ，从 $N=1$ 出发逐渐增大，当增大到 $k$ 时，出现 $m_{\\mathcal{H}}(N) &lt; 2^N$ 的情形，则我们说 $k$ 是该假设空间的break point。换句话说，对于任何大小为 $N(N \\ge k)$ 的数据集， $\\mathcal{H}$ 都没有办法打碎它。 举例来讲，由2.3.1节知，当假设空间 $\\mathcal{H}$ 定义为平面上所有直线时，其break point就为4。 有了break point的概念，再经过一系列归纳证明(详见台大机器学习课程lecture6)，我们有这样一个结论: 设break point存在且为 $k$ 的假设空间的增长函数上界为 $B(N,k)$，则 $B(N,k)$ 满足$$m_{\\mathcal{H}}(N) \\le B(N,k) \\le \\sum_{i=0}^{k-1}{N \\choose i} \\le N^{k-1}$$注: 上式的证明可见这个知乎回答，另外最后一个不等号仅在 $N \\ge 2$ 且 $k \\ge 2$ 时成立。即break point存在时增长函数上界是一个多项式，多项式的最高幂次项为 $N^{k–1}$。 所以我们得到结论：如果break point存在，则增长函数 $m_{\\mathcal{H}}(N)$ 是多项式的。多项式的量级就比 $2^N$ 小多了，这就很容易保证式$(1.3.3)$右边这个上界很小，学习就可行了! 2.3.3 VC界上一小节提到如果break point存在，学习是可行的。既然如此，我们来回答一下2.2节最后提出的问题: 可不可以用 $m_{\\mathcal{H}}(N)$ 直接替换掉式$(2.1.2)$ 中的 $\\text{effective}(M)$ 呢，即式$(2.2.1)$是否成立。 答案是不能直接替换,正确的不等式是$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 4 m_{\\mathcal{H}}(2N) \\exp(-\\frac18 \\epsilon^2 N) \\tag{2.3.1}$$ 上式其实和式 $(2.2.1)$ 差不多，其证明略显复杂我们暂不去探究，可参考此处。 式$(2.3.1)$就是VC界，这个公式的意义在于：如果假设空间 $\\mathcal{H}$ 存在有限的break point $k$，即 $m_{\\mathcal{H}}(2N)$ 会被最高幂次为 $k–1$ 的多项式上界给约束住，那么，随着 $N$ 的逐渐增大，指数式 $exp(\\cdot)$ 的下降会比多项式 $m_{\\mathcal{H}}(2N)$ 的增长速度更快，所以此时可以推断出VC界是有界的。更进一步，当 $N$ 足够大时，对于 $\\mathcal{H}$ 中的任意一个假设 $g$ ，$E_{in}(g)$ 都将接近于 $E_{out}(g)$，即学习是可行的。 2.4 VC维现在，我们终于可以定义VC维了: 假设空间 $\\mathcal{H}$ 的VC维是能被 $\\mathcal{H}$ 打散的最大数据集的大小，即$$VC(\\mathcal{H}) = max \\lbrace N: m_{\\mathcal{H}}(N) = 2^N\\rbrace$$根据此定义，有 $VC(\\mathcal{H}) = k-1$，其中 $k$ 是 $\\mathcal{H}$ 的break point。 $VC(\\mathcal{H}) = d$ 表明存在大小为 $d$ 的数据集能被假设空间 $\\mathcal{H}$ 打散，需要注意的是这并不意味着所有大小为 $d$ 的数据集都能被 $\\mathcal{H}$ 打散，例如二维平面上的所有直线构成的假设空间 $\\mathcal{H}$ 的VC维为3，但是它并不能打散位于同一条直线上的三个点。事实上，VC维的定义与数据具体分布是无关的。 因为 $VC(\\mathcal{H}) = k-1$，所以由2.3.2节可知当 $N \\ge 2$ 且 $k \\ge 2$ 时，有$$m_{\\mathcal{H}}(N) \\le N^{VC(\\mathcal{H})} \\tag{2.4.1}$$ 将上式代入$(2.3.1)$的右边VC界有$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 4 (2N)^{VC(\\mathcal{H})} \\exp(-\\frac18 \\epsilon^2 N) \\tag{2.4.2}$$ 所以，1.3节的可学习的两个核心条件等价于: 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。再结合条件2即达到了 $E_{out}(g) \\approx 0$ 的目标。 假设空间 $\\mathcal{H}$ 的VC维 $VC(\\mathcal{H})$ 是有限的且训练样本数 $N$ 足够大。此时可保证式(2.4.2)右边上界趋于0，即学习算法 $\\mathcal{A}$ 从 $\\mathcal{H}$ 选出的任意假设 $g$ 都满足 $E_{in}(g) \\approx E_{out}(g)$。 VC维反映了函数集的学习能力，VC维越大，能学到的模型越复杂。根据前面的推导，我们知道VC维的大小与学习算法无关，与数据集的具体分布无关，与我们求解的目标函数也无关，只与模型和假设空间有关。另外，实践中有这样一个规律：一般情况下，假设空间的VC维约等于假设自由变量的数目。 2.5 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系令式$(2.4.2)$右边的 $4 (2N)^{VC(\\mathcal{H})} \\exp(-\\frac18 \\epsilon^2 N) = \\delta$，即坏事发生的概率$$\\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq \\delta \\tag{2.5.1}$$则可反解出$$\\epsilon = \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\tag{2.5.2}$$由(2.5.1)可得出，有 $1-\\delta$ 的概率好事情会发生，好事情即$$E_{in}(g) - \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\le E_{out}(g) \\le E_{in}(g) + \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\tag{2.5.3}$$上式就是 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系。其中，根号部分也可以看做模型的复杂度 $\\Omega$，模型越复杂，$E_{in}(g)$ 与 $E_{out}(g)$ 离得越远。如图2.5所示，当固定样本数 $N$ 时，随着VC维的上升，$E_{in}(g)$ 会不断降低，而复杂度 $\\Omega$ 会不断上升，其上升与下降的速度在每个阶段都有所不同，因此我们要寻找一个二者兼顾的比较合适的VC维使 $E_{out}(g)$ 最小。 图2.5 此外，由上面的分析易知，样本数 $N$ 也会影响 $E_{out}(g)$。例如，当前有一个 $VC(\\mathcal{H})=3$ 的假设空间，要使 $\\epsilon=0.1$ 且 $\\delta=0.1$，则要想满足式$(2.5.2)$，可计算出理论上样本数 $N$ 需要达到 $10000VC(\\mathcal{H})$ 这个量级，但实际应用中我们发现 $N$ 达到 $10VC(\\mathcal{H})$ 就够了。这是因为，VC界是一个及其宽松的上界，因为它需要对任何学习算法，对任何数据分布，对任何目标函数都要成立,所以实际应用中的上界要比VC界小很多。 3. 总结总结一下本文的行文思路， 先用Hoeffding不等式说明了可学习的两个条件: (1) 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。 (2) 假设空间 $\\mathcal{H}$ 中假设数 $M$ 是有限的且训练样本数 $N$ 足够大。 但假设空间 $\\mathcal{H}$ 中假设数 $M$ 往往是无穷大的。幸运的是，在推导出条件(2)时，我们要求假设空间的所有假设都是独立的，而假设空间 $\\mathcal{H}$ 中独立假设数 $\\text{effective}(M)$ 却是有限的，增长函数告诉我们 $\\text{effective}(M)$ 的上界为 $2^N$ 。 $2^N$ 这个上界还是太大了，学习还是很难可行。所以我们又引入了break point的概念，使 $2^N$ 的量级降为 $N^{k-1}$, 由此得到了VC界。 然后我们给出了VC维的定义，可学习的两个条件转变为: (1) 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。 (2) 假设空间 $\\mathcal{H}$ 的VC维 $VC(\\mathcal{H})$ 是有限的且训练样本数 $N$ 足够大。 最后我们讨论了 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系，发现为了使学习器更好($E_{out}(g)$更小)，要选择合适的VC维，不能太大也不能太小。 因笔者自身水平实在有限，如果文章有任何的不妥，还请读者告之。此外，VC维可以说是机器学习中的一大核心，并非一篇博客就可以讲解透彻，所以本文也省略了一些复杂的证明，如果想深入理解可以去查阅相关书籍或论文。 参考 周志华《机器学习》第12章.计算学习理论 台大机器学习基石课程 ECE 901 Lecture 19: The Proof of the Vapnik-Chervonenkis (VC) Inequality Computational Learning Theory - VC Dimension [陆勤学习]解读机器学习基础概念：VC维的来龙去脉","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"VC维","slug":"VC维","permalink":"https://tangshusen.me/tags/VC维/"}]},{"title":"实际应用中关于size_t的一个容易忽略的坑","slug":"size-t","date":"2018-12-08T13:42:13.000Z","updated":"2018-12-30T09:15:20.196Z","comments":true,"path":"2018/12/08/size-t/","link":"","permalink":"https://tangshusen.me/2018/12/08/size-t/","excerpt":"今天在LeetCode上做3Sum的时候，遇到了一个一开始令我百思不得其解的bug，最后发现还是自己太菜了😭，在此记录一下以加深印象。","text":"今天在LeetCode上做3Sum的时候，遇到了一个一开始令我百思不得其解的bug，最后发现还是自己太菜了😭，在此记录一下以加深印象。 起因如下图所示，下面这段代码是过不了输入为空的测试样例的。 但是如果我加上一个”多余的”提前判断的语句就能过，如下图所示。 为什么看似等价的代码一个能过一个不能过呢？ 分析考虑这样一段代码:123456789101112131415#include &lt;iostream&gt;#include &lt;typeinfo&gt;#include&lt;vector&gt;using namespace std;int main()&#123; vector&lt;int&gt;ar; cout &lt;&lt; \"数组ar的size是\" &lt;&lt; ar.size()&lt;&lt; endl; for(int i = 0; i &lt; ar.size() - 1; i++)&#123; cout &lt;&lt; \"进入了for循环！\" &lt;&lt; endl; break; &#125; cout &lt;&lt; \"ar.size() - 1: \" &lt;&lt; ar.size() - 1 &lt;&lt; endl; return 0;&#125; 运行结果是:123数组ar的size是0进入了for循环！ar.size() - 1: 18446744073709551615 其中 $18446744073709551615 = 2^{64} - 1$。仿佛知道问题大概出在哪儿了。 结论这才突然想起C++ primer讲过，size()返回的是一个类型为size_t的量，那什么是size_t型呢？来看标准库的定义: size_tUnsigned integral typeAlias of one of the fundamental unsigned integer types. 原来size_t是无符号型的，但是为什么 ar.size() - 1 没有自动转换为带符号型的呢？ C++ primer第五版中文版P35还讲过： 提示：切勿混用带符号类型和无符号类型如果表达式里既有带符号类型又有无符号类型，当带符号类型取值为负时会出现异常结果，这是因为带符号数会自动转换为无符号数。 原来在同时存在无符号型数和有符号型数的表达式中，带符号型数是会自动转换为无符号型的! 所以，当无符号的ar.size()减去1时，结果自然不是-1而是 $2^{n} - 1$，$n$ 表示size_t型的位数。 值得提一点的是，size_t的位数并不一定等于unsigned的位数的: size_t和unsigned int有所不同,size_t的取值range是目标平台下最大可能的数组尺寸。一些平台下size_t的范围小于int的正数范围,又或者大于unsigned int.最典型的,在x64下,int还是4B,但size_t是8B.这意味着你在x64下最大可能开辟的数组尺寸是2^64.作者：KE meng链接：https://www.zhihu.com/question/24773728/answer/28920149来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 总结以后一定要注意，size()是返回的无符号型的数！所以对于第一个图中代码，for循环内部是会执行的，结果自然不对了(越界)。以后要用到数组的size时，还是先定义int len = ar.size()，这样不仅不会反犯这次这个错误，还能方便多次使用。","categories":[{"name":"C++","slug":"C","permalink":"https://tangshusen.me/categories/C/"}],"tags":[{"name":"语法","slug":"语法","permalink":"https://tangshusen.me/tags/语法/"},{"name":"坑","slug":"坑","permalink":"https://tangshusen.me/tags/坑/"}]},{"title":"Quick, Draw! Doodle Recognition Challenge 总结","slug":"kaggle-doodle-reco","date":"2018-12-05T13:58:29.000Z","updated":"2019-01-04T12:28:03.949Z","comments":true,"path":"2018/12/05/kaggle-doodle-reco/","link":"","permalink":"https://tangshusen.me/2018/12/05/kaggle-doodle-reco/","excerpt":"这个比赛于12.05早上结束，最终结果是排在69/1316、铜牌，离银牌区差4名，还是比较遗憾的。不过这是我第一次花大量时间和精力在图像分类问题上，作为一个小菜鸡能拿到牌还算满意。现在作个总结。另外本次比赛我的所有代码（带注释）已经开源(戳我)，有兴趣的可以看看，顺便给个star。","text":"这个比赛于12.05早上结束，最终结果是排在69/1316、铜牌，离银牌区差4名，还是比较遗憾的。不过这是我第一次花大量时间和精力在图像分类问题上，作为一个小菜鸡能拿到牌还算满意。现在作个总结。另外本次比赛我的所有代码（带注释）已经开源(戳我)，有兴趣的可以看看，顺便给个star。 这篇博客主要记录我在这次比赛过程中学到的一些东西，由于是第一次花精力认真做图像类的比赛所以学到的东西还是很多的。此外还会总结一下排在前列的大佬们在讨论区分享的他们的方案，留作日后参考。 1. 赛题简述1.1 数据集还记得前段时间很火的微信小程序“猜画小歌”吗，这个比赛的数据就来自这个小程序的网页版Quick, Draw!，游戏提示用户绘制描绘特定类别的涂鸦，例如“香蕉”，“桌子”等，所以Google通过这个小游戏收集了来自世界各地的涂鸦数据, 数据集所有信息都可见此数据集的官方仓库。本次比赛使用了340类一共约五千万个样本。 主办方给了两个版本的训练集，raw 和 simplified，都是以csv文件的形式给出的。raw版本就是原始收集到的数据各字段如下所示: Key Type Description key_id 64-bit unsigned integer 独一无二的样本ID word string 样本所属类别 recognized bool 样本是否被游戏识别 timestamp datetime 样本创建时间 countrycode string player所在国家代码(ISO 3166-1 alpha-2) drawing string 涂鸦数据信息 其中drawing字段就是涂鸦数据，包含坐标和时间信息，示例如下:12345678910111213[ [ // First stroke [x0, x1, x2, x3, ...], [y0, y1, y2, y3, ...], [t0, t1, t2, t3, ...] ], [ // Second stroke [x0, x1, x2, x3, ...], [y0, y1, y2, y3, ...], [t0, t1, t2, t3, ...] ], ... // Additional strokes] raw版本的数据集很大而且很多冗余信息，所以大多数选手(包括我)都是用的simplified版本作为主要训练集，simplified数据集去掉了时间信息和冗余的坐标信息(比如两点确定一条线段，那么线段中间的点就是冗余的)并将坐标进行了scale，具体处理方式如下: scaled 的坐标数据进行了左上对齐，最小值为0最大值为255. 进行了重采样使坐标都是0-255的整数. 去除冗余坐标使用的是Ramer–Douglas–Peucker算法，epsilon设为2.0； simplified数据集示例如下图所示: 图1.1 更多信息可见此数据集的官方仓库，这里就不赘述了。 1.2 赛题任务本题的任务就是预测测试集涂鸦属于哪个类别，是一个单分类问题。此题的难度在于，由于训练数据来自游戏本身，涂鸦样本可能不完整而且可能与标签不符，噪声比较多，如图1.2所示(图片来源)。选手需要构建一个识别器，可以有效地从这些噪声数据中学习得到模型。 图1.2 上图就是训练集中属于“蚊子”类别的数据示例，绿色是被标记为”可识别”的样本，红色是被标记为”不可识别”的样本，可以看到不管是可识别还是不可识别的样本，都存在噪声的情况。 1.3 评价指标虽然是一个单分类问题，但是对于每一个样本，我们需要提交最有可能的3个预测结果(按可能性从大到小排)，评价指标是Mean Average Precision @ 3 (MAP@3):$$\\text{MAP@3} = \\frac { 1 } { U } \\sum _ { u = 1 } ^ { U } \\sum _ { k = 1 } ^ { m i n ( n , 3 ) } P ( k )$$其中 $U$ 是测试集样本总数，$n$ 是每个样本的预测值总数，$P(k)$ 是前 $k$ 个结果中准确率, 具体可参见这个kernel，另外计算代码可参考这里。简单点讲，在提交的三个预测结果中，真实结果越靠前分数就越高。 2. 我的方案可见此题的数据是序列数据，所以最先想到可以用RNN，当然把数据渲染成图片也可以用CNN。根据我的实际实验，RNN的效果并不好（应该是我网络结构没设计好，讨论区有人提到用RNN也可以达到不错的效果），所以就采用了CNN相关模型，后来又merge了队友，最终的69名(PB 0.94223)是队友的提交结果，我的提交结果(PB 0.94185)应该是73名。 2.1 数据相关2.1.1 打乱原始文件题目给的数据是每一类一个csv文件，一共有340类，每一类有十多万个样本，即使是使用simplified数据集，总的csv文件大小也达到了20G+的级别，所以一次性读进内存肯定是不行的。我首先采用了这个kernel将340个csv文件混合在一起然后再随机分成100份分别存储，这样每一份里面的每一个样本的类别都是随机的。思路就是根据key_id的值产生一个0-99的伪随机数cv，然后cv就觉定当前样本应该放在哪个文件，最后再将每个文件里的样本顺序打乱。其核心代码如下: (1) 决定某个样本应该存放在哪个文件:1234567891011121314151617181920212223for y, cat in tqdm(enumerate(categories)): # 共340个类别 df = s.read_training_csv(cat) # df就为当前类别的csv df['y'] = y # y为 0~339 的数字，相当于对类别进行了LabelEncode df['cv'] = (df.key_id // 10 ** 7) % NCSVS # NCSVS = 100, cv决定了应该放在哪一个文件中 for k in range(NCSVS): filename = INPUT_PATH + '/shuffled_csv/train_%d_%d.csv'%(k+1, NCSVS) chunk = df[df.cv == k] # 得到df中cv=k的样本，应该存放在当前文件中 chunk = chunk.drop(['key_id'], axis=1) if y == 0: # 新建文件 chunk.to_csv(filename, index=False) else: # mode='a': 附加写 方式打开文件 chunk.to_csv(filename, mode='a', header=False, index=False) ``` (2) 将每个文件中的样本顺序打乱:``` pythonfor k in tqdm(range(NCSVS)): filename = INPUT_PATH + '/shuffled_csv/train_%d_%d.csv'%(k+1, NCSVS) if os.path.exists(filename): df = pd.read_csv(filename) df['rnd'] = np.random.rand(len(df)) # 给每个样本一个随机数 df = df.sort_values(by='rnd').drop('rnd', axis=1) df.to_csv(filename + '.gz', compression='gzip', index=False) # 以压缩的方式存储csv os.remove(filename) 这样处理后，原始simplified数据集中340个共20G+的csv文件被处理成100个csv共7G+，而且每个文件里的样本不是属于同一类而是随机的，这就方便后续的数据读取了。上面完整的代码见我的仓库。 2.1.2 多进程读取经过2.1.1处理后的数据就可以很方便地直接用了，我们可以考虑并行读取使读取更快:1234567891011121314151617181920212223242526def read_one_df_file(df_file): \"\"\"定义一个读取一个csv的函数，这个函数会当做参数传入下面的并行处理的函数\"\"\" unused_cols = [\"countrycode\", \"recognized\", \"timestamp\", \"cv\"] name = df_file.split('_')[-2] print('%s ' % (name), end = ' ', flush=True) df = pd.read_csv(df_file) drop_cols = [col for col in unused_cols if col in df.columns] if len(drop_cols) &gt; 0: df = df.drop(drop_cols, axis=1) return dfdef multi_thread_read_df_files(df_files, processes=32): \"\"\"并行读取多个csv并组成一个大的bigdf\"\"\" start = dt.datetime.now() pool = Pool(processes=processes) # from multiprocessing import Pool dfs = pool.map(read_one_df_file, df_files) pool.close() pool.join() end = dt.datetime.now() print(\"\\nTotal time:\", (end - start).seconds, \"seconds\") big_df = pd.concat(dfs, ignore_index=False, sort=False) big_df.reset_index(drop=True, inplace=True) return big_df 上面的完整代码见我的仓库里的data_loader.py，另外多进程的学习可参考此处。 2.1.3 outliers由图1.2知训练数据中有很多噪声，如何衡量噪声并去除这些噪声数据（outliers）呢？kernel sketch entropy提出用熵（entropy）来找出这些outliers, 即把entropy低于和高于某阈值的样本视为outliers。 先来看看如何计算entropy：12345def entropy_it(x): counts = np.bincount(x) # 计算x中 0-255这些数字的出现次数 p = counts[counts &gt; 0] / float(len(x)) # 归一化成概率 # compute Shannon entropy in bits return -np.sum(p * np.log2(p)) 直观理解，如果一张图片上的信息很少例如像素值几乎完全一样，那么归一化后的概率p就几乎是一个one hot的向量，这样 -np.sum(p * np.log2(p)) 就几乎得0；相反地，如果图片上的信息很丰富，像素分布比较均匀，那么p就是一个每个元素几乎都相等的向量，这样算出来的entropy就比较大。 例如训练集样本entropy低于和高于99%样本的示例分别如下： 图2.1 但是我最终并没有按照此方法去掉这些“outliers”，主要是出于以下考虑： 训练集很大，接近五千万，所以数据噪声对模型的影响应该有限； 按照此方法可得出测试集中也有一些噪声； 按照此方法得出的不一定就是噪声，例如图2.1第一排第一个应该是‘雨滴’，最后一排第三个应该是‘龙卷风’。 时间不够了，如果时间够的话我肯定会试一下。 这个kernel的作者也在讨论中提到： Be careful, do not remove unusual samples from training. In my recipe I use a curriculum learning, i.e. increase the amount of outliers at each new epoch. 虽然我最后并没有用这个方法，但是却提供了一个去噪的好思路。本节的完整代码见我的仓库中的sketch_entropy notebook。 2.2 模型2.2.1 模型结构本次比赛我最后采用的结构是xception（完整代码见此处），用的是pretrainedmodels库,这个库有主流模型的pytorch的实现，直接用就是，特别方便。代码如下1234567891011121314from pretrainedmodels.models.xception import Xceptionxception_path = \"/YOUR_PATH/pytorch/xception-43020ad28.pth\"def create_model(num_classes=340, model_func=Xception, pretrained_path=xception_path): model = model_func(num_classes=1000) # imageNet预训练参数，真的有用吗？ model.load_state_dict(torch.load(pretrained_path)) # 修改最后的fc层 fc_in_feas = model.fc.in_features model.fc = nn.Linear(fc_in_feas, num_classes) model.last_linear = model.fc # pretrainedmodels这个包里的模型作forward时使用的是last_linear return model 2.2.2 梯度累积trick我们知道，一般来说，增大batch size会使最终的预测效果变得更好，但是GPU显存是有限的不可能无限增大batch size，这时候梯度累积就派上用场了。简单来说，梯度累积就是累积多个batch的梯度然后一次更新参数，而不是常用的一个batch更新一次，亲测在小数据集上是有效果提升的（本次比赛数据集size很大，但我也用了这个trick，没有和不用这个trick做比较）。参考这里Gopal_Sharma的系列回答，我写了如下代码：12345678910111213141516171819202122# loss, preds, step_acc = train_step(model, inputs, labels, criterion, optimizer)################# 将batch_accumulate_size个batch的梯度积累起来,只在最后一次更新网络参数 ###################inputs = inputs.to(DEVICE, dtype=torch.float)labels = labels.to(DEVICE, dtype=torch.float)if step % batch_accumulate_size == 0: optimizer.zero_grad()with torch.set_grad_enabled(True): # forward outputs = model(inputs) loss = criterion(outputs, labels.long()) / batch_accumulate_size # 一定要除以这个size,原因见上面链接的讨论 loss.backward() _, preds = torch.max(outputs, 1)correct_num = torch.sum(preds == labels.long())step_acc = correct_num.double() / inputs.size(0) if (step + 1) % batch_accumulate_size == 0: optimizer.step() # 只在最后一次更新网络参数loss = batch_accumulate_size * loss.item() # 转换为数字方便后面用visdom画图step_acc = step_acc.item()######################################################################################## 2.2.3 多GPUpytorch实现多GPU还是比较方便的，只需要加上一行代码即可：12model = create_model()multi_gpu_model = nn.DataParallel(model) 需要注意的是，使用了DataParallel(model)的模型在保存的时候会在参数的key前面加上“module.”，所以如果使用单GPU时加载多GPU保存的模型参数时会报错KeyError: &#39;unexpected key &quot;module.xx.weight&quot; in state_dict&#39;，正确的处理方式如下：12345678910111213from collections import OrderedDictpretrained_net_dict = torch.load(best_model_path)if hps.gpus == 1 and list(pretrained_net_dict.keys())[0][:6] == \"module\":# 如果当前是单GPU但是保存的模型是多GPU，那就要去掉每个key的前缀\"module.\" new_state_dict = OrderedDict() for k, v in pretrained_net_dict.items(): name = k[7:] # remove \"module.\" new_state_dict[name] = v # load params model.load_state_dict(new_state_dict)else: model.load_state_dict(pretrained_net_dict) 2.2.4 图像数据的一个坑本节的notebook见此处。 事情的起因是这样的，我在训练的时候没有进行数据增强(只用了toTensor和Normalize两个transform)，而我在测试的时候想用一下用torchvision自带的一些图片增强的transform(例如CenterCrop、RandomHorizontalFlip、RandomRotation等等)，但是这些transform要求输入的是PIL图片，所以我在测试的时候就用了如下代码将image array转成了PIL图片：1PIL_image = Image.fromarray(image_array.astype('uint8'), 'RGB') 但最后测试出来的结果与验证时完全不一样，模型基本上是靠猜。这是为什么呢？仔细看看下面这个图就知道了。 图2.2 由图2.2可知，训练和测试的时候数据取值范围都变了，网络预测结果当然就很差了。先来看看ToTensor的官方文档: 123torchvision.transforms.ToTensorConvert a PIL Image or numpy.ndarray to tensor.Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]. 可见ToTensor将输入的0-255的数据scale到0-1并且还调整了一下维度顺序，那为什么图2.2的训练输入还是0-255呢? 问题就出在数据的类型上面，训练时，原始图片数据iamge_array的类型是float64(而不是ToTensor期待的uint8)，经过ToTensor转换后数值大小不会变依然是0-255只是调了一下维度顺序。而测试的时候，由于ToPILImage强制要求输入类型是uint8，所以先将输入转换成了uint8格式，所以就正确的被scale到了0-1。 总结一下，由于像素值为0到255的整数，所以刚好是uint8所能表示的范围，而很多关于图片的函数就默认输入的是uint8型，若不是，可能不会报错但的可能得不到想要的结果。所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug 。 3. top方案3.1 1st place solution第一名的方案由现在排在所有kaggle用户第五的超级大佬Pavel Pleskov贡献，原文见此处。 3.1.1 模型结构刚开始，Pavel训练了很多分类模型：resnet18, resnet34, resnet50, resnet101, resnet152, resnext50, resnext101, densenet121, densenet201, vgg11, pnasnet, incresnet, polynet, nasnetmobile, senet154, seresnet50, seresnext50, seresnext101。此外，数据预处理尝试了1个和3个通道的输入、image size从112逐渐增大到256。大约40个模型中，最优的模型得到了0.946的分数，这个单一模型就可以拿到金牌了。 可以看到，这种类型的比赛如果前期能花大量时间尝试不同的模型，那基本就能保证奖牌了，甚至金牌。 3.1.2 ensemble为了将多个模型的输出集成起来，粗暴一点就是直接将输出的概率值求平均再取top3即得到最终的输出(也就是blend)。怎样将多个模型的结果ensemble在一起呢？因为一共340类，所以每一个模型对每个样本都会输出340个概率值，如果将每个概率值作为ensemble的feature，假设一共有8个模型，那么一个样本就有340x8个feature，这个特征维度有点大了而且其中很多都是接近0的值。 Pavel的思路是: for each sample and for each model you collect top 10 probabilities with the labels, then convert them into 10 samples with the binary outcome - whether this is a correct label or not (9 negative examples + 1 positive). It’s easy to feed such a dataset to any booster because the number of features will be small (equal to the number of models). 大概意思是将ensemble转换成一个二分类问题: 根据8(模型数)个概率值判断是不是label(例如这8个概率值都大于0.8，那么几乎可以肯定这就是label)。详细来讲，LGBM的特征维度等于模型数(每个特征就代表一个模型的输出概率)，而样本数将会是原始样本数的10倍。21st place solution也用到了这个方法，比直接平均得到的分数要高。 但是我有一点不明白的是如何找这个top10，因为对于mode1它的输出概率值top10可能是class0-9，对于model2它的输出概率值top10可能是class1-10，这样就对应不上了。但是我倒是有一个思路那就是先对8个模型的输出概率求个平均再取top10(21st place solution貌似使用的最好的model来预测出top10)。例如8个模型对于某张涂鸦图片的平均输出概率top10是O1、O2…O10，那么这就能产生10个LGBM的输入样本，会得到10个输出(是0-1的概率值)，取最大的三个即最终这个涂鸦样本的结果。 3.1.3 Predictions balancing trickHeng CherKeng发现，测试集中的groundtruth分布应该是均匀的，而且发现 (112199+1)/340=330 (训练集样本数加1除以类别数得330)。这一点很重要，通过对模型输出的概率按照此规律进行后处理，平均给每个模型带来了0.7%的提升。那么如何进行后处理呢? Pavel给出的算法是：对于当前最多的预测类别,将所有这个类别对应的概率不断减去一个很小的数直到这个类别不是最多的，重复上述过程直到预测类别差不多均匀。Pavel在之前的比赛也用到了这个算法(代码见此处)，代码原理和刚刚说的略有不同，算法步骤如下: 先对每一种类别赋一个初始为1的系数coefficients，当前预测概率等于实际概率乘以对应的系数； 计算每种类别的数目，按照这个数目再计算一个score，逻辑是预测越均匀score就越大; 对最多的类别label，执行coefficients[label] -= alpha； 若还没达到最大迭代次数，就继续执行2、3，执行过程中记录最大的score对应的coefficients，迭代完成后返回这个coefficients。 上述的score计算过程如下:12345678def _compute_score_with_coefficients(predicts, coefficients): _, counter = _get_labels_distribution(predicts, coefficients) # 计算每种类别的数目 # 按照下面的计算过程，当预测是均匀的时，score达到最大340 score = 0. for label in range(NCATS): # NCATS=340 score += min(NCATS * float(counter[label]) / len(predicts), 1.0) return score Pavel Ostyakov写的此算法的pytorch版见此处。 3.2 5th place solution3.2.1 总体流程第五名的方案由Artur Ispiriants和Mykhailo Matviiv贡献，原文见此处。 Artur Ispiriants先将每个样本从CSV文件提取出来，每个样本用一个二进制文件存放，这占用了大约400G的SSD，比较耗空间，但是方便后续各种模型的使用。 Artur一共训练了三个模型: Se-Resnext50 DPN-92 Se-Resnext101 每个模型都使用了在ImageNet上预训练的权重。图片尺寸使用了128、192、224、256，实验显示图片尺寸越大分数就越高，但是由于显存限制，尺寸越大就越难训练了。使用128的尺寸就能达到0.944的LB。 后来Artur Ispiriants merge了队友Mykhailo Matviiv，LB达到了约0.948，后来又使用了完整数据集里的时间信息: 延迟时间 每一笔的时间 笔画数量 上述三个数据都被scale到0-255。使用了这三个信息后，LB提升到了0.951。 3.2.2 训练流程由于数据集巨大，所以训练一个epoch就需要很长的时间，所以要经常保存模型，大约4-6个小时保存一下checkpoint。下面是Mykhailo Matviiv训练SE-ResNext101的流程： 图片尺寸取128x128训练网络直到收敛，这大概需要20个checkpoint，能达到0.945. 上一步得不到提升时，使用2.2.2节的梯度累积技术使batch size达到约3-4k，继续训练，模型进一步提升； 更进一步的提升就是在更大的图片尺寸(192然后256)进行fine tune。 3.2.3 trick比赛使用的一些trick如下： 经常保存checkpoint带来的一个提升就是snapshot ensembling，即一个模型最终的预测输出是这个模型的几个checkpoint的综合。最后的输出是多个模型的平均blend。 伪标签。这个方法是比赛最后阶段的主要提分点。此时blend模型的分数为0.951，使用这个输出给测试集加上了label（预测的top1），然后(只)用这些带label的测试集fine tune所有模型10个epoch，挑选3个最佳的epoch blend得到了0.952的LB。然后再用新的输出给测试集加上label，再fine tune，分数就达到了0.953，然后由于种种原因没再进行了(作者说再进行可能会进一步提升)。我认为这个方法要避免过拟合，作者也说了要谨慎使用，可以考虑将带伪标签的测试集混合在训练集进行训练以减少过拟合的风险。 3.3 其他3.3.1 RNN模型单模型0.941的RNN模型: 1d CNN+LSTM 3.3.2 11th place solution资源有限的情况下达到第11名的方案。 3.3.3 21st place solution也使用了3.1.2所示的ensemble方法，评论处有具体的ensemble方法。 3.3.4 24th place solution24th solution, 用的keras，并用了keras封装好的梯度累积trick 3.3.5 10 lessons46th的团队在这里给出了参加这个比赛得出的10条教训，有兴趣的可以去看看。 4. 总结 比赛前期应该多多尝试不同的网络结构； 这种超大数据集的图像类比赛，一般来讲就是网络越深、图片尺寸越大、batchsize越大，效果就越好； 注意积累一些trick，例如梯度累积、伪标签、Predictions balancing等等； 由于训练一个epoch时间漫长，所以每隔几个小时就保存一下模型是很有必要的，一个模型的预测输出应该是该模型几个checkpoint的输出的融合； 多逛逛讨论区。","categories":[{"name":"Competitions","slug":"Competitions","permalink":"https://tangshusen.me/categories/Competitions/"}],"tags":[{"name":"kaggle,classification","slug":"kaggle-classification","permalink":"https://tangshusen.me/tags/kaggle-classification/"}]},{"title":"Longest Palindromic Substring(最长回文子串)","slug":"Longest-Palindromic-Substring","date":"2018-12-01T14:23:15.000Z","updated":"2018-12-30T09:14:45.273Z","comments":true,"path":"2018/12/01/Longest-Palindromic-Substring/","link":"","permalink":"https://tangshusen.me/2018/12/01/Longest-Palindromic-Substring/","excerpt":"1. 问题描述Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.给定一个字符串s，找出s中的最长回文子串。s的长度不超过1000.","text":"1. 问题描述Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.给定一个字符串s，找出s中的最长回文子串。s的长度不超过1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer. Example 2: Input: “cbbd”Output: “bb” 2. 题解2.1 暴力法2.1.1 思路暴力穷举所有子字符串的可能，然后依次按位判断其是否是回文。虽然其时间复杂度很高，但它对空间的要求很低。 2.1.2 复杂度空间复杂度显然为 $O(1)$ ；穷举所有字符串复杂度为 $O(n^2)$ ，再加上判断是否是回文的，所以总的时间复杂度为 $O(n^3)$ 。 2.1.3 代码代码就不给了，给了你也不会看😀 2.2 动态规划2.2.1 思路我们知道，当某个字符串是回文的时候，在它两边同时增加一个相同字符后肯定依然是回文的，例如 bccb -&gt; abccba。基于这个特点，我们可以将暴力法中的判断是否为回文这一步用动态规划解决。 具体的，我们可以先把所有长度为1的子字符串计算出来，这些必定是回文的；然后计算出所有长度为2的子字符串并判断是否为回文。到长度为3的时候，我们就可以利用上次的计算结果：如果中心对称的短字符串不是回文，那长字符串也不是，如果短字符串是回文，那就要看长字符串两头是否一样。这样，一直到长度最大的子字符串，我们就把整个字符串集穷举完了。在这个过程中用一个 n x n 的二维bool型数组isOK记录是否会回文，其中n是字符串s的长度，isOK[i][j] == true就表示子串s[i...j]是回文的。 2.2.2 复杂度由于要申请一个二维数组isOK, 所以空间复杂度为 $O(n^2)$ ;由于使用动态规划，时间复杂度从暴力法的 $O(n^3)$ 减少到 $O(n^2)$。实测: Runtime: 244 ms, faster than 14.67% of C++ online submissions for Longest Palindromic Substring. 2.2.3 代码123456789101112131415161718192021class Solution &#123;public: string longestPalindrome(string s) &#123; if(!s.size()) return \"\"; vector&lt;vector&lt;bool&gt;&gt;isOK(s.size(), vector&lt;bool&gt;(s.size(), false)); string res = \"\"; for(int len = 1; len &lt;= s.size(); len++)&#123; // len代表子串长度 for(int start = 0; start + len &lt;= s.size(); start++)&#123; // start代表子串起始位置 if(len == 1) isOK[start][start] = true; else if(len == 2) isOK[start][start + 1] = (s[start] == s[start + 1]); else isOK[start][start + len - 1] = isOK[start + 1][start + len - 2] \\ &amp;&amp; s[start] == s[start + len - 1]; // 更新结果 if(isOK[start][start + len - 1] &amp;&amp; len &gt; res.size()) res = s.substr(start, len); &#125; &#125; return res; &#125;&#125;; 2.3 中心扩散法2.3.1 思路上面讲的动态规划虽然优化了时间，但也浪费了很多空间。实际上我们并不需要一直存储所有子字符串的回文情况，我们需要知道的只是中心对称的较小一层是否是回文。所以如果我们从小到大连续以某点为个中心的所有子字符串进行计算，就能省略这个空间。需要注意的是，由于中心对称有两种情况: 长度为奇数，则以中心字母对称； 长度为偶数，则以两个字母中间为对称。 所以我们要分别计算这两种对称情况。 2.3.2 复杂度相较于2.2的动态规划，空间复杂度缩小为 $O(1)$；时间复杂度一样，都是 $O(n^2)$。实测: Runtime: 20 ms, faster than 57.88% of C++ online submissions for Longest Palindromic Substring. 2.3.3 代码1234567891011121314151617181920212223class Solution &#123;public: string longestPalindrome(string s) &#123; if(!s.size()) return \"\"; string res = s.substr(0, 1); for(int mid = 0; mid &lt; s.size(); mid++)&#123; // mid为中心字母或者对称轴的前一个字母的下标 // mid为中心字母下标，即子串长度为奇数 for(int half_len = 1; mid + half_len &lt; s.size() &amp;&amp; mid - half_len &gt;= 0; half_len++)&#123; if(s[mid + half_len] != s[mid - half_len]) break; if(2 * half_len + 1 &gt; res.size()) res = s.substr(mid - half_len, 2*half_len + 1); &#125; // mid为对称轴的前一个字母，即子串长度为偶数 for(int half_len = 1; mid + half_len &lt; s.size() &amp;&amp; mid - half_len &gt;= -1; half_len++)&#123; if(s[mid + half_len] != s[mid - half_len + 1]) break; if(2 * half_len &gt; res.size()) res = s.substr(mid - half_len + 1, 2 * half_len); &#125; &#125; return res; &#125;&#125;; 2.4 马拉车(Manacher)算法下面要出场的就是大名鼎鼎的马拉车算法了，前面介绍的算法最快也不过 $O(n^2)$ 的时间复杂度，而马拉车的时间复杂度为逆天的 $O(n)$ 😨，是此题最理想的复杂度了。 本节主要参考LeetCode对此算法的详细解释。 2.4.1 思路首先，为了避免2.3那样将子串分为长度为奇数和偶数两种情况，我们先将字符串简单处理一下, 在s中的每个字符两边插入一个字符“#”得到字符串(在具体实现中，为了避免越界检查，通常还会在首尾额外插入两个与所有可能的字符都不同的字符如^、$),例如： s = abaaba —插入字符–&gt; T = #a#b#a#a#b#a# 为了找到最长的回文子串，我们先计算出以每个字符为中心的最长回文子串，然后比较之后找出最长的。我们使用数组P来保存以T中每个字符为中心的最长回文子串的半径(既长度的一半)。紧接着上面的例子: T : # a # b # a # a # b # a #P : 0 1 0 3 0 1 6 1 0 3 0 1 0 通过数组P，找到其中最大的数字6，我们可以马上得出最长的回文字符串就是s本身abaaba，即问题转换为如何高效地求解数组P。 我们仔细观察一下上面这个特殊的例子，我们会发现不仅T是对称的，就连P都是对称的，由于我们的目的就是计算出P的所有元素值，那么如果P是对称的，岂不是可以大大减少计算量！马拉车算法就是基于这样一个想法展开的。 为了详细介绍马拉车算法，我们来看一个稍微复杂的例子s = babcbabcbaccba: 如上图所示,假设已经完成了P数组的部分数值的计算，当前需要计算的是P[i]。我们引入变量 R，表示当前访问到的所有回文子串中所能触及的最右一个字符的位置。另外还要记录下R对应的回文串的对称轴所在的位置，记为C。另外也可推断出该回文串的左边位置L。图中的实线即表示C，两条虚线(L和R)分别表示以C为中心的回文串的边界。现在需要计算的是 P[i] 的值，图中 i’ 表示的是 i 关于 C 对称的点。那么问题来了，怎么高效地算出P[i]。 当前 i 的值是 13，我们需要得到P[13]的值，我们首先看下 i 关于 C对称的 i&#39; = 9的值。 如上图所示，两条绿色实线覆盖的区域分表表示的是 以 i’ 和 i 为中心的最长回文子串。我们已经知道了 P[i&#39;] = 1, 那么由于回文子串的对称性(即上图L~C和C~R对应的子串是关于C对称的)，我们可以推断出 P[i] = p[i&#39;] = 1。实际上，C之后的三个元素都遵循了这种对称性（既 P[12] = P[10] = 0, P[13] = P[9] =1, P[14] = P[8] = 0)。 如上图所示，现在我们到了 i = 15 这个点，i 关于 C对称的点是 i&#39; = 7, 那么这里 P[15] = P[7] = 7 还会不会成立呢？ 很显然是不成立的，我们凭肉眼观察可知 p[15] = 5 而 P[7] = 7。这是为什么呢？ 上图中，绿色实线表示的是以C为中心的最长回文子串所覆盖的区域，红色实线表示的是与绿色区域不匹配的部分，左边的红色实线是以T[i&#39;]为中心的最长回文子串所覆盖区域超出绿色实线的部分。右边的红色实线是以T[i]为中心的最长回文子串所覆盖区域超出绿色实线的部分。而绿色的虚线部分则是分别以T[i]和T[i&#39;]为中心最长回文子串与绿色实线部分的重叠部分。 从图中我们可以明显的看出被两条绿色实线所覆盖的区域中，C两边的子串是完全相同的。同时绿色虚线的那部分也是关于中心对称的。当 i = 12,13,14 即 i&#39; = 10,9,8 时，以T[i&#39;]为中心的最大回文子串全落在了L和R之间，这就使得我们能够使用LR的对称性直接得出关于T[i]对称的最大回文子串；但当 i&#39; = 7 即 P[i&#39;] = 7，此时以T[i&#39;]为中心的最长回文子串超出了以C为中心的最长回文子串的左边界(图中L左边红色实线)，正是因为这个原因，此时无法再按照对称性直接得出 P[i] 的值了，但是可以推出 P[i] &gt;= 5。 现在我们知道的是P[i] &gt;= 5, 为了找出P[i]最终的值，我们只有继续以P[i]为中心向两边扩展进行比较，在这个例子中P[21] != P[1],那么我们最终推断是P[i] = 5。 总结一下，在每一步中，都存在两种可能: R &gt; i，也就是刚刚我们讨论的情况，此时又细分为两种情况:(1) 若 P[i&#39;] &lt; R – i, 则令 P[i] = P[i&#39;];(2) 否则， 先令P[i] = P[i&#39;]，再以i为中心扩展回文串并P[i]++，直到左右两边字符不同或者到达边界。并更新变量R、C。 R &lt;= i，即i移动到R右边了，此时也应该以i为中心扩展回文串。类似情况1(2),只是P[i]初始为0。 2.4.2 复杂度空间复杂度显然是O(n).下面讨论一下时间复杂度，虽然代码中存在两个循环for和while，但是需要注意是： 当R不需要进行扩展时，不会进入while循环； R需要进行扩展时，会进入while循环，但整个算法过程while一共循环最多n次，即R从0不断扩展到n。 由此可见，马拉车算法是线性的时间复杂度，即O(n)。 亲测: Runtime: 8 ms, faster than 88.39% of C++ online submissions for Longest Palindromic Substring. 2.5.1 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123;private: // 将字符串S转换成T，例如S = \"abba\", T = \"^#a#b#b#a#$\". // ^ 和 $ 是为了避免越界检查 string preProcess(string s) &#123; int n = s.size(); if (n == 0) return \"^$\"; string t = \"^\"; for (int i = 0; i &lt; n; i++) t += \"#\" + s.substr(i, 1); t += \"#$\"; return t; &#125; public: string longestPalindrome(string s) &#123; string T = preProcess(s); int n = T.size(); vector&lt;int&gt;P(n); int C = 0, R = 0; for (int i = 1; i &lt; n-1; i++) &#123; int i_mirror = 2 * C - i; // i' = C - (i-C) P[i] = (R &gt; i) ? min(R - i, P[i_mirror]) : 0; // 尝试扩展以i为中心的回文串 while (T[i + 1 + P[i]] == T[i - 1 - P[i]]) P[i]++; // 如果以i为中心的回文串的右边界超过了R，则应该更新R和C if (i + P[i] &gt; R) &#123; C = i; R = i + P[i]; &#125; &#125; // 找出P中最大的元素 int maxLen = 0; int centerIndex = 0; for (int i = 1; i &lt; n-1; i++) &#123; //注意跳过首尾 if (P[i] &gt; maxLen) &#123; maxLen = P[i]; centerIndex = i; &#125; &#125; return s.substr((centerIndex - 1 - maxLen)/2, maxLen); // 减一是因为去掉第一个字符^ &#125;&#125;;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://tangshusen.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://tangshusen.me/tags/动态规划/"},{"name":"马拉车算法","slug":"马拉车算法","permalink":"https://tangshusen.me/tags/马拉车算法/"},{"name":"字符串","slug":"字符串","permalink":"https://tangshusen.me/tags/字符串/"}]},{"title":"AdaBoost算法详解与python实现","slug":"adaboost","date":"2018-11-18T14:05:04.000Z","updated":"2018-12-30T09:14:14.935Z","comments":true,"path":"2018/11/18/adaboost/","link":"","permalink":"https://tangshusen.me/2018/11/18/adaboost/","excerpt":"目前网上大多数博客只介绍了AdaBoost算法是什么，但是鲜有人介绍为什么Adaboost长这样，本文对此给出了详细的解释。","text":"目前网上大多数博客只介绍了AdaBoost算法是什么，但是鲜有人介绍为什么Adaboost长这样，本文对此给出了详细的解释。 1. 概述1.1 集成学习目前存在各种各样的机器学习算法，例如SVM、决策树、感知机等等。但是实际应用中，或者说在打比赛时，成绩较好的队伍几乎都用了集成学习(ensemble learning)的方法。集成学习的思想，简单来讲，就是“三个臭皮匠顶个诸葛亮”。集成学习通过结合多个学习器(例如同种算法但是参数不同，或者不同算法)，一般会获得比任意单个学习器都要好的性能，尤其是在这些学习器都是”弱学习器”的时候提升效果会很明显。 弱学习器指的是性能不太好的学习器，比如一个准确率略微超过50%的二分类器。 下面看看西瓜书对此做的一个简单理论分析。考虑一个二分类问题 $y \\in {-1, +1}$ 、真实函数 $f$ 以及奇数 $M$ 个犯错概率相互独立且均为 $\\epsilon $ 的个体学习器(或者称基学习器) $h_i$ 。我们用简单的投票进行集成学习，即分类结果取半数以上的基学习器的结果:$$H(x) = sign(\\sum_{i=1}^M h_i(x)) \\tag{1.1.1}$$由Hoeffding不等式知，集成学习后的犯错(即过半数基学习器犯错)概率满足$$P(H(x) \\neq f(x)) \\leq exp(- \\frac 1 2 M (1-2\\epsilon)^2) \\tag{1.1.2}$$ 式 $（1.1.2）$ 的证明是周志华《机器学习》的习题8.1，题解可参考此处 式 $（1.1.2）$ 指出，当犯错概率独立的基学习器个数 $M$ 很大时，集成后的犯错概率接近0，这也很符合直观想法: 大多数人同时犯错的概率是比较低的。 就如上面加粗字体强调的，以上推论全部建立在基学习器犯错相互独立的情况下，但实际中这些学习器不可能相互独立，而如何让基学习器变得“相对独立一些”，也即增加这些基学习器的多样性，正是集成学习需要考虑的主要问题。 按照每个基学习器之间是否存在依赖关系可以将集成学习分为两类： 基学习器之间存在强依赖关系，一系列基学习器需要串行生成，代表算法是Boosting； 基学习器之间不存在强依赖关系，一系列基学习器可并行生成，代表算法是Bagging和随机森林。 Boosting系列算法里最著名算法主要有AdaBoost和提升树(Boosting tree)系列算法，本文只介绍最具代表性的AdaBoost。提升树、Bagging以及随机森林不在本文介绍范围内，有时间了再另外介绍。 1.2 BoostingBoosting指的是一类集成方法，其主要思想就是将弱的基学习器提升(boost)为强学习器。具体步骤如下: 先用每个样本权重相等的训练集训练一个初始的基学习器； 根据上轮得到的学习器对训练集的预测表现情况调整训练集中的样本权重(例如提高被错分类的样本的权重使之在下轮训练中得到更多的关注), 然后据此训练一个新的基学习器； 重复2直到得到 $M$ 个基学习器，最终的集成结果是 $M$ 个基学习器的组合。 由此看出，Boosting算法是一个串行的过程。 Boosting算法簇中最著名的就是AdaBoost，下文将会详细介绍。 2. AdaBoost原理2.1 基本思想对于1.2节所述的Boosting算法步骤，需要回答两个问题: 如何调整每一轮的训练集中的样本权重？ 如何将得到的 $M$ 个组合成最终的学习器？ AdaBoost(Adaptive Boosting, 自适应增强)算法采取的方法是: 提高上一轮被错误分类的样本的权值，降低被正确分类的样本的权值； 线性加权求和。误差率小的基学习器拥有较大的权值，误差率大的基学习器拥有较小的权值。 Adaboost算法结构如下图(图片来源)所示。 图2.1 下面先给出AdaBoost算法具体实现步骤，至于算法解释（为什么要这样做）将在下一大节阐述。 2.2 算法步骤考虑如下形式的二分类（标准AdaBoost算法只适用于二分类任务）训练数据集:$${(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$$其中 $x_i$是一个含有$d$个元素的列向量, 即 $x_i\\in \\mathcal{X} \\subseteq \\mathbf{R}^d$ ; $y_i$是标量, $y\\in{+1,-1}$。 Adaboost算法具体步骤如下: 初始化样本的权重$$D_1=(w_{11}, w_{12},…w_{1N}), w_{1i}=\\frac 1 N, i = 1,2…N \\tag{2.2.1}$$ 对$m = 1,2,…M$,重复以下操作得到 $M$ 个基学习器:(1) 按照样本权重分布 $D_m$ 训练数据得到第 $m$ 个基学习器 $G_m(x)$:$$G_m(x): \\mathcal{X} \\to {-1, +1}$$(2) 计算 $G_m(x)$ 在加权训练数据集上的分类误差率:$$e_m = \\sum_{i=1}^NP(G_m(x_i) \\neq y_i)=\\sum_{i=1}^N w_{mi} I(G_m(x_i) \\neq y_i) \\tag{2.2.2}$$上式中 $I(\\cdot)$ 是指示函数，考虑更加周全的AdaBoost算法在这一步还应该判断是否满足基本条件(例如生成的基学习器是否比随机猜测好), 如果不满足，则当前基学习器被抛弃，学习过程提前终止。(3) 计算 $G_m(x)$ 的系数(即最终集成使用的的基学习器的权重):$$\\alpha_m = \\frac 1 2 log \\frac {1-e_m} {e_m} \\tag{2.2.3}$$(4) 更新训练样本的权重$$D_{m+1}=(w_{m+1,1}, w_{m+1,2},…w_{m+1,N}) \\tag{2.2.4}$$$$w_{m+1, i} = \\frac{w_{mi}} {Z_m} exp(-\\alpha_my_iG_m(x_i)) ,i=1,2,…N \\tag{2.2.5}$$其中 $Z_m$ 是规范化因子，目的是为了使 $D_{m+1}$ 的所有元素和为1。即$$Z_m=\\sum_{i=1}^N w_{mi} exp(-\\alpha_my_iG_m(x_i)) \\tag{2.2.6}$$ 构建最终的分类器线性组合$$f(x) = \\sum_{i=1}^M \\alpha_m G_m(x) \\tag{2.2.7}$$得到最终的分类器为$$G(x) = sign(f(x))=sign(\\sum_{i=1}^M \\alpha_m G_m(x)) \\tag{2.2.8}$$ 由式 $(2.2.3)$ 知，当基学习器 $G_m(x)$ 的误差率 $e_m \\le 0.5$ 时，$\\alpha_m \\ge 0$，并且 $\\alpha_m$ 随着 $e_m$ 的减小而增大，即分类误差率越小的基学习器在最终集成时占比也越大。即AdaBoost能够适应各个弱分类器的训练误差率，这也是它的名称中”适应性(Adaptive)”的由来。 由式 $(2.2.5)$ 知， 被基学习器 $G_m(x)$ 误分类的样本权值得以扩大，而被正确分类的样本的权值被得以缩小。 需要注意的是式 $(2.2.7)$ 中所有的 $\\alpha_m$ 的和并不为1(因为没有做一个softmax操作)，$f(x)$ 的符号决定了所预测的类，其绝对值代表了分类的确信度。 3. AdaBoost算法解释有没有想过为什么AdaBoost算法长上面这个样子，例如为什么 $\\alpha_m$ 要用式 $(2.2.3)$ 那样计算？本节将探讨这个问题。 3.1 前向分步算法在解释AdaBoost算法之前，先来看看前向分步算法。 就以AdaBoost算法的最终模型表达式为例:$$f(x) = \\sum_{i=1}^M \\alpha_m G_m(x) \\tag{3.1.1}$$可以看到这是一个“加性模型(additive model)”。我们希望这个模型在训练集上的经验误差最小，即$$min \\sum_{i=1}^N L(y_i, f(x)) \\iff min \\sum_{i=1}^N L(y_i, \\sum_{i=1}^M \\alpha_m G_m(x)) \\tag{3.1.2}$$通常这是一个复杂的优化问题。前向分步算法求解这一优化问题的思想就是: 因为最终模型是一个加性模型，如果能从前往后，每一步只学习一个基学习器 $G_m(x)$ 及其权重 $\\alpha_m$ , 不断迭代得到最终的模型，那么就可以简化问题复杂度。具体的，当我们经过 $m-1$ 轮迭代得到了最优模型 $f_{m-1}(x)$ 时，因为 $$f_m(x)= f_{m-1}(x) + \\alpha_mG_m(x) \\tag{3.1.3}$$所以此轮优化目标就为$$min \\sum_{i=1}^N L(y_i, f_{m-1}(x) + \\alpha_mG_m(x)) \\tag{3.1.4}$$求解上式即可得到第 $m$ 个基分类器 $G_m(x)$ 及其权重 $\\alpha_m$ 。这样，前向分步算法就通过不断迭代求得了从 $m=1$ 到 $m=M$ 的所有基分类器及其权重，问题得到了解决。 3.2 AdaBoost算法证明上一小结介绍的前向分步算法逐一学习基学习器，这一过程也即AdaBoost算法逐一学习基学习器的过程。但是为什么2.2节中的公式为什么长那样还是没有解释。本节就证明前向分步算法的损失函数是指数损失函数(exponential loss function)时，AdaBoost学习的具体步骤就如2.2节所示。 指数损失函数即$$L(y, f(x)) = exp(-yf(x))$$周志华《机器学习》p174有证明，指数损失函数是分类任务原本0/1损失函数的一致(consistent)替代损失函数，由于指数损失函数有更好的数学性质，例如处处可微，所以我们用它替代0/1损失作为优化目标。 将指数损失函数代入式 $(3.1.4)$ ，优化目标就为$$\\underset{\\alpha_m,G_m}{argmin} \\sum_{i=1}^N exp[-y_i(f_{m-1}(x) + \\alpha_mG_m(x))] \\tag{3.2.1}$$因为 $y_if_{m-1}(x)$ 与优化变量 $\\alpha$ 和 $G$ 无关，如果令$$w_{m,i} = exp[-y_i f_{m-1}(x)] \\tag{3.2.2}$$ 这个 $w_{m,i}$ 其实就是2.2节中归一化之前的权重 $w_{m,i}$ 那么式 $(3.2.1)$ 等价于$$\\underset{\\alpha_m,G_m}{argmin} \\sum_{i=1}^N w_{m,i}exp(-y_i\\alpha_mG_m(x)) \\tag{3.2.3}$$ 我们分两步来求解式 $(3.2.3)$ 所示的优化问题的最优解 $\\hat{\\alpha}_m$ 和 $\\hat{G}_m(x)$ : 对任意的 $\\alpha_m &gt; 0$, 求 $\\hat{G}_m(x)$：$$\\hat{G}_m (x) = \\underset{G_m}{argmin} \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) \\tag{3.2.4}$$ 上式将指数函数换成指示函数是因为前面说的指数损失函数和0/1损失函数是一致等价的。 式子 $(3.2.4)$ 所示的优化问题其实就是AdaBoost算法的基学习器的学习过程，即2.2节的步骤2(1)，得到的 $\\hat{G}_m(x)$ 是使第 $m$ 轮加权训练数据分类误差最小的基分类器。 求解 $\\hat{\\alpha}_m$ ： 将式子 $(3.2.3)$ 中的目标函数展开$$\\begin{aligned}\\sum_{i=1}^N w_{m,i}exp(-y_i\\alpha_mG_m(x)) &amp;= \\sum_{y_i=G_m(x_i)} w_{m,i}e^{- \\alpha} + \\sum_{y_i \\neq G_m(x_i)}w_{m,i}e^{\\alpha} \\\\\\\\&amp; = (e^{\\alpha} - e^{-\\alpha}) \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) + e^{-\\alpha} \\sum_{i=1}^N w_{m,i}\\end{aligned} \\tag{3.2.5}$$ 注：为了简洁，上式子中的$\\hat{G}_m(x)$ 被略去了 $\\hat{\\cdot}$ ， $\\alpha_m$ 被略去了下标 $m$ ，下同 将上式对 $\\alpha$ 求导并令导数为0，即 $$(e^{\\alpha} + e^{-\\alpha}) \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) - e^{-\\alpha} \\sum_{i=1}^N w_{m,i} = 0 \\tag{3.2.6} $$ 解得 $$ \\hat{\\alpha}_m = \\frac 1 2 log \\frac {1-e_m} {e_m} \\tag{3.2.7} $$ 其中, $e_m$ 是分类误差率： $$ e_m = \\frac {\\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)} {\\sum_{i=1}^N w_{mi}} \\tag{3.2.8} $$ 如果式子 $(3.2.8)$ 中的 $w_{mi}$ 归一化成和为1的话那么式 $(3.2.8)$ 也就和2.2节式 $(2.2.2)$ 一模一样了，进一步地也有上面的 $\\hat{\\alpha}_m$ 也就是2.2节的 $\\alpha_m$ 。 最后来看看每一轮样本权值的更新，由 $(3.1.3)$ 和 $(3.2.2)$ 可得 $$ w_{m+1,i} = w_{m,i} exp[-y_i \\alpha_m G_{m}(x)] \\tag{3.2.9} $$ 如果将上式进行归一化成和为1的话就和与2.2节中 $(2.2.5)$ 完全相同了。 由此可见，2.2节所述的AdaBoost算法步骤是可以经过严密推导得来的。总结一下，本节推导有如下关键点: AdaBoost算法是一个加性模型，将其简化成前向分步算法求解； 将0/1损失函数用数学性质更好的指数损失函数替代。 4. python实现4.1 基学习器首先需要定义一个基学习器，它应该是一个弱分类器。弱分类器使用库 sklearn 中的决策树分类器DecisionTreeClassifier, 可设置该决策树的最大深度为1。12# Fit a simple decision tree(weak classifier) firstclf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1) 4.2 AdaBoost实现然后就是完整AdaBoost算法的实现了，如下所示。12345678910111213141516171819202122232425262728293031323334353637def my_adaboost_clf(Y_train, X_train, Y_test, X_test, M=20, weak_clf=DecisionTreeClassifier(max_depth = 1)): n_train, n_test = len(X_train), len(X_test) # Initialize weights w = np.ones(n_train) / n_train pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)] for i in range(M): # Fit a classifier with the specific weights weak_clf.fit(X_train, Y_train, sample_weight = w) pred_train_i = weak_clf.predict(X_train) pred_test_i = weak_clf.predict(X_test) # Indicator function miss = [int(x) for x in (pred_train_i != Y_train)] print(\"weak_clf_%02d train acc: %.4f\" % (i + 1, 1 - sum(miss) / n_train)) # Error err_m = np.dot(w, miss) # Alpha alpha_m = 0.5 * np.log((1 - err_m) / float(err_m)) # New weights miss2 = [x if x==1 else -1 for x in miss] # -1 * y_i * G(x_i): 1 / -1 w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2])) w = w / sum(w) # Add to prediction pred_train_i = [1 if x == 1 else -1 for x in pred_train_i] pred_test_i = [1 if x == 1 else -1 for x in pred_test_i] pred_train = pred_train + np.multiply(alpha_m, pred_train_i) pred_test = pred_test + np.multiply(alpha_m, pred_test_i) pred_train = (pred_train &gt; 0) * 1 pred_test = (pred_test &gt; 0) * 1 print(\"My AdaBoost clf train accuracy: %.4f\" % (sum(pred_train == Y_train) / n_train)) print(\"My AdaBoost clf test accuracy: %.4f\" % (sum(pred_test == Y_test) / n_test))","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"AdaBoost","slug":"AdaBoost","permalink":"https://tangshusen.me/tags/AdaBoost/"},{"name":"集成学习(ensemble)","slug":"集成学习-ensemble","permalink":"https://tangshusen.me/tags/集成学习-ensemble/"}]},{"title":"TensorFlow实现多层RNN的一个大坑","slug":"tf-multi-rnn-bug","date":"2018-11-13T14:30:02.000Z","updated":"2018-12-30T09:15:56.162Z","comments":true,"path":"2018/11/13/tf-multi-rnn-bug/","link":"","permalink":"https://tangshusen.me/2018/11/13/tf-multi-rnn-bug/","excerpt":"","text":"起因事情的起因是这样的，我已经用tensorflow实现了一个带attention的encoder-decoder(都是单层的RNN)的结构，代码组织结构如下所示1234567891011121314151617encoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)def Encoder(cell, inputs): '''根据输入得到输出''' ...... return outputs# shape: (batch_size, max_seq_len, rnn_size)encoder_outputs = Encoder(encoder_cell, inputs)# 下面是attentionattn_mech = tf.contrib.seq2seq.LuongAttention(...) decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attn_mech, attention_layer_size=attn_size,...)# 下面的就不重要了...... 上面这段代码在attn_size为任何值的时候都是可以正常执行的。这也很符合预期，因为上面这段代码所干的事情如下: 用encoder将input编码成encoder_output(即attention的keys或者memory)； 对于decode的每一个时刻t，将t-1时刻得到的attention context(shape[-1]为attn_size)和decoder的输入合并在一起输入到decoder；…… 可以看到attn_size确实是任何值都可以, 也即decoder的输入维度(attn_size + input_x_size)为任何都可以。 注意TensorFlow中的RNN cell不需要显式指定输入的维度(而是自己推断出来)，这和pytorch不一样:pytorch_rnn = torch.nn.LSTM(input_size = attn_size + input_x_size, hidden_size=rnn_size) 经过后来我又想将decoder改成多层的RNN，decoder结构就像下面右边这样： 于是我将decoder_cell的定义做了如下修改:12345......one_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell for _ in range(dec_num_layers)])...... 除非把attn_size设置成rnn_size - input_x_size，否则会报类似下面的维度不对的错误(假设rnn_size=256, attn_size + input_x_size = 356)1ValueError: Dimensions must be equal, but are 256 and 356 for &apos;rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/MatMul_1&apos; (op: &apos;MatMul&apos;) with input shapes: [30,256], [356,1200]. 这是为什么呢？明明按照前面的分析，明明attn_size设置成任何值都可以的啊。 解决一开始我一直以为是我的attention写得不对，于是google了好久都没发现attention问题在哪？直到我看到了这个issue才发现是我的多层RNN没写对，还是自己太菜了😭 正确的多层decoder_cell应该是如下定义:1234......cell_list = [tf.nn.rnn_cell.LSTMCell(num_units=rnn_size) for _ in range(dec_num_layers)]decoder_cell = tf.nn.rnn_cell.MultiRNNCell(cell_list)...... 咋一看上面这段代码貌似和之前的错误代码没什么区别，但是如下代码你就应该意识到哪儿不对了12345678&gt;&gt;&gt; str = \"bug\"&gt;&gt;&gt; strs = [str for _ in range(2)]&gt;&gt;&gt; print(strs)['bug', 'bug']&gt;&gt;&gt; for str in strs: print(id(str)) # id()函数用于获取对象的内存地址43670492004367049200 注意到上面输出的两个地址都是一样的。因此，我们就知道问题出在哪儿了:对于前面错误的多层rnn实现, 每一层的LSTMCell其实都是同一个(指向它们的指针是相同的)，那么每一层的LSTMCell的weights维度就也是一样的，但其实第一层的输入维度(attn_size + input_x_size)和其它层的（rnn_size)一般都是不一样的，如下图所示，这样就会报维度错误了。 而正确代码中，每一个LSTMCell都是通过tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)定义的，因此可以有不同的结构，自然不会报错。 总结 TensorFlow中错误的多层RNN实现方式: 123one_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell for _ in range(dec_num_layers)])# decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell]*dec_num_layers])也是错误的 TensorFlow中正确的多层RNN实现方式: 12cell_list = [tf.nn.rnn_cell.LSTMCell(num_units=rnn_size) for _ in range(dec_num_layers)]decoder_cell = tf.nn.rnn_cell.MultiRNNCell(cell_list) 参考 Cannot stack LSTM with MultiRNNCell and dynamic_rnn using dynamic_rnn with multiRNN gives error","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://tangshusen.me/categories/Deep-Learning/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://tangshusen.me/tags/tensorflow/"},{"name":"RNN","slug":"RNN","permalink":"https://tangshusen.me/tags/RNN/"},{"name":"attention","slug":"attention","permalink":"https://tangshusen.me/tags/attention/"},{"name":"seq2seq","slug":"seq2seq","permalink":"https://tangshusen.me/tags/seq2seq/"}]},{"title":"看了这篇文章你还不懂SVM你就来打我","slug":"SVM","date":"2018-10-27T15:19:45.000Z","updated":"2018-12-30T09:15:43.822Z","comments":true,"path":"2018/10/27/SVM/","link":"","permalink":"https://tangshusen.me/2018/10/27/SVM/","excerpt":"","text":"支持向量机(Support Vector Machine, SVM)1. 概要1.1 简介自从大半年前接触到SVM以来，感觉一直没怎么把SVM整明白。直到最近上的《模式识别》课程才仿佛打通了我的任督二脉，使我终于搞清楚了SVM的来龙去脉，所以写个博客作个总结。 SVM是什么? 先来看看维基百科上对SVM的定义: 支持向量机（英语：support vector machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。 如果从未接触SVM的话，维基的这一大段解释肯定会让你一头雾水。简单点讲，SVM就是一种二类分类模型，他的基本模型是的定义在特征空间上的间隔最大的线性分类器，SVM的学习策略就是间隔最大化。 1.2 直观理解我们先来看看下面这个图: 图1.1 图中有分别属于两类的一些二维数据点和三条直线。如果三条直线分别代表三个分类器的话，请问哪一个分类器比较好？ 我们凭直观感受应该觉得答案是H3。首先H1不能把类别分开，这个分类器肯定是不行的；H2可以，但分割线与最近的数据点只有很小的间隔，如果测试数据有一些噪声的话可能就会被H2错误分类(即对噪声敏感、泛化能力弱)。H3以较大间隔将它们分开，这样就能容忍测试数据的一些噪声而正确分类，是一个泛化能力不错的分类器。 对于支持向量机来说，数据点若是$p$维向量，我们用$p-1$维的超平面来分开这些点。但是可能有许多超平面可以把数据分类。最佳超平面的一个合理选择就是以最大间隔把两个类分开的超平面。因此，SVM选择能够使离超平面最近的数据点的到超平面距离最大的超平面。 以上介绍的SVM只能解决线性可分的问题，为了解决更加复杂的问题，支持向量机学习方法有一些由简至繁的模型: 线性可分SVM 当训练数据线性可分时，通过硬间隔(hard margin，什么是硬、软间隔下面会讲)最大化可以学习得到一个线性分类器，即硬间隔SVM，如上图的的H3。 线性SVM 当训练数据不能线性可分但是可以近似线性可分时，通过软间隔(soft margin)最大化也可以学习到一个线性分类器，即软间隔SVM。 非线性SVM 当训练数据线性不可分时，通过使用核技巧(kernel trick)和软间隔最大化，可以学习到一个非线性SVM。 2. 线性可分SVM——硬间隔考虑如下形式的线性可分的训练数据集:$${(X_1,y_1),(X_2,y_2),…,(X_n,y_n)}$$其中 $X_i$是一个含有$d$个元素的列向量, 即$X_i\\in \\mathbf{R}^d$; $y_i$是标量, $y\\in{+1,-1}$, $y_i = +1$时表示$X_i$属于正类别, $y_i = -1$时表示$X_i$属于负类别。 注: 本文中, $X$、$X_i$、$W$等都是(列)向量，有的文章一般用 $x_i$ 表示一个向量而用 $X$ 表示所有 $x_i$ 组成的一个矩阵，注意区分。 回忆一下感知机的目标: 找到一个超平面使其能正确地将每个样本正确分类。感知机使用误分类最小的方法求得超平面，不过此时解有无穷多个(例如图1.1的H2和H3以及它俩的任意线性组合)。而线性可分支持向量机利用间隔最大化求最优分离超平面,这时解是唯一的。 2.1 超平面与间隔一个超平面由法向量$W$和截距$b$决定,其方程为$X^TW+b=0$, 可以规定法向量指向的一侧为正类,另一侧为负类。下图画出了三个平行的超平面，法方向取左上方向。 注意: 如果$X$和$W$都是列向量,即$X^TW$会得到$X$和$W$的点积(dot product, 是一个标量),等价于$X \\cdot W$和$W \\cdot X$。 图2.1 为了找到最大间隔超平面，我们可以先选择分离两类数据的两个平行超平面，使得它们之间的距离尽可能大。在这两个超平面范围内的区域称为“间隔(margin)”，最大间隔超平面是位于它们正中间的超平面。这个过程如上图所示。 2.2 间隔最大化将高数里面求两条平行直线的距离公式推广到高维可求得图2.1中margin的$\\rho$:$$margin = \\rho = \\frac 2 {||W||} \\tag{2.2.1}$$我们的目标是使$\\rho$最大, 等价于使$\\rho^2$最大:$$\\underset{W,b}{max} \\rho \\iff \\underset{W,b}{max} \\rho^2 \\iff \\underset{W,b}{min}\\frac 1 2 ||W||^2 \\tag{2.2.2}$$上式的$\\frac 1 2$是为了后续求导后刚好能消去，没有其他特殊意义。 同时也不要忘了有一些约束条件:$$X_i^TW+b \\ge +1, y_i=+1 \\\\\\\\X_i^TW+b \\le -1, y_i=-1 \\tag{2.2.3}$$总结一下，间隔最大化问题的数学表达就是$$\\underset{W,b}{min}J(W) = \\underset{W,b}{min}\\frac 1 2 ||W||^2 \\\\\\\\s.t.\\quad y_i(X_i^TW+b) \\ge 1, i=1,2,…n. \\tag{2.2.4}$$ 通过求解上式即可得到最优超平面 $ \\hat{W} $ 和 $ \\hat{b} $ 。具体如何求解见2.4和2.5节。 2.3 支持向量在线性可分的情况下，训练数据集的样本点中与分离超平面距离最近的数据点称为支持向量(support vector)，支持向量是使$(2.2.4)$中的约束条件取等的点，即满足$$ y_i(X_i^TW+b) = 1 \\tag{2.3.1}$$的点。也即所有在直线$ X^TW+b = 1$或直线$ X^TW+b = -1$的点。如下图所示: 图2.2 在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用(具体推导见2.4节最后)。如果移动非支持向量，甚至删除非支持向量都不会对最优超平面产生任何影响。\u001c也即支持向量对模型起着决定性的作用，这也是“支持向量机”名称的由来。 2.4 对偶问题如何求解式 $(2.2.4)$ 呢？ 我们称式 $(2.2.4)$ 所述问题为原始问题(primal problem), 可以应用拉格朗日乘子法构造拉格朗日函数(Lagrange function)再通过求解其对偶问题(dual problem)得到原始问题的最优解。转换为对偶问题来求解的原因是: 对偶问题更易求解，由下文知对偶问题只需优化一个变量$\\alpha$且约束条件更简单； 能更加自然地引入核函数，进而推广到非线性问题。 首先构建拉格朗日函数。为此需要引进拉格朗日乘子(Lagrange multiplier) $\\alpha_i \\ge 0, i=1,2,…n$。则拉格朗日函数为:$$L(W,b,\\alpha)=\\frac 1 2 ||W||^2 - \\sum_{i=1}^n \\alpha_i [y_i(X_i^TW+b)-1]\\tag{2.4.1}$$因此，给定一个$W$和$b$, 若不满足式$(2.2.4)$的约束条件，那么有$$\\underset{\\alpha}{max} L(W,b,\\alpha) = +\\infty \\tag{2.4.2}$$否则，若满足式$(2.2.4)$的约束条件，有$$\\underset{\\alpha}{max} L(W,b,\\alpha) = J(W) = \\frac 1 2 ||W||^2 \\tag{2.4.3}$$结合式$(2.4.2)$和$(2.4.3)$知，优化问题$$\\underset{W, b}{min} \\underset{\\alpha}{max} L(W,b,\\alpha)\\tag{2.4.4}$$与式$(2.2.4)$所述问题是完全等价的。 根据拉格朗日对偶性，式$(2.4.4)$所述问题即原始问题的对偶问题是:$$\\underset{\\alpha}{max} \\underset{W, b}{min} L(W,b,\\alpha) \\tag{2.4.5}$$ 以上具体推导细节可参见书籍《统计学习方法》或者知乎文章拉格朗日对偶性 为了求得对偶问题的解，需要先求得$L(W,b,\\alpha)$对$W$和$b$的极小再求对$\\alpha$的极大。 (1) 求$\\underset{W, b}{min} L(W,b,\\alpha)$:对拉格朗日函数求导并令导数为0，有:$$\\nabla_W L(W,b,\\alpha) = W - \\sum_{i=1}^n \\alpha_i y_i X_i = 0 \\implies W= \\sum_{i=1}^n \\alpha_i y_i X_i\\tag{2.4.6}$$$$\\nabla_b L(W,b,\\alpha) = - \\sum_{i=1}^n \\alpha_i y_i = 0 \\implies \\sum_{i=1}^n \\alpha_i y_i = 0 \\tag{2.4.7}$$将上面两式代入$L(W,b,\\alpha)$： 所以，$$\\underset{W, b}{min} L(W,b,\\alpha) = -\\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ + \\ \\sum_{i=1}^n \\alpha_i \\tag{2.4.8}$$ (2) 求$\\underset{W, b}{min} L(W,b,\\alpha)$ 对$\\alpha$的极大:等价于式$(2.4.8)$对$\\alpha$求极大，也等价于式$(2.4.8)$取负数后对$\\alpha$求极小，即$$\\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ - \\ \\sum_{i=1}^n \\alpha_i \\tag{2.4.9}$$同时满足约束条件:$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\\\alpha_i \\ge 0, i=1,2,…,n. \\tag{2.4.10}$$ 至此，我们得到了原始最优化问题$(2.2.4)$和对偶最优化问题$(2.4.9)$、$(2.4.10)$。 由slater条件知，因为原始优化问题的目标函数和不等式约束条件都是凸函数，并且该不等式约束是严格可行的(因为数据是线性可分的), 所以存在 $ \\hat{W} $, $ \\hat{b}$ ,$\\hat{\\alpha} $，使得$ \\hat{W} $, $ \\hat{b}$是原始问题的解，$\\hat{\\alpha} $是对偶问题的解。这意味着求解原始最优化问题$(2.2.4)$可以转换为求解对偶最优化问题$(2.4.9)$、$(2.4.10)$。 slater 条件:原始问题一般性表达为$$\\underset{x}{min} \\quad f(x) \\\\\\\\s.t. \\ c_i(x) \\le 0, i=1,2,…k \\\\\\\\\\quad \\quad h_j(x) = 0, j=1,2,…,l$$则其拉格朗日函数为$$L(x,\\alpha,\\beta)=f(x) + \\sum_{i=1}^k \\alpha_i c_i(x) +\\sum_{j=1}^l \\beta_j h_j(x), \\quad \\alpha_i \\ge 0$$假设原始问题目标函数 $f(x)$ 和不等式约束条件 $c_i(x)$都是凸函数，原始问题等式约束$h_j(x)$都是仿射函数，且不等式约束 $c_i(x)$是严格可行的，即存在 $x$ ，对所有 $i$ 都有 $c_i(x) &lt; 0$ ，则存在 $\\hat{x} $, $\\hat{\\alpha} $, $\\hat{\\beta} $，使 $\\hat{x} $ 是原始问题的解， $\\hat{\\alpha} $, $\\hat{\\beta} $是对偶问题的解。 那么如何求解优化问题$(2.4.9)$、$(2.4.10)$的最优解 $\\hat{\\alpha}$ 呢？不难发现这是一个二次规划问题，有现成的通用的算法来求解。 事实上通用的求解二次规划问题的算法的复杂度正比于训练数据样本数，所以在实际应用中需要寻求更加高效的算法，例如序列最小优化(Sequential Minimal Optimiation, SMO)算法。 假设我们现在求得了$(2.4.9)$、$(2.4.10)$的最优解 $\\hat{\\alpha}$，则根据式$(2.4.6)$可求得最优$\\hat{W}$：$$\\hat{W}= \\sum_{i=1}^n \\hat{\\alpha}_i y_i X_i \\tag{2.4.11}$$因为至少存在一个 $\\hat{\\alpha}_j &gt; 0$(若不存在，即 $\\hat{\\alpha}$ 全为0，则 $\\hat{W}=0$, 即 $margin = \\frac 2 {||\\hat{W}||}= \\infty $,显然不行), 再根据KKT条件，即$$\\begin{cases}乘子非负: \\alpha_i \\ge 0 (i=1,2,…n.下同) \\\\\\\\约束条件: y_i(X_i^TW+b) - 1\\ge 0 \\\\\\\\互补条件: \\alpha_i (y_i(X_i^TW+b) - 1)=0\\end{cases}$$所以至少存在一个 $j$ , 使 $ y_j(X_j^T \\hat{W}+\\hat{b}) - 1=0$, 即可求得最优 $\\hat{b}$:$$\\begin{aligned}\\hat{b} &amp; = \\frac 1 {y_j} -X_j^T \\hat{W} \\\\\\\\&amp; = y_j -X_j^T \\hat{W} \\\\\\\\&amp; = y_j-\\sum_{i=1}^n \\hat{\\alpha}_i y_i X_j^T X_i\\end{aligned} \\tag{2.4.12}$$至此，所以我们就求得了整个线性可分SVM的解。求得的分离超平面为:$$\\sum_{i=1}^n \\hat{\\alpha}_i y_i X^TX_i + \\hat{b}=0 \\tag{2.4.13}$$则分类的决策函数为$$f(X) = sign(\\sum_{i=1}^n \\hat{\\alpha}_i y_i X^TX_i + \\hat{b})\\tag{2.4.14}$$再来分析KKT条件里的互补条件，对于任意样本 $(X_i, y_i)$ ，总会有 $ \\alpha_i=0 $ 或者 $y_if(X_i)=y_i(X_i^T \\hat{W}+b) = 1$。则有 若$ \\alpha_i=0$，此样本点不是支持向量，对模型没有任何作用； 若$ \\alpha_i&gt;0$，此样本点位于最大间隔边界上，是一个支持向量，如下图所示。 图2.3 此外，当样本点是非支持向量时，因为$ \\alpha_i=0$, 所以SVM的解中的求和项中第 $i$ 项就为0，所以SVM的解$(2.4.11)$、$(2.4.12)$可简化为如下形式:$$\\hat{W}= \\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_i \\tag{2.4.15}$$$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_j^T X_i\\tag{2.4.16}$$类似的，判别函数也可转换成如下形式:$$f(X) = sign(\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X^TX_i + \\hat{b})\\tag{2.4.17}$$所以，整个SVM的解只与支持向量SV有关，与非支持向量无关。这也就解释了2.3节的结论，即在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用。 3. 线性SVM——软间隔在前面的讨论中，我们一直假定训练数据是严格线性可分的，即存在一个超平面能完全将两类数据分开。但是现实任务这个假设往往不成立，例如下图所示的数据。 图3.1 3.1 软间隔最大化解决该问题的一个办法是允许SVM在少量样本上出错，即将之前的硬间隔最大化条件放宽一点，为此引入“软间隔(soft margin)”的概念。即允许少量样本不满足约束$$y_i(X_i^TW+b) \\ge 1 \\tag{3.1.1}$$为了使不满足上述条件的样本点尽可能少，我们需要在优化的目标函数$(2.2.2)$里面新增一个对这些点的惩罚项。最常用的是hinge损失:$$l_{hinge}(z) = max(0, 1-z) \\tag{3.1.2}$$即若样本点满足约束条件损失就是0, 否则损失就是 $1-z$ ,则优化目标 $(2.2.2)$ 变成$$\\underset{W,b}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n max(0, 1 - y_i(X_i^TW+b))\\tag{3.1.3}$$其中 $C &gt; 0$ 称为惩罚参数，$C$ 越小时对误分类惩罚越小，越大时对误分类惩罚越大，当 $C$ 取正无穷时就变成了硬间隔优化。实际应用时我们要合理选取 $C$，$C$ 越小越容易欠拟合，$C$ 越大越容易过拟合。 如果我们引入“松弛变量” $ \\xi_i \\ge 0$, 那么式 $(3.1.3)$ 可重写成$$\\underset{W,b,\\xi}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i\\\\\\\\s.t.\\ y_i(X_i^TW+b) \\ge 1-\\xi_i \\\\\\\\\\xi_i \\ge 0, i=1,2,…n. \\tag{3.1.4}$$上式所述问题即软间隔支持向量机。 3.2 对偶问题式 $(3.1.4)$ 表示的软间隔支持向量机依然是一个凸二次规划问题，和硬间隔支持向量机类似，我们可以通过拉格朗日乘子法将其转换为对偶问题进行求解。式 $(3.1.4)$ 对应的拉格朗日函数为$$L(W,b,\\xi,\\alpha,\\beta)=\\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i - \\sum_{i=1}^n \\alpha_i [y_i(X_i^TW+b) - 1 + \\xi_i] - \\sum_{i=1}^n \\beta_i \\xi_i\\tag{3.2.1}$$类似2.4节，为了求得对偶问题的解，我们需要先求得$L(W,b,\\xi,\\alpha,\\beta)$对 $W$、$b$ 和 $\\xi$ 的极小再求对 $\\alpha$ 和 $\\beta$ 的极大。 以下两步和2.4节几乎完全一样，除了最后对 $\\alpha$ 的约束条件略有不同。 (1) 求$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta)$:将 $L(W,b,\\xi,\\alpha,\\beta)$ 分别对 $W$、$b$ 和 $\\xi$ 求偏导并令为0可得$$W=\\sum_{i=1}^n \\alpha_i y_i X_i \\tag{3.2.2}$$$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\tag{3.2.3}$$$$C = \\alpha_i + \\beta_i \\tag{3.2.4}$$将上面三个式子代入式 $(3.2.1)$ 并进行类似式 $(2.4.8)$ 的推导即得$$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta) =-\\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ + \\ \\sum_{i=1}^n \\alpha_i \\tag{3.2.5}$$注意其中的 $\\beta$ 被消去了。 (2) 求$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta)$对 $\\alpha$ 的极大：式$(3.2.5)$对$\\alpha$求极大，也等价于式$(3.2.5)$取负数后对$\\alpha$求极小，即$$\\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ - \\ \\sum_{i=1}^n \\alpha_i \\tag{3.2.6}$$同时满足约束条件:$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\\\quad 0 \\le \\alpha_i \\le C, i=1,2,…,n. \\tag{3.2.7}$$ 至此，我们得到了原始最优化问题$(3.1.4)$和对偶最优化问题$(3.2.6)$、$(3.2.7)$。 类似2.4节地，假设我们现在通过通用的二次规划求解方法或者SMO算法求得了$(3.2.6)$、$(3.2.7)$的最优解 $\\hat{\\alpha}$，则根据式$(3.2.2)$可求得最优$\\hat{W}$：$$\\hat{W}= \\sum_{i=1}^n \\hat{\\alpha}_i y_i X_i \\tag{3.2.8}$$再根据KKT条件，即$$\\begin{cases}乘子非负: \\alpha_i \\ge 0 ,\\enspace \\beta_i \\ge 0 (i=1,2,…n.下同)\\\\\\\\约束条件: y_i(X_i^TW+b) - 1\\ge \\xi_i \\\\\\\\互补条件: \\alpha_i [y_i(X_i^TW+b) - 1+\\xi_i]=0, \\enspace \\beta_i \\xi_i=0\\end{cases}$$可求得整个软间隔SVM的解，即:$$\\hat{W}= \\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_i \\tag{3.2.9}$$$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_j^T X_i\\tag{3.2.10}$$其中 $j$ 需满足 $0 &lt; \\hat{\\alpha}_j &lt; C$ 。 对于任意样本 $(X_i, y_i)$ ， 若 $ \\alpha_i=0$，此样本点不是支持向量，该样本对模型没有任何的作用； 若 $ \\alpha_i&gt;0$，此样本是一个支持向量。 若满足 $ \\alpha_i&gt;0$ ，进一步地， 若 $ 0 &lt; \\alpha_i &lt; C$, 由式 $(3.2.4)$ 得 $\\beta_i = 0$，即刚好 $y_i(X_i^TW+b) =1$，样本恰好在最大间隔边界上； 若 $\\alpha_i = C$，有$\\beta_i &gt; 0$，此时若 $\\beta_i &lt; 1$则该样本落在最大间隔内部，若 $\\beta_i &gt; 1$ 则该样本落在最大间隔内部即被错误分类。 如下图所示。 图3.2 因此，我们有与2.4节相同的结论，最优超平面只与支持向量有关而与非支持向量无关。 3.3 惩罚参数 $C$对于不同惩罚参数 $C$，SVM结果如下图所示。 图3.3 再来看看我们的原始目标函数:$$\\underset{W,b,\\xi}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i$$ 对于更加一般化的问题，可将上述式子抽象成：$$\\underset{f}{min} \\quad \\Omega(f) + C \\sum_{i=1}^n l(f(x_i),y_i) \\tag{3.3.1}$$前一项可以理解为“结构风险(structural risk)”，用来描述所求模型的某些性质(SVM就是要求间隔最大)；第二项称为“经验风险(empirical risk)”，用来描述模型与训练数据的契合程度(即误差)。而参数 $C$ 就是用于对二者的折中,即我们一方面要求模型要满足某种性质另一方面又想使模型与训练数据很契合。 从正则化角度来讲， $\\Omega(f)$ 称为正则化项，$C$ 称为惩罚参数，$C$ 越大即对误分类的惩罚越大(要求模型对训练模型更契合)，这可能会存在过拟合；$C$ 越小即相对更加看重正则化项，此时可能存在欠拟合。 4. 非线性SVM——核技巧前面介绍的都是线性问题，但是我们经常会遇到非线性的问题(例如异或问题)，此时就需要用到核技巧(kernel trick)将线性支持向量机推广到非线性支持向量机。需要注意的是，不仅仅是SVM，很多线性模型都可以用核技巧推广到非线性\u001c模型，例如核线性判别分析(KLDA)。 4.1 核函数如下图所示，核技巧的基本思路分为两步: 使用一个变换将原空间的数据映射到新空间(例如更高维甚至无穷维的空间)； 然后在新空间里用线性方法从训练数据中学习得到模型。 图4.1 怎样映射到特征空间？ 先来看看核函数的定义， 设 $\\mathcal{X}$ 是输入空间(欧式空间$R^n$的子集或离散集合)，又设 $\\mathcal{H}$ 是特征空间(希尔伯特空间)，如果存在一个 $\\mathcal{X}$ 到 $\\mathcal{H}$ 的映射$$\\phi(x): \\mathcal{X} \\to \\mathcal{H}$$使得对所有 $x,z \\in \\mathcal{X}$，函数 $K(x,z)$ 满足条件$$K(x,z)=\\phi(x) \\cdot \\phi(z)$$则称 $K(x,z)$ 为核函数， $\\phi(x)$ 为映射函数，式中 $\\phi(x) \\cdot \\phi(z)$ 为 $\\phi(x)$ 和 $\\phi(z)$ 的內积。 通常，直接计算 $K(x,z)$ 比较容易而通过 $\\phi(x)$ 和 $\\phi(z)$ 计算 $K(x,z)$ 并不容易。而幸运的是，在线性支持向量机的对偶问题中，无论是目标函数还是决策函数都只涉及到输入样本与样本之间的內积，因此我们不需要显式地定义映射 $\\phi(x)$ 是什么而只需事先定义核函数 $K(x,z)$ 即可。也就是说，在核函数 $K(x,z)$ 给定的情况下，可以利用解线性问题的方法求解非线性问题的支持向量机，此过程是隐式地在特征空间中进行的。 4.2 正定核由上面的介绍可知，我们只需要定义核函数就可以了。但是如何不通过映射 $\\phi(x)$ 判断给定的一个函数 $K(x,z)$ 是不是核函数呢？或者说，$K(x,z)$ 需要满足什么条件才是一个核函数。 通常所说的核函数就是正定核函数，下面不加证明的给出正定核的充要条件，具体证明略显复杂，有兴趣的可以参考《统计学习方法》。 设 $\\mathcal{X} \\subset R^n$ ,$K(x,z)$ 是定义在 $\\mathcal{X} \\times \\mathcal{X}$ 上的对称函数，如果对任意的 $x_i \\in \\mathcal{X}, i=1,2,…,m$，$K(x,z)$ 对应的Gram矩阵$$K = [K(x_i, x_j)]_{m \\times m}$$是半正定矩阵，则 $K(x,z)$ 是正定核。 虽然有了上述定义，但是实际应用时验证 $K(x,z)$ 是否是正定核依然不容易，因此在实际问题中一般使用已有的核函数，下面给出一些常用的核函数。 多项式核函数(polynomial kernel function)$$K(x,z) = (x \\cdot z + 1)^p \\tag{4.2.1}$$ 高斯核函数(Guassian kernel function)$$K(x,z) = exp(- \\frac {||x-z||^2} {2 \\sigma^2} ) \\tag{4.2.2}$$ 4.3 非线性支持向量机如前4.1、4.2所述，利用核技巧可以很简单地把线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机中的內积换成核函数即可。下面简述非线性支持向量机学习算法。 首先选取适当的核函数 $K(x,z)$ 和适当的参数 $C$，构造最优化问题$$\\begin{aligned}&amp; \\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j K(X_i,X_j) \\ - \\ \\sum_{i=1}^n \\alpha_i \\\\\\\\&amp; s.t. \\quad \\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\&amp; \\qquad 0 \\le \\alpha_i \\le C, i=1,2,…,n.\\end{aligned} \\tag{4.3.1}$$再利用现成的二次规划问题求解算法或者SMO算法求得最优解 $\\hat{\\alpha}$ 。 选择 $\\hat{\\alpha}$ 的一个满足 $0 &lt; \\hat{\\alpha}_j &lt; C$ 的分量 $\\hat{\\alpha}_j$ ，计算$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i K(X_j,X_i)\\tag{4.3.2}$$ 构造决策函数：$$f(x)=sign(\\sum_{i \\in SV}\\hat{\\alpha}_i y_i K(X_j,X_i) + \\hat{b}) \\tag{4.3.3}$$ 5. 总结5.1 SVM优缺点任何算法都有其优缺点，支持向量机也不例外。 支持向量机的优点是: 由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。 不仅适用于线性线性问题还适用于非线性问题(用核技巧)。 拥有高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。 理论基础比较完善(例如神经网络就更像一个黑盒子)。 支持向量机的缺点是: 二次规划问题求解将涉及m阶矩阵的计算(m为样本的个数), 因此SVM不适用于超大数据集。(SMO算法可以缓解这个问题) 只适用于二分类问题。(SVM的推广SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题) 5.2 SVM调参经验SVM很适合做分类任务，但是如果刚开始接触SVM而不知道如何进行合理的参数选择的话可能得不到满意的结果。下面简介运用SVM的基本步骤，或者说调参经验。 主要参考:Hsu C W, Chang C C, Lin C J. A practical guide to support vector classification[J]. 2003. 将原始数据转换为SVM算法期待的格\u001c\u001c式； 将数据进行scaling(很重要)； 一般考虑用高斯核RBF(如果特征维度太高，建议直接用线性SVM)； 交叉验证寻找最优的RBF的参数以及参数 $C$ ; 用上面找到的最优参数在整个训练集上训练；","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"SVM","slug":"SVM","permalink":"https://tangshusen.me/tags/SVM/"},{"name":"kernel trick","slug":"kernel-trick","permalink":"https://tangshusen.me/tags/kernel-trick/"},{"name":"classification","slug":"classification","permalink":"https://tangshusen.me/tags/classification/"}]}]}