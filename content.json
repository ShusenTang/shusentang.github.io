{"meta":{"title":"TangShusen","subtitle":null,"description":null,"author":"TangShusen","url":"https://tangshusen.me"},"pages":[{"title":"About me","date":"2018-11-11T14:41:04.000Z","updated":"2019-11-18T13:47:09.739Z","comments":true,"path":"about/index.html","permalink":"https://tangshusen.me/about/index.html","excerpt":"","text":"I’m a graduate student majoring in the Computer Science at School of EE &amp; CS, Peking University, China. Email | Website | GitHub | 知乎"},{"title":"分类","date":"2018-10-27T16:30:26.000Z","updated":"2018-11-11T14:43:48.261Z","comments":true,"path":"categories/index.html","permalink":"https://tangshusen.me/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-27T16:34:16.000Z","updated":"2018-11-10T16:18:46.450Z","comments":true,"path":"tags/index.html","permalink":"https://tangshusen.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"动态规划之背包问题系列","slug":"knapsack-problem","date":"2019-11-24T03:05:44.000Z","updated":"2019-11-26T16:31:10.008Z","comments":true,"path":"2019/11/24/knapsack-problem/","link":"","permalink":"https://tangshusen.me/2019/11/24/knapsack-problem/","excerpt":"背包问题是一类经典的动态规划问题，它非常灵活，需要仔细琢磨体会，本文先对背包问题的几种常见类型作一个总结，然后再看看LeetCode上几个相关题目。","text":"背包问题是一类经典的动态规划问题，它非常灵活，需要仔细琢磨体会，本文先对背包问题的几种常见类型作一个总结，然后再看看LeetCode上几个相关题目。 根据维基百科，背包问题（Knapsack problem）是一种组合优化的NP完全（NP-Complete，NPC）问题。问题可以描述为：给定一组物品，每种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。NPC问题是没有多项式时间复杂度的解法的，但是利用动态规划，我们可以以伪多项式时间复杂度求解背包问题。一般来讲，背包问题有以下几种分类： 01背包问题 完全背包问题 多重背包问题 此外，还存在一些其他考法，例如恰好装满、求方案总数、求所有的方案等。本文接下来就分别讨论一下这些问题。 1. 01背包1.1 题目最基本的背包问题就是01背包问题（01 knapsack problem）：一共有N件物品，第i（i从1开始）件物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？ 1.2 分析如果采用暴力穷举的方式，每件物品都存在装入和不装入两种情况，所以总的时间复杂度是O(2^N)，这是不可接受的。而使用动态规划可以将复杂度降至O(NW)。我们的目标是书包内物品的总价值，而变量是物品和书包的限重，所以我们可定义状态dp:1dp[i][j]表示将前i件物品装进限重为j的背包可以获得的最大价值, 0&lt;=i&lt;=N, 0&lt;=j&lt;=W 那么我们可以将dp[0][0…W]初始化为0，表示将前0个物品（即没有物品）装入书包的最大价值为0。那么当 i &gt; 0 时dp[i][j]有两种情况： 不装入第i件物品，即dp[i−1][j]； 装入第i件物品（前提是能装下），即dp[i−1][j−w[i]] + v[i]。 即状态转移方程为1dp[i][j] = max(dp[i−1][j], dp[i−1][j−w[i]]+v[i]) // j &gt;= w[i] 由上述状态转移方程可知，dp[i][j]的值只与dp[i-1][0,...,j-1]有关，所以我们可以采用动态规划常用的方法（滚动数组）对空间进行优化（即去掉dp的第一维）。需要注意的是，为了防止上一层循环的dp[0,...,j-1]被覆盖，循环的时候 j 只能逆向枚举（空间优化前没有这个限制），伪代码为：12345// 01背包问题伪代码(空间优化版)dp[0,...,W] = 0for i = 1,...,N for j = W,...,w[i] // 必须逆向枚举!!! dp[j] = max(dp[j], dp[j−w[i]]+v[i]) 时间复杂度为O(NW), 空间复杂度为O(W)。由于W的值是W的位数的幂，所以这个时间复杂度是伪多项式时间。 动态规划的核心思想避免重复计算在01背包问题中体现得淋漓尽致。第i件物品装入或者不装入而获得的最大价值完全可以由前面i-1件物品的最大价值决定，暴力枚举忽略了这个事实。 2. 完全背包2.1 题目完全背包（unbounded knapsack problem）与01背包不同就是每种物品可以有无限多个：一共有N种物品，每种物品有无限多个，第i（i从1开始）种物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？ 2.2 分析一我们的目标和变量和01背包没有区别，所以我们可定义与01背包问题几乎完全相同的状态dp:1dp[i][j]表示将前i种物品装进限重为j的背包可以获得的最大价值, 0&lt;=i&lt;=N, 0&lt;=j&lt;=W 初始状态也是一样的，我们将dp[0][0…W]初始化为0，表示将前0种物品（即没有物品）装入书包的最大价值为0。那么当 i &gt; 0 时dp[i][j]也有两种情况： 不装入第i种物品，即dp[i−1][j]，同01背包； 装入第i种物品，此时和01背包不太一样，因为每种物品有无限个（但注意书包限重是有限的），所以此时不应该转移到dp[i−1][j−w[i]]而应该转移到dp[i][j−w[i]]，即装入第i种商品后还可以再继续装入第种商品。 所以状态转移方程为1dp[i][j] = max(dp[i−1][j], dp[i][j−w[i]]+v[i]) // j &gt;= w[i] 这个状态转移方程与01背包问题唯一不同就是max第二项不是dp[i-1]而是dp[i]。 和01背包问题类似，也可进行空间优化，优化后不同点在于这里的 j 只能正向枚举而01背包只能逆向枚举，因为这里的max第二项是dp[i]而01背包是dp[i-1]，即这里就是需要覆盖而01背包需要避免覆盖。所以伪代码如下： 12345// 完全背包问题思路一伪代码(空间优化版)dp[0,...,W] = 0for i = 1,...,N for j = w[i],...,W // 必须正向枚举!!! dp[j] = max(dp[j], dp[j−w[i]]+v[i]) 由上述伪代码看出，01背包和完全背包问题此解法的空间优化版解法唯一不同就是前者的 j 只能逆向枚举而后者的 j 只能正向枚举，这是由二者的状态转移方程决定的。此解法时间复杂度为O(NW), 空间复杂度为O(W)。 2.3 分析二除了分析一的思路外，完全背包还有一种常见的思路，但是复杂度高一些。我们从装入第 i 种物品多少件出发，01背包只有两种情况即取0件和取1件，而这里是取0件、1件、2件…直到超过限重（k &gt; j/w[i]），所以状态转移方程为：12# k为装入第i种物品的件数, k &lt;= j/w[i]dp[i][j] = max&#123;(dp[i-1][j − k*w[i]] + k*v[i]) for every k&#125; 同理也可以进行空间优化，需要注意的是，这里max里面是dp[i-1]，和01背包一样，所以 j 必须逆向枚举，优化后伪代码为123456// 完全背包问题思路二伪代码(空间优化版)dp[0,...,W] = 0for i = 1,...,N for j = W,...,w[i] // 必须逆向枚举!!! for k = [0, 1,..., j/w[i]] dp[j] = max(dp[j], dp[j−k*w[i]]+k*v[i]) 相比于分析一，此种方法不是在O(1)时间求得dp[i][j]，所以总的时间复杂度就比分析一大些了，为 $O(NW \\frac W {\\bar{w}})$级别。 2.4 分析三、转换成01背包01背包问题是最基本的背包问题，我们可以考虑把完全背包问题转化为01背包问题来解：将一种物品转换成若干件只能装入0件或者1件的01背包中的物品。 最简单的想法是，考虑到第 i 种物品最多装入 W/w[i] 件，于是可以把第 i 种物品转化为 W/w[i] 件费用及价值均不变的物品，然后求解这个01背包问题。 更高效的转化方法是采用二进制的思想：把第 i 种物品拆成重量为 $w_i 2^k$、价值为 $v_i 2^k$ 的若干件物品，其中 k 取遍满足 $w_i 2^k \\le W$ 的非负整数。这是因为不管最优策略选几件第 i 种物品，总可以表示成若干个刚才这些物品的和（例：13 = 1 + 4 + 8）。这样就将转换后的物品数目降成了对数级别。 3. 多重背包3.1 题目多重背包（bounded knapsack problem）与前面不同就是每种物品是有限个：一共有N种物品，第i（i从1开始）种物品的数量为n[i]，重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？ 3.2 分析一此时的分析和完全背包的分析二差不多，也是从装入第 i 种物品多少件出发：装入第i种物品0件、1件、…n[i]件（还要满足不超过限重）。所以状态方程为：12# k为装入第i种物品的件数, k &lt;= min(n[i], j/w[i])dp[i][j] = max&#123;(dp[i-1][j − k*w[i]] + k*v[i]) for every k&#125; 同理也可以进行空间优化，而且 j 也必须逆向枚举，优化后伪代码为123456// 完全背包问题思路二伪代码(空间优化版)dp[0,...,W] = 0for i = 1,...,N for j = W,...,w[i] // 必须逆向枚举!!! for k = [0, 1,..., min(n[i], j/w[i])] dp[j] = max(dp[j], dp[j−k*w[i]]+k*v[i]) 总的时间复杂度约为 $O(NW{\\bar{n}}) = O(W \\sum_i {n_i})$ 级别。 3.3 分析二、转换成01背包采用2.4节类似的思路可以将多重背包转换成01背包问题，采用二进制思路将第 i 种物品分成了 $O(logn_i)$ 件物品，将原问题转化为了复杂度为 $O(W \\sum_i{logn_i})$ 的 01 背包问题，相对于分析一是很大的改进。 4. 其他情形除了上述三种基本的背包问题外，还有一些其他的变种，如下图所示（图片来源）。 本节列举几种比较常见的。 4.1 恰好装满背包问题有时候还有一个限制就是必须恰好装满背包，此时基本思路没有区别，只是在初始化的时候有所不同。 如果没有恰好装满背包的限制，我们将dp全部初始化成0就可以了。因为任何容量的背包都有一个合法解“什么都不装”，这个解的价值为0，所以初始时状态的值也就全部为0了。如果有恰好装满的限制，那只应该将dp[0,…,N][0]初始为0，其它dp值均初始化为-inf，因为此时只有容量为0的背包可以在什么也不装情况下被“恰好装满”，其它容量的背包初始均没有合法的解，应该被初始化为-inf。 4.2 求方案总数除了在给定每个物品的价值后求可得到的最大价值外，还有一类问题是问装满背包或将背包装至某一指定容量的方案总数。对于这类问题，需要将状态转移方程中的 max 改成 sum ，大体思路是不变的。例如若每件物品均是完全背包中的物品，转移方程即为1dp[i][j] = sum(dp[i−1][j], dp[i][j−w[i]]) // j &gt;= w[i] 4.3 二维背包前面讨论的背包容量都是一个量：重量。二维背包问题是指每个背包有两个限制条件（比如重量和体积限制），选择物品必须要满足这两个条件。此类问题的解法和一维背包问题不同就是dp数组要多开一维，其他和一维背包完全一样，例如5.4节。 4.4 求最优方案一般而言，背包问题是要求一个最优值，如果要求输出这个最优值的方案，可以参照一般动态规划问题输出方案的方法：记录下每个状态的最优值是由哪一个策略推出来的，这样便可根据这条策略找到上一个状态，从上一个状态接着向前推即可。 以01背包为例，我们可以再用一个数组G[i][j]来记录方案，设 G[i][j] = 0表示计算 dp[i][j] 的值时是采用了max中的前一项(也即dp[i−1][j])，G[i][j] = 1 表示采用了方程的后一项。即分别表示了两种策略: 未装入第 i 个物品及装了第 i 个物品。其实我们也可以直接从求好的dp[i][j]反推方案：若 dp[i][j] = dp[i−1][j] 说明未选第i个物品，反之说明选了。 5. LeetCode相关题目本节对LeetCode上面的背包问题进行讨论。 5.1 Partition Equal Subset Sum（分割等和子集）416. Partition Equal Subset Sum（分割等和子集） 题目给定一个只包含正整数的非空数组。问是否可以将这个数组分割成两个子集，使得两个子集的元素和相等。 由于所有元素的和sum已知，所以两个子集的和都应该是sum/2（所以前提是sum不能是奇数），即题目转换成从这个数组里面选取一些元素使这些元素和为sum/2。如果我们将所有元素的值看做是物品的重量，每件物品价值都为1，所以这就是一个恰好装满的01背包问题。 我们定义空间优化后的状态数组dp，由于是恰好装满，所以应该将dp[0]初始化为0而将其他全部初始化为INT_MIN，然后按照类似1.2节的伪代码更新dp：123456int capacity = sum / 2;vector&lt;int&gt;dp(capacity + 1, INT_MIN);dp[0] = 0;for(int i = 1; i &lt;= n; i++) for(int j = capacity; j &gt;= nums[i-1]; j--) dp[j] = max(dp[j], 1 + dp[j - nums[i-1]]); 更新完毕后，如果dp[sum/2]大于0说明满足题意。 由于此题最后求的是能不能进行划分，所以dp的每个元素定义成bool型就可以了，然后将dp[0]初始为true其他初始化为false，而转移方程就应该是用或操作而不是max操作。完整代码如下：1234567891011121314bool canPartition(vector&lt;int&gt;&amp; nums) &#123; int sum = 0, n = nums.size(); for(int &amp;num: nums) sum += num; if(sum % 2) return false; int capacity = sum / 2; vector&lt;bool&gt;dp(capacity + 1, false); dp[0] = true; for(int i = 1; i &lt;= n; i++) for(int j = capacity; j &gt;= nums[i-1]; j--) dp[j] = dp[j] || dp[j - nums[i-1]]; return dp[capacity];&#125; 另外此题还有一个更巧妙更快的解法，基本思路是用一个bisets来记录所有可能子集的和，详见我的Github。 5.2 Coin Change（零钱兑换）322. Coin Change 题目给定一个价值amount和一些面值，假设每个面值的硬币数都是无限的，问我们最少能用几个硬币组成给定的价值。 如果我们将面值看作是物品，面值金额看成是物品的重量，每件物品的价值均为1，这样此题就是是一个恰好装满的完全背包问题了。不过这里不是求最多装入多少物品而是求最少，我们只需要将2.2节的转态转移方程中的max改成min即可，又由于是恰好装满，所以除了dp[0]，其他都应初始化为INT_MAX。完整代码如下：12345678910111213int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; vector&lt;int&gt;dp(amount + 1, INT_MAX); dp[0] = 0; for(int i = 1; i &lt;= coins.size(); i++) for(int j = coins[i-1]; j &lt;= amount; j++)&#123; // 下行代码会在 1+INT_MAX 时溢出 // dp[j] = min(dp[j], 1 + dp[j - coins[i-1]]); if(dp[j] - 1 &gt; dp[j - coins[i-1]]) dp[j] = 1 + dp[j - coins[i-1]]; &#125; return dp[amount] == INT_MAX ? -1 : dp[amount]; &#125; 注意上面1 + dp[j - coins[i-1]]会存在溢出的风险，所以我们换了个写法。 另外此题还可以进行搜索所有可能然后保持一个全局的结果res，但是直接搜索会超时，所以需要进行精心剪枝，剪枝后可击败99%。详见我的Github。 5.3 Target Sum（目标和）494. Target Sum 这道题给了我们一个数组（元素非负），和一个目标值，要求给数组中每个数字前添加正号或负号所组成的表达式结果与目标值S相等，求有多少种情况。 假设所有元素和为sum，所有添加正号的元素的和为A，所有添加负号的元素和为B，则有sum = A + B 且 S = A - B，解方程得A = (sum + S)/2。即题目转换成：从数组中选取一些元素使和恰好为(sum + S) / 2。可见这是一个恰好装满的01背包问题，要求所有方案数，将1.2节状态转移方程中的max改成求和即可。需要注意的是，虽然这里是恰好装满，但是dp初始值不应该是inf，因为这里求的不是总价值而是方案数，应该全部初始为0（除了dp[0]初始化为1）。所以代码如下： 1234567891011121314151617int findTargetSumWays(vector&lt;int&gt;&amp; nums, int S) &#123; int sum = 0; // for(int &amp;num: nums) sum += num; sum = accumulate(nums.begin(), nums.end(), 0); if(S &gt; sum || sum &lt; -S) return 0; // 肯定不行 if((S + sum) &amp; 1) return 0; // 奇数 int target = (S + sum) &gt;&gt; 1; vector&lt;int&gt;dp(target + 1, 0); dp[0] = 1; for(int i = 1; i &lt;= nums.size(); i++) for(int j = target; j &gt;= nums[i-1]; j--) dp[j] = dp[j] + dp[j - nums[i-1]]; return dp[target];&#125; 5.4 Ones and Zeros（一和零）474. Ones and Zeroes 题目给定一个仅包含 0 和 1 字符串的数组。任务是从数组中选取尽可能多的字符串，使这些字符串包含的0和1的数目分别不超过m和n。 我们把每个字符串看做是一件物品，把字符串中0的数目和1的数目看做是两种“重量”，所以就变成了一个二维01背包问题，书包的两个限重分别是 m 和 n，要求书包能装下的物品的最大数目（也相当于价值最大，设每个物品价值为1）。 我们可以提前把每个字符串的两个“重量” w0和w1算出来用数组存放，但是注意到只需要用一次这两个值，所以我们只需在用到的时候计算w0和w1就行了，这样就不用额外的数组存放。完整代码如下： 12345678910111213141516171819202122int findMaxForm(vector&lt;string&gt;&amp; strs, int m, int n) &#123; int num = strs.size(); int w0, w1; vector&lt;vector&lt;int&gt;&gt;dp(m+1, vector&lt;int&gt;(n+1, 0)); for(int i = 1; i &lt;= num; i++)&#123; w0 = 0; w1 = 0; // 计算第i-1个字符串的两个重量 for(char &amp;c: strs[i - 1])&#123; if(c == '0') w0 += 1; else w1 += 1; &#125; // 01背包, 逆向迭代更新dp for(int j = m; j &gt;= w0; j--) for(int k = n; k &gt;= w1; k--) dp[j][k] = max(dp[j][k], 1+dp[j-w0][k-w1]); &#125; return dp[m][n];&#125; 6. 总结本文讨论了几类背包问题及LeetCode相关题目，其中01背包问题和完全背包问题是最常考的，另外还需要注意一些其他变种例如恰好装满、二维背包、求方案总数等等。除了本文讨论的这些背包问题之外，还存在一些其他的变种，但只要深刻领会本文所列的背包问题的思路和状态转移方程，遇到其它的变形问题，应该也不难想出算法。如果想更加详细地理解背包问题，推荐阅读经典的背包问题九讲。 参考 背包问题 - 维基百科 背包问题-笔记整理 动态规划与贪婪法题16：背包问题总结 - CSDN 背包问题九讲2.0 - 崔添翼 更多我的LeetCode中文题解，可前往GitHub查看：https://github.com/ShusenTang/LeetCode","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://tangshusen.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://tangshusen.me/tags/动态规划/"}]},{"title":"Range Sum Query - Mutable (区间查询)","slug":"range-sum-query-mutable","date":"2019-11-17T09:53:12.000Z","updated":"2019-11-18T13:06:12.169Z","comments":true,"path":"2019/11/17/range-sum-query-mutable/","link":"","permalink":"https://tangshusen.me/2019/11/17/range-sum-query-mutable/","excerpt":"本文是LeetCode 307. Range Sum Query - Mutable的题解，主要是对树状数组（Binary Indexed Tree）和线段树（Segment Tree）的学习。","text":"本文是LeetCode 307. Range Sum Query - Mutable的题解，主要是对树状数组（Binary Indexed Tree）和线段树（Segment Tree）的学习。 1. 问题描述初始时给定一个大小为n的整数数组nums，设计两个方法： sumRange(i,j): 求区间[i, j]之间的元素和（0 &lt;= i &lt;= j &lt; n），包含边界; update(i, val): 将nums[i]的值修改为val。 而且假设了上述两个方法的调用是均匀分布的。 2. 题解2.1 初步分析如果数组nums是不可变的，那就是题目303. Range Sum Query - Immutable，是一个很简单的题，我们只需要维护一个累加数组sum, sum[i]表示前i个元素和, 这样以后就可以以常数复杂度获得某个区间的和: sumRange(i,j) = sum[j] - sum[i-1]。如果此题也采用此思路的话，每次调用update(i, val)都需要更新sum, 即update(i, val)的复杂度是O(n)；若采用每次调用sumRange(i,j)才进行求和的策略，虽然update(i, val)复杂度降成常数，但是sumRange(i,j)复杂度变成了O(n)。由于题目说了sumRange和update的调用是均匀分布的，因此上述两种策略在分别m次调用的情况下时间复杂度都是O(mn)，不够高效。 2.2 解法一、折中策略2.2.1 分析2.1节的分析中的两种策略要么让sumRange为O(1)而update为O(n)，要么让sumRange为O(n)而update为O(1)，即两种策略都是不公平的。所以我们很容易想到将复杂度均摊到sumRange和update上，即采取两种策略的折中策略：将原数组分为若干块，为了均摊复杂度，我们让每块长度block = sqrt(n)。然后我们开辟一个大小跟块数（=sqrt(n) 向上取整）相同的二维数组，采用303题的策略提前计算好每个块内部的累加和数组。对于sumRange求区间和操作，我们将i和j之间块的和累加起来(需要考虑两端不足整块的部分)就可以了，由于块数是sqrt(n)（向上取整），所以复杂度是O(sqrt(n))。而在调用update更新的时候，我们先确定要更新的元素在哪个块里，然后只更新该块对应的累加和数组，因为块长度最大为sqrt(n)，所以复杂度还是O(sqrt(n))。因此sumRange和update的复杂度均为O(sqrt(n))，即在分别m次调用的情况下时间复杂度为O(m*sqrt(n))。 2.2.2 代码12345678910111213141516171819202122232425262728293031323334353637383940414243class NumArray &#123; int len, block; // nums长度, 块长度 vector&lt;vector&lt;int&gt;&gt;block_sum; public: NumArray(vector&lt;int&gt;&amp; nums) &#123; len = nums.size(); block = int(sqrt(len)); vector&lt;int&gt;sum; int accum = 0; for(int i = 0; i &lt; len; i++)&#123; accum += nums[i]; sum.push_back(accum); if((i + 1) % block == 0 || i == len - 1)&#123; block_sum.push_back(sum); accum = 0; sum.clear(); &#125; &#125; &#125; void update(int i, int val) &#123; int block_i = i / block, block_j = i % block; // 块号, 块内索引 int diff = val - block_sum[block_i][block_j]; if(block_j != 0) diff += block_sum[block_i][block_j - 1]; for(int j = block_j; j &lt; block_sum[block_i].size(); j++) block_sum[block_i][j] += diff; &#125; int sumRange(int i, int j) &#123; int block_i = i / block, block_j = j / block; // 块号, 块号 int res = 0; for(int k = block_i; k &lt; block_j; k++) res += block_sum[k].back(); // 减去左端多加的部分 if(i % block != 0) res -= block_sum[block_i][i % block - 1]; // 加上右端不足整块的部分 res += block_sum[block_j][j % block]; return res; &#125;&#125;; 2.3 解法二、树状数组2.3.1 树状数组（Binary Indexed Tree）树状数组（Binary Indexed Tree, 又Fenwick Tree）其实并不是一棵树，只是对数组各元素进行逻辑上的划分。根据维基百科，树状数组是一种用于高效计算数列前缀和的数据结构，它可以以O(logn)的时间得到任意前缀和（两个前缀和相减即可得到区间和），并同时支持以O(logn)的时间对数组某个值进行修改，空间复杂度为O(n)。由此可见，我们可以用树状数组解此题，使sumRange和update的复杂度均为O(logn)。因此我们有必要来了解一下树状数组。 从英文名字Binary Indexed Tree可猜到树状数组是与二进制有关的，事实上确实是这样，树状数组的核心思想就是将一个前缀和划分成多个子序列的和，而划分的方法与2的幂（或者说二进制）密切相关。 作为对比，本文讲的三个解法都是对数组先划分成子序列，只是划分的方式不同。2.2节的思路就是无脑将数组均分成大小为sqrt(n)的块；树状数组则采用精心设计的划分方式；而2.4节讲的线段树则是不断进行二分。 举个例子说明这种划分方式，例如想求前13个数（下标从1开始，下同）的前缀和sum(13)，我们可以先看不大于13的最大的2的幂是多少，是2^3=8, 所以先分成第1到第8个数的和；还剩下5个数，又看不大于5的最大的2的幂是多少，是2^2=4，所以再分成第9到第12个数的和；最后还剩下一个数，即第13个数。所以我们有：1sum(13) = Range(1, 8) + Range(9, 12) + Range(13, 13) 其中Range(i,j)就是闭区间[i,j]的区间和。如果按照这种方式划分的话，很显然Range(i,j)中的参数i是可以根据j确定的，例如若j=12那么i一定等于9，我们把这个映射关系记为f(j)。如果我们将上面的数字都转成二进制然后稍加分析就可得到1f(j) = j - lowBit(j) + 1; 其中lowBit(j)表示将j转为二进制后, 最后一个1的位置所代表的数值。例如1j=12 ---二进制--&gt; 1100 ---lowBit--&gt; 0100 ---f(j)--&gt; 1001 学过补码表示的童鞋可以想到lowBit(j)可以通过将j与上-j得到，C++代码即123int lowBit(int j)&#123; return j &amp; (-j);&#125; 那么，我们用一个数组bit（Binary Indexed Tree）来表示经过我们精心设计的划分后的子序列的区间和，其中bit[i]表示区间[f(i), i]的和，如下图所示。 那么bit数组计算好后（先不管如何计算），那么我们该如何计算前缀和以及修改某个元素呢？ 计算前缀和 由前面计算前缀和sum(13)的例子 123sum(13) = Range(1, 8) + Range(9, 12) + Range(13, 13) = bit[8] + bit[12] + bit[13] = bit[13] + bit[12] + bit[8] 可总结出求前缀和的算法： 123456789int sum(int i)&#123; // 前idx个数的和, logn // 这里的i从1开始编号 int res = 0; while(i &gt; 0)&#123; res += bit[i]; i -= lowBit(i); &#125; return res;&#125; 可见可以在log(n)的复杂度求得某个前缀和。 更新元素 由前面的图可知，更新某个元素也是采样类似的思路，只是说是个逆向过程。例如如果想更新nums[1]，对应下标加1为2，由上图可知需要自底向上更新bit[2]、bit[4]、bit[8]；又例如更新nums[4]，对应下标加1为5，应该自底向上更新bit[5]、bit[6]、bit[8]。所以们可总结更新算法如下 123456789void update(int i, int val) &#123; //logn int diff = val - nums[i]; nums[i] = val; i += 1; // bit中下标从1开始 while(i &lt;= nums.size())&#123; bit[i] += diff; i += lowBit(i); &#125; &#125; 可见求前缀和函数sum和更新函数update的唯一不同就是前者是不断减去lowBit(i)而后者是不断加上lowBit(i)。 建树 前面的分析都是建立在我们已经计算好了数组bit的基础上，那么如何计算bit呢？最简单的思路就是先用0初始化bit，然后调用n次update就可以了，此时建树时间复杂度为O(nlogn)。此外，存在一个O(n)时间计算bit的算法： 将bit[i+1]初始化成nums[i]（因为bit下标从1开始）; 对1到n的每一个i，令j = i + lowBit(i)，更新bit[j] = bit[j] + bit[i]。 综上，我们可以用树状数组以对数时间复杂度求前缀和以及更新元素，而两个前缀和相减即可得到区间和，因此sumRange和update的复杂度均为O(logn)，初始建树的时间复杂度最低只需O(n)；我们需要一个bit数组，因此空间复杂度为O(n)。 2.3.2 代码综合前面的分析，我们用如下代码（数组data是nums的复本）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class NumArray &#123;private: vector&lt;int&gt;bit; // bit中下标从1开始, bit[0] = 0 vector&lt;int&gt;data; // copy of nums int lowBit(int x)&#123; return x &amp; (-x); &#125; int sum(int idx)&#123; // logn // 前idx个数的和 int res = 0; while(idx &gt; 0)&#123; res += bit[idx]; idx -= lowBit(idx); &#125; return res; &#125;public: NumArray(vector&lt;int&gt;&amp; nums) &#123; // nlogn bit = vector&lt;int&gt;(nums.size() + 1, 0); // O(nlogn)建树 data = vector&lt;int&gt;(nums.size(), 0); for(int i = 0; i &lt; nums.size(); i++) update(i, nums[i]); // // O(n)建树 // data = nums; // for(int i = 1; i &lt;= nums.size(); i++)&#123; // bit[i] += nums[i-1]; // int j = i + lowBit(i); // if(j &lt;= nums.size()) bit[j] += bit[i]; // &#125; &#125; void update(int i, int val) &#123; //logn int diff = val - data[i]; data[i] = val; i += 1; // bit中下标从1开始 while(i &lt;= data.size())&#123; bit[i] += diff; i += lowBit(i); &#125; &#125; int sumRange(int i, int j) &#123; //logn return sum(j+1) - sum(i); &#125;&#125;; 2.4 解法三、线段树2.4.1 线段树（Segment Tree）和树状数组一样，利用线段树也可以以对数复杂度进行区间查询和元素更新。树状数组是利用索引的二进制表示来划分子序列，而线段树是不断进行二分来划分子序列，如下图所示 1234567 [0,7] ┌───────────────┴───────────────┐ [0,3] [4,7] ┌───────┴───────┐ ┌───────┴───────┐ [0,1] [2,3] [4,5] [6,7] ┌───┴───┐ ┌───┴───┐ ┌───┴───┐ ┌───┴───┐[0,0] [1,1] [2,2] [3,3] [4,4] [5,5] [6,6] [7,7] 可知线段树是一棵二叉树，树中的每个结点保存着一个区间范围以及对应区间和（也可以保存区间最大值、最小值、异或值等等，只要满足结合律就可以了），其左右子结点分别存储该结点区间拆分为两半之后各自区间的信息。 我们就可以自顶向下不断查询得到某个区间和，也可以自底向上地不断更新某个元素对应的叶结点到根结点的路径上的结点值来进行元素更新，由于树高是O(logn)，所以区间查询和元素修改复杂度都是O(logn)。 我们可以采用自顶向下不断递归直到叶结点的建树方式；也可以采用自底向上迭代的建树方式。前者就是普通的线段树，需要不断递归压栈；而后者就是常用的zkw线段树（出自张昆玮的论文《统计的力量》，zkw即其名字拼音首字母），本文采用的是后者。 我们用一个数组st(segment tree)来存放线段树且下标从1开始，先来看看当数据数组nums的大小n刚好是2的幂时的情况，此时最简单，因为构建出来的刚好是一个完美二叉树，如下图所示123456789 st[1] [0,3] ┌───────────┴───────────┐ st[2] st[3] [0,1] [2,3] ┌─────┴─────┐ ┌─────┴─────┐ st[4] st[5] st[6] st[7] [0,0] [1,1] [2,2] [3,3]nums[0] nums[1] nums[2] nums[3] 上图所示的是一棵完美二叉树，叶子数（即数据数组nums的大小4）刚好是2的幂，此时st的大小是2n（算上了无用的st[0]），而且可立即得到第一个叶子结点nums[0]存放在st[4]，第二个叶子结点nums[1]存放在st[5]，以此类推。 即叶子结点对应nums下标刚好与st相差n，其中n是nums的大小。 所以我们很好写出当nums大小刚好是2的幂时的建树代码：12345678// nums的大小n是2的幂时, 建立线段树, 复杂度O(n)void buildST(vector&lt;int&gt;&amp; nums) &#123; for (int i = n; i &lt; n * 2; ++i) st[i] = nums[i - n]; // 叶子 for (int i = n - 1; i &gt; 0; --i) st[i] = st[i &lt;&lt; 1] + st[(i &lt;&lt; 1)|1]; // st[i &lt;&lt; 1]和st[(i &lt;&lt; 1)|1]分别表示左右孩子&#125; 然后自底向上修改某个元素则很简单：12345678910// nums的大小n是2的幂时, 更新元素, 复杂度O(logn)void update(int i, int val) &#123; i += n; // 转成到st的下标 st[i] = val; // 更新叶子 while (i &gt; 0) &#123; // st[i^1]表示st[i]的兄弟 st[i &gt;&gt; 1] = st[i] + st[i^1]; i &gt;&gt;= 1; &#125;&#125; 如何进行自顶向下的区间查询sumRange(i, j)呢？ 若st[i]是右子结点，说明结果应包含它但不包含它的父亲，那么将结果加上st[i]并使i增加1，最后将i除以2进入下一循环； 若st[i]是左子结点，它跟其右兄弟在要求的区间里，则此时直接将i除以2（即直接进入其父亲结点）进入下一循环即可； 对j的处理同理：若j是左子结点，那么需要加上st[j]并使j减去1最后将j除以2进入下一循环；若j是右子结点，直接将j除以2进入下一循环即可。可以通过判断i的奇偶性来判断st[i]是左子结点还是右子结点。12345678910// nums的大小n是2的幂时, 区间查询, 复杂度O(logn)int sumRange(int i, int j) &#123; i += n; j += n; // 转成到st的下标 int res = 0; for (; i &lt;= j; i &gt;&gt;= 1, j &gt;&gt;= 1)&#123; if((i &amp; 1)) res += st[i++]; // st[i]是右子结点 if(!(j &amp; 1)) res += st[j--]; // st[j]是左子结点 &#125; return res;&#125; 上述分析的前提是nums的大小n是2的幂，但是对于一般情况下又是如何呢？ 简单的方法是在nums的结尾补0，直到其长度正好为2的幂。最坏情况下，我们需要大小约为4n的st而不是2n（其实问题也不大，很多人就是这么做的）。例如，若n=17，则我们应该补15个0，开辟大小为64的st。 其实，前面的代码对于任意大小的nums都是正确的! 我们依然只需要开辟一个2n大小的数组st就可以按照上述代码进行建树、查询、更新操作。 二叉树中: 度为0的结点数 = 度为2的结点数 + 1，又因为st中没有度为1的结点，所以只需开辟2n大小的st数组（算上了无用的st[0]）。 例如若n=6，那么建立的st树如下，可以验证一下前面查询、更新操作的代码都是正确的。 123456789101112 st[1] [0,5] ┌───────────┴───────────┐ | st[2] | [2,5] | ┌───────┴───────┐ st[3] st[4] st[5] [0,1] [2,3] [4,5] ┌───┴───┐ ┌───┴───┐ ┌───┴───┐ st[6] st[7] st[8] st[9] st[10] st[11] [0,0] [1,1] [2,2] [3,3] [4,4] [5,5]nums[0] nums[1] nums[2] nums[3] nums[4] nums[5] 另外，线段树还支持区间更新，此时可以开辟一个大小为n的懒标记（lazy tag）数组来提高效率，由于此题并没有涉及，所以不详述。 2.4.2 代码将前面的代码总结一下即可得到完整代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344class NumArray &#123;private: int n; // nums.size() vector&lt;int&gt;st; // segment tree // int leftChild(int r)&#123;return r &lt;&lt; 1;&#125; // int rightChild(int r)&#123;return r &lt;&lt; 1 | 1;&#125; // r &lt;&lt; 1 + 1 void buildST(vector&lt;int&gt;&amp; nums) &#123; for (int i = n; i &lt; n * 2; ++i) st[i] = nums[i - n]; // 叶子 for (int i = n - 1; i &gt; 0; --i) st[i] = st[i &lt;&lt; 1] + st[(i &lt;&lt; 1)|1]; // st[i &lt;&lt; 1]和st[(i &lt;&lt; 1)|1]分别表示左右孩子 &#125; public: NumArray(vector&lt;int&gt;&amp; nums) &#123; n = nums.size(); st = vector&lt;int&gt;(2 * n, 0); buildST(nums); &#125; void update(int i, int val) &#123; i += n; // 转成到st的下标 st[i] = val; while (i &gt; 0) &#123; // st[i^1]表示st[i]的兄弟 st[i &gt;&gt; 1] = st[i] + st[i ^ 1]; i &gt;&gt;= 1; &#125; &#125; int sumRange(int i, int j) &#123; i += n; j += n; // 转成到st的下标 int res = 0; for (; i &lt;= j; i &gt;&gt;= 1, j &gt;&gt;= 1)&#123; if ((i &amp; 1)) res += st[i++]; // st[i]是右子结点 if (!(j &amp; 1)) res += st[j--]; // st[j]是左子结点 &#125; return res; &#125;&#125;; 2.5 总结本文讲的三个解法都是对数组先划分成子序列，只是划分的方式不同。2.2节的折中思路就是无脑将数组均分成大小为sqrt(n)的块，区间查询和单点修改的复杂度都是O(sqrt(n))；树状数组则采用精心设计的划分方式，区间查询和单点修改的复杂度都是O(logn)；而线段树则是不断进行二分，区间查询和单点修改的复杂度也都是O(logn)。 树状数组和线段树的思想很类似，不过也有不同之处，具体区别和联系如下： 树状数组逻辑上是一棵普通的树，而线段树逻辑上是一颗完全二叉树； 两者时间复杂度级别相同, 但是树状数组的常数明显优于线段树而且代码实现简单； 线段树的空间复杂度在常数上为树状数组的两倍； 一般来讲，凡是可以使用树状数组解决的问题, 使用线段树也可以解决, 但是线段树能够解决的问题树状数组未必能够解决（例如求区间最大/小值）； 参考 树状数组（Binary Indexed Tree），看这一篇就够了 - CSDN 树状数组详解 - 博客园 Efficient and easy segment trees - Codeforces 关于线段树(Segment tree)和树状数组(BIT)的区别 - 知乎 更多我的LeetCode中文题解，可前往GitHub查看：https://github.com/ShusenTang/LeetCode","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://tangshusen.me/categories/LeetCode/"}],"tags":[{"name":"树状数组","slug":"树状数组","permalink":"https://tangshusen.me/tags/树状数组/"},{"name":"线段树","slug":"线段树","permalink":"https://tangshusen.me/tags/线段树/"}]},{"title":"动态规划之股票买卖系列","slug":"Buy-and-Sell-Stock","date":"2019-11-03T09:53:05.000Z","updated":"2019-11-21T11:51:19.633Z","comments":true,"path":"2019/11/03/Buy-and-Sell-Stock/","link":"","permalink":"https://tangshusen.me/2019/11/03/Buy-and-Sell-Stock/","excerpt":"股票买卖系列是动态规划的经典题目，Leetcode上有六道关于股票买卖相关的问题，本文对这六道题作一个分析与总结。","text":"股票买卖系列是动态规划的经典题目，Leetcode上有六道关于股票买卖相关的问题，本文对这六道题作一个分析与总结。 1. 总体分析1.1 题意给定一个大小为n的数组prices代表连续n天某支股票的股价，prices[i]即第i天的股价，且必须在买进后才能卖出。再给定一些限制条件，问最大收益。一般有如下几种限制条件，对于LeetCode上六道题： 买卖一次: 121. Best Time to Buy and Sell Stock 不限买卖次数: 122. Best Time to Buy and Sell Stock II 买卖两次: 123. Best Time to Buy and Sell Stock III 买卖k次:188. Best Time to Buy and Sell Stock IV 带有冷却的股票买卖问题:309. Best Time to Buy and Sell Stock with Cooldown 带有交易费用的股票买卖问题:714. Best Time to Buy and Sell Stock with Transaction Fee 1.2 分析前两种情况比较简单，属于LeetCode中的easy题，所以我们考虑普遍情况：可买卖k次。动态规划的关键在于状态以及状态转移方程如何定义。首先考虑影响状态的变量： 当前处于第几天； 已经交易的次数； 手头是否持有股票； 即根据手头是否持有股票，我们定义两个二维数组来定义状态：12dp0[i][j]: 第i天结束，已有j次买卖，手头没有股票时的最大利润dp1[i][j]: 第i天结束，已有j次买卖，手头有股票时的最大利润 因此，dp0[0][j]对于所有j都要初始化为0，而dp1[0][j]对于所有j都要初始化为-prices[i]。如果我们将dp0所有值都求出来了，那么很明显dp0[n-1][k]就是在最后一天结束时已进行k次交易且手头无股票时的最大收益，也即返回结果。先看初始状态: 当i==0 &amp;&amp; j&gt;=0: dp0[0][j] = 0, dp1[0][j] = -prices[0]; 当i&gt;0 &amp;&amp; j==0: dp0[i][0] = 0, dp1[i][0] = max(dp1[i-1][0], -prices[i]); 再来考虑状态转移方程，当i&gt;0且j&gt;0时有12dp0[i][j] = max(dp0[i-1][j], dp1[i-1][j-1] + prices[i]) # 保持 or 卖出dp1[i][j] = max(dp1[i-1][j], dp0[i-1][j] - prices[i]) # 保持 or 买入 有了状态定义及转移方程，剩下就好办了。接下来针对具体问题具体分析。 2. 具体分析2.1 买卖一次121. Best Time to Buy and Sell Stock 此题比较简单，可以不按照上述思考进行分析。要想获益最大，肯定是低价买入高价卖出，所以最简单的方法就是从前向后遍历数组，记录当前出现过的最低价格cur_min_price，作为买入价格，并计算以当天价格出售的收益，作为可能的最大收益，整个遍历过程中，出现过的最大收益就是所求。此代码略。 我们看看此题对应1.2节分析的情况，此时只能买卖一次，k = 1，此时代码就为12345678910111213141516171819int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; vector&lt;vector&lt;int&gt;&gt;dp0(n, vector&lt;int&gt;(2, 0)); vector&lt;vector&lt;int&gt;&gt;dp1(n, vector&lt;int&gt;(2, 0)); dp1[0][0] = -prices[0]; for(int i = 1; i &lt; n; i++)&#123; // j = 0 dp1[i][0] = max(dp1[i-1][0], -prices[i]); // j=1 dp0[i][1] = max(dp0[i-1][1], dp1[i-1][0] + prices[i]); // 保持 or 卖出 // dp1[i][1] = max(dp1[i-1][1], dp0[i-1][1] - prices[i]); &#125; return dp0[n-1][1];&#125; 代码中注释部分是一些没有必要的部分，另外空间还可以进行优化，因为dp[i]只与dp[i-1]有关，所以i这一维是没必要的。这是动态规划空间复杂度优化的常用思路，优化后的代码如下：12345678910111213141516171819int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; vector&lt;int&gt;dp0(2, 0); vector&lt;int&gt;dp1(2, 0); dp1[0] = -prices[0]; for(int i = 1; i &lt; n; i++)&#123; int tmp = dp1[0]; // j = 0 dp1[0] = max(dp1[0], -prices[i]); // j=1 dp0[1] = max(dp0[1], tmp + prices[i]); // 保持 or 卖出 &#125; return dp0[1];&#125; 由于此题比较简单，所以上述代码显得有些繁琐，其实有更加简洁的动态规划方法解此题：定义dp[i]代表”在第i天卖出时的最大获益”，则dp[i]的值该如何得到？根据在哪一天买入我们可以分成两种情况： 在第i天买入在第i天卖出； 在第i天前某一天买入在第i天卖出； 对于第1种情况，即在同一天买入卖出，获益0；对于第2种情况，因为dp[i-1]代表在第i-1天卖出时的最大获益，那如果我在第i-1天不卖而是在第i天卖不就是这种情况下的最大获益吗，此时获益为dp[i-1] + prices[i] - prices[i-1]。所以状态转移方程为1dp[i] = max(0, dp[i-1] + prices[i] - prices[i-1]) 在从前往后更新dp时我们还需要用一个变量记录全局的最大获益，时空复杂度均为O(n)。代码如下：1234567891011int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() == 0) return 0; vector&lt;int&gt;dp(prices.size(), 0); int max_profit = 0; for(int i = 1; i &lt; prices.size(); i++)&#123; dp[i] = max(0, prices[i] - prices[i-1] + dp[i-1]); max_profit = max(max_profit, dp[i]); &#125; return max_profit;&#125; 从状态转移方程看出，dp[i-1]只与前一天dp[i-1]有关，所以也可采取前面类似的思路对空间进行优化，优化后代码如下：1234567891011int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size() == 0) return 0; int dp = 0; int max_profit = 0; for(int i = 1; i &lt; prices.size(); i++)&#123; dp = max(0, prices[i] - prices[i-1] + dp); max_profit = max(max_profit, dp); &#125; return max_profit;&#125; 2.2 不限买卖次数122. Best Time to Buy and Sell Stock II 此时不考虑买卖次数，所以我们采用1.2分析的话dp数组就只需要两维:12dp0[i]: 第i天结束，手头没有股票时的最大利润dp1[i]: 第i天结束，手头有股票时的最大利润 此时代码如下：1234567891011121314int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; vector&lt;int&gt;dp0(n, 0); vector&lt;int&gt;dp1(n, 0); dp1[0] = -prices[0]; for(int i = 1; i &lt; n; i++)&#123; dp0[i] = max(dp0[i-1], dp1[i-1] + prices[i]); dp1[i] = max(dp1[i-1], dp0[i-1] - prices[i]); &#125; return dp0[n-1];&#125; 同理，这里空间也可优化，这里就不贴代码了。 类似上一题，此题比较简单，所以采用1.2的思路显得很繁琐，有更加简洁的动归方法：用dp[i]代表”在第i天卖出时的最大获益”（那么此时dp[i]肯定是单调增数组），状态转移方程为1dp[i] = dp[i-1] + max(0, prices[i] - prices[i-1]) 在更新完毕后，dp[n-1]即最终结果，时空复杂度均为O(n)。我们依然可以采用上一题提到的方法将空间复杂度优化到常数，代码如下。1234567891011int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; int dp = 0; int max_profit = 0; for(int i = 1; i &lt; n; i++) dp = dp + max(0, prices[i] - prices[i-1]); return dp;&#125; 2.3 买卖两次123. Best Time to Buy and Sell Stock III 此题要求最多买买两次，即k=2，按照1.2的分析，我们有代码：1234567891011121314151617181920int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; vector&lt;vector&lt;int&gt;&gt;dp0(n, vector&lt;int&gt;(3, 0)); vector&lt;vector&lt;int&gt;&gt;dp1(n, vector&lt;int&gt;(3, 0)); dp1[0][0] = -prices[0]; dp1[0][1] = -prices[0]; // i = 0 for(int i = 1; i &lt; n; i++)&#123; dp1[i][0] = max(dp1[i-1][0], -prices[i]); // j = 0 // j = 1 dp0[i][1] = max(dp0[i-1][1], dp1[i-1][0] + prices[i]); // 保持 or 卖出 dp1[i][1] = max(dp1[i-1][1], dp0[i-1][1] - prices[i]); // 保持 or 买入 // j = 2 dp0[i][2] = max(dp0[i-1][2], dp1[i-1][1] + prices[i]); // 保持 or 卖出 // dp1[i][2] = max(dp0[i-1][2], dp0[i-1][2] - prices[i]); // 保持 or 买入 &#125; return dp0[n-1][2];&#125; 代码中注释部分是一些没有必要的部分，另外空间也可以进行优化，优化后的代码就不贴了。 此题还有一个常见的解法，将在2.4节介绍。 2.4 买卖k次188. Best Time to Buy and Sell Stock IV 此时就是1.2节分析的一般情况了，代码如下：1234567891011121314151617181920212223242526int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n || !k) return 0; if (k &gt; n / 2) &#123; // 当k很大时相当于不限制次数 int res = 0; int hold = prices[0]; for (int i = 1; i &lt; n; i++) res += max(0, prices[i] - prices[i - 1]); return res; &#125; vector&lt;vector&lt;int&gt;&gt;dp0(n, vector&lt;int&gt;(k+1, 0)); vector&lt;vector&lt;int&gt;&gt;dp1(n, vector&lt;int&gt;(k+1, 0)); for(int j = 0; j &lt;= k; j++) dp1[0][j] = -prices[0]; // i = 0 for(int i = 1; i &lt; n; i++)&#123; dp1[i][0] = max(dp1[i-1][0], -prices[i]); // j = 0 for(int j = 1; j &lt;= k; j++)&#123; // j &gt; 0 dp0[i][j] = max(dp0[i-1][j], dp1[i-1][j-1] + prices[i]); // 保持 or 卖出 dp1[i][j] = max(dp1[i-1][j], dp0[i-1][j] - prices[i]); // 保持 or 买入 &#125; &#125; return dp0[n-1][k];&#125; 需要注意的是，LeetCode给了非常极端的测试样例，就是 k 非常大，但是我们稍加思考就知道当k &gt; n/2 时就相当于不限制买卖次数了，因为我们最多进行n/2次有效的买卖，即第0天买第1天卖、第2天买第3天卖…，所以在上面代码中，我们先判断是否满足k &gt; n/2，若是则直接按照不限制次数（2.2节）的思路返回结果。 前面提到，由于当前状态的值只与上一个状态有关，所以我们可以进行空间优化，优化后空间复杂度为O(k)，代码如下：12345678910111213141516171819202122232425262728int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); // k = min(n / 2, k); if(!n || !k) return 0; if (k &gt; n / 2) &#123; // 当k很大时相当于不限制次数 int res = 0; int hold = prices[0]; for (int i = 1; i &lt; n; i++) res += max(0, prices[i] - prices[i - 1]); return res; &#125; vector&lt;int&gt;dp0(k+1, 0); vector&lt;int&gt;dp1(k+1, 0); for(int j = 0; j &lt;= k; j++) dp1[j] = -prices[0]; for(int i = 1; i &lt; n; i++)&#123; dp1[0] = max(dp1[0], -prices[i]); // j = 0 for(int j = 1; j &lt;= k; j++)&#123; // j &gt; 0 int pre_dp0 = dp0[j]; // 上一次循环的dp0[j]备份 dp0[j] = max(dp0[j], dp1[j-1] + prices[i]); // 保持 or 卖出 dp1[j] = max(dp1[j], pre_dp0 - prices[i]); // 保持 or 买入 &#125; &#125; return dp0[k];&#125; 此外，此题还有一个常见的解法，也是用两个动归数组：local和global，意义如下：12local[i][j]: 已买卖j次且在最后一次是在i天卖出的最大获益；global[i][j]: 截止到第i天，买卖j次的最大获益； 在进行状态计算时只可能有两种情况： 保持现状（或理解成在第i天买入后当天就卖出） 在第i天前某一天买入，在第i天卖出； 所以状态转移方程为12local[i][j] = max(global[i-1][j-1], prices[i] - prices[i-1] + local[i-1][j]); // 情况1 or 情况2global[i][j] = max(global[i-1][j], local[i][j]); 所以代码如下（进行了空间优化）：12345678910111213141516171819202122int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n || !k) return 0; if (k &gt; n / 2) &#123; // 当k很大时相当于不限制次数 int res = 0; int hold = prices[0]; for (int i = 1; i &lt; n; i++) res += max(0, prices[i] - prices[i - 1]); return res; &#125; vector&lt;int&gt;local(k+1, 0); vector&lt;int&gt;global(k+1, 0); for(int i = 1; i &lt; n; i++)&#123; for(int j = 1; j &lt;= k; j++)&#123; local[j] = max(global[j-1], prices[i] - prices[i-1] + local[j]); global[j] = max(global[j], local[j]); &#125; &#125; return global[k];&#125; 以上两种解法都很巧妙，注意区别与联系。 2.5 带有冷却的股票买卖问题309. Best Time to Buy and Sell Stock with Cooldown 这道题在买卖不受限制题目的基础上，加了新的限制：卖出后必须至少隔一天才能继续买，也即新增了一个状态：”处于冷却期”。此时，”手头有股票”只能从”处于冷却期”转移而来，而不是之前那样从”手头无股票”转移而来。我们需要开辟三个动归数组:123dp0[i]: 第i天结束，手头没有股票时的最大利润dp1[i]: 第i天结束，手头有股票时的最大利润cool[i]: 第i天结束且第i天处于冷冻期时的最大利润 状态转移方程为：123dp0[i] = max(dp0[i-1], dp1[i-1] + prices[i]); // 保持 or 卖出dp1[i] = max(dp1[i-1], cool[i-1] - prices[i]); // 保持 or (冷却 -&gt; 买入)cool[i] = max(cool[i-1], dp0[i-1]); // 第i-1天结束时没有股票说明第i天可以是冷却期 所以有如下代码（进行了空间优化）：123456789101112131415161718192021222324int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int n = prices.size(); if(!n) return 0; // vector&lt;int&gt;dp0(n, 0); // vector&lt;int&gt;dp1(n, 0); // vector&lt;int&gt;cool(n, 0); // dp1[0] = - prices[0]; // i = 0 // for(int i = 1; i &lt; n; i++)&#123; // dp0[i] = max(dp0[i-1], dp1[i-1] + prices[i]); // dp1[i] = max(dp1[i-1], cool[i-1] - prices[i]); // cool[i] = max(cool[i-1], dp0[i-1]); // &#125; // return dp0[n-1]; // 空间优化后: int dp0 = 0, dp1 = - prices[0], cool = 0; for(int i = 1; i &lt; n; i++)&#123; int pre_dp0 = dp0; dp0 = max(dp0, dp1 + prices[i]); dp1 = max(dp1, cool - prices[i]); cool = max(cool, pre_dp0); &#125; return dp0;&#125; 2.6. 带有交易费用的股票买卖问题714. Best Time to Buy and Sell Stock with Transaction Fee 这道题在买卖不受限制题目的基础上，加了新的条件：每买卖一次需要交一次交易费用。那其实在买卖不受限制题目的基础上，唯一需要改变的就是在卖出（或买入）的时候减去交易费用。代码如下（进行了空间优化）：1234567891011121314151617181920212223int maxProfit(vector&lt;int&gt;&amp; prices, int fee) &#123; int n = prices.size(); if(!n) return 0; // vector&lt;int&gt;dp0(n, 0); // vector&lt;int&gt;dp1(n, 0); // dp1[0] = - prices[0]; // i = 0 // for(int i = 1; i &lt; n; i++)&#123; // // 唯一和122不限次数不同就是减去fee // dp0[i] = max(dp0[i-1], dp1[i-1] + prices[i] - fee); // dp1[i] = max(dp1[i-1], dp0[i-1] - prices[i]); // &#125; // return dp0[n-1]; // 空间优化: int dp0 = 0, dp1 = - prices[0]; for(int i = 1; i &lt; n; i++)&#123; int pre_dp0 = dp0; // 唯一和122不限次数不同就是减去fee dp0 = max(dp0, dp1 + prices[i] - fee); dp1 = max(dp1, pre_dp0 - prices[i]); &#125; return dp0;&#125; 3 总结以上六道题就是 LeetCode 当中股票系列的全部内容，此类问题关键就是如何定义状态及状态转移方程，上述设定状态和定义转移方程的思想是可以复用到其他类型的动归问题当中去的，总的来说就是根据有所有不确定的变量（例如这里就是手头是否持有股票等）来定义状态，根据当前状态和之前状态的关系来确定转移方程，这个需要平时的积累和大量的刷题练习。另外上面用到的空间优化方法是动归里很常用的方法，务必掌握。 参考文献[1] 股票问题汇总.[2]【Leetcode 动态规划】 买卖股票 I II III IV 冷却，共5题. 更多我的LeetCode中文题解，可前往GitHub查看：https://github.com/ShusenTang/LeetCode","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://tangshusen.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://tangshusen.me/tags/动态规划/"}]},{"title":"TensorFlow AttentionWrapper源码超详细图解","slug":"tf-attention","date":"2019-03-09T10:37:19.000Z","updated":"2019-03-13T05:56:32.843Z","comments":true,"path":"2019/03/09/tf-attention/","link":"","permalink":"https://tangshusen.me/2019/03/09/tf-attention/","excerpt":"Attention在seq2seq模型中是一个很有用的机制，由于TensorFlow烂成翔的官方文档以及网上很少而且晦涩难懂的教程，我在如何正确使用TensorFlow现成attention接口上面费了很大一番功夫。本文用详细图解的方式清晰展现了其源代码构成，方便大家学习使用。本文会先简略的介绍一下seq2seq attention的原理，然后详细剖析TensorFlow相关的源代码，懒得看文字分析的可以直接跳到2.7节看图。","text":"Attention在seq2seq模型中是一个很有用的机制，由于TensorFlow烂成翔的官方文档以及网上很少而且晦涩难懂的教程，我在如何正确使用TensorFlow现成attention接口上面费了很大一番功夫。本文用详细图解的方式清晰展现了其源代码构成，方便大家学习使用。本文会先简略的介绍一下seq2seq attention的原理，然后详细剖析TensorFlow相关的源代码，懒得看文字分析的可以直接跳到2.7节看图。 1. 原理简介1.1 seq2seqseq2seq是”Sequence to Sequence”的简写，seq2seq模型的核心就是编码器（Encoder）和解码器（Decoder）组成的，该架构相继在论文[1][2]提出，后来[3]又提出了在seq2seq结构中加入Attention机制，使seq2seq的性能大大提升，现在seq2seq被广泛地用于机器翻译、对话生成、人体姿态序列生成等各种任务上，并取得了非常好的效果。 图1.1 seq2seq基本结构 未加入attention机制的seq2seq基本模型如上图所示，左侧的RNN编码器将输入编码成一个中间状态c向量，右侧的解码器在每一个时间步都会接收c的输入然后进行解码，得到输出结果。例如如果编码器的输入为“我爱你”，编码器的期望输出为“I love you”，那么seq2seq就实现了翻译任务，以上就是最基本的seq2seq模型原理。 1.2 attention仔细观察图1.1所示的模型就可以发现一个问题，c向量是连接编码器和解码器唯一的桥梁，那么c向量中必须包含了原始序列中的所有信息，当编码器输入序列很长的时候，由于RNN并不能很好地对很长的序列进行建模，c向量就很难囊括输入序列所有信息了，此时解码器也就很难正确地生成了。 Attention机制解决了这个问题，它可以使得在输入序列长的时候精确率也不会有明显下降，它是怎么做的呢？既然一个c向量存不了，那么就引入多个c向量: $c_1, c_2, …$，称为context vector。 图1.2 带attention的seq2seq结构 带attention的seq2seq结构如图1.2所示，attention机制跟人类翻译句子时候的思路有些类似，即将注意力关注于我们翻译词语对应的上下文（context）。而 $c_i$ 就存放了此刻输入的上下文信息，这样当解码器解码到第 $i$ 步的时候通过分析此时输入序列的上下文信息即可精准地进行解码。 下面用公式化的语言叙述一下加入attention与否的seq2seq结构。在没有引入attention之前，编码器在某个时刻解码的时候实际上是依赖于三个部分的（图1.1没有画出），首先我们知道RNN中，每次输出结果会依赖于隐藏态和输入（在训练过程中这个输入就是ground truth，在测试时这个输入就是上一步的输出），在seq2seq模型中，还需要依赖于c向量，所以这里我们设在 $i$ 时刻，解码器解码的期望输出是 $y_i$，上一次解码结果（的ground truth）是 $y_{i-1}$，此时刻隐藏态是 $h_i’$，所以它们满足这样的关系：$$y_i = f(y_{i-1}, h_i’, c) \\tag{1.1}$$即每次的解码输出是上一个隐藏态和上一个输出结果和c向量共同计算得出的。 那么加入attention机制后，将每时刻固定的c向量换成 $c_i$，有$$y_i = f(y_{i-1}, h_i’, c_i) \\tag{1.2}$$ 那么上下文信息 $c_i$ 是怎么计算得来的呢？目前常用的两种方式就是Bahdanau attention[3]和Luong attention[4]，下面就分别来介绍一下。 1.2.1 Bahdanau attention假设编码器的所有时刻的隐藏态（hidden state）为 $h_1, h_2, …, h_{T_x}$，则有$$c_i = \\sum_{j = 1}^{T_x} \\alpha_{ij}h_j \\tag{1.3}$$这里 $\\alpha_{ij}$ 为每一个编码器输出的隐藏态 $h_j$ 被分配到的权重，它的值越大代表对编码器 $j$ 时刻输入的注意力就越大。而 $\\alpha_{ij}$ 的计算法方式如下：$$\\alpha _ { i j } = \\frac { \\exp \\left( e _ { i j } \\right) } { \\sum _ { k = 1 } ^ { T _ { x } } \\exp \\left( e _ { i k } \\right) } \\tag{1.4}$$$$e _ { i j } = a \\left( h_{i-1}’ , h _ { j } \\right) = v _ { a } ^ { T } \\tanh \\left( \\boldsymbol{W_a} h_{i-1}’ + \\boldsymbol{U_ a} h _ { j } \\right) \\tag{1.5}$$也就是说，权重 $\\alpha_{ij}$ 就是解码器隐藏态 $h_{i-1}’$ 和编码器隐藏态 $h_j$ 计算得到一个数值 $e_{ij}$ （一般称为得分，score）再经过softmax归一化得到的。 1.2.2 Luong attentionLuong attention[4]与Bahdanau attention最大的不同就是计算得分的方式不同，论文[4]中给出了一下三种计算方式：$$e_{ij} = \\text{score} (h_i’, h_j) = \\begin{cases} \\begin{array} { l l } { h_i’^ { \\top } h_j } &amp; { \\text { dot } } \\\\{ h_i’^ { \\top } \\boldsymbol {W_a} h_j } &amp; { \\text { general } } \\\\ { v_a ^ { \\top } \\tanh \\left( \\boldsymbol { W_a } \\left[ h_i’ ; h_j \\right] \\right) } &amp; { \\text { concat} } \\end{array} \\end{cases} \\tag{1.6}$$常用的计算方式就是式 $(1.6)$ 中的”general”，即用 $\\boldsymbol { W_a }$ 统一 $h_i$ 和 $h_j$ 的维度再作內积（”dot”相当于是”general”的特殊情况，即 $h_i$ 和 $h_j$ 的维度已经统一了）。 1.2.3 小节综上，attention机制的大致原理就是通过在解码的每一步计算一下此刻应该对编码器每时刻的输入赋予多少注意力，然后再有针对性地进行解码。但除了计算分数的方式有很多方式，attention的具体细节花样还有很多，例如是否将解码器前一步得到的 $c_{i-1}$ 作为此刻解码器的输入，是否将编码器所有隐藏态都参与注意力计算等等。下一节我们通过对TensorFlow的源码进行剖析来看看TensorFlow是怎么实现的。 2. TensorFlow源码剖析2.1 概览在TensorFlow中，Attention 的相关实现代码是在tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py文件中，这里面我们需要关注的有如下几个类： AttentionMechanism: 所有attention机制的父类，内部没有任何实现。 _BaseAttentionMechanism: 继承自AttentionMechanism，定义了attention机制的一些公共方法实现和属性。 BahdanauAttention和LuongAttention：均继承自_BaseAttentionMechanism，分别实现了1.2节所述的两种attention机制。 AttentionWrapper: 用于封装RNNCell的类，继承自RNNCell，所以被它封装后依然是一个RNNCell类，只不过是带了attention的功能。 AttentionWrapperState：用来存放计算过程中的state，前面说了AttentionWrapper其实也是一个RNNCell，那么它也有隐藏态（hidden state）信息，AttentionWrapperState就是这个state。除了RNN cell state，其中还额外存放了一些信息。 此外还有_BaseMonotonicAttentionMechanism、BahdanauMonotonicAttention、LuongMonotonicAttention以实现单调（monotonic）attention机制，以及一些公共的方法，如_luong_score、_bahdanau_score、_prepare_memory等等。 在进一步分析之前，我们先来明确代码中一些术语的意思： key &amp; query: Attention的本质可以被描述为一个查询（query）与一系列（键key-值value）对一起映射成一个输出：将query和每个key进行相似度计算得到权重并进行归一化，将权重和相应的键值value进行加权求和得到最后的attention，这里key=value。简单理解就是，query相当于前面说的解码器的隐藏态 $h_i’$ ，而key就是编码器的隐藏态 $h_i$。 memory: 这个memory其实才是编码器的所有隐藏态，与前面的key区别就是key可能是memory经过处理（例如线性变换）后得到的。 alignments: 计算得到的每步编码器隐藏态 $h$ 的权重向量，即 $[\\alpha_{i1}, \\alpha_{i2},…, \\alpha_{iT_x}]$。 后面会遇到这些术语，如果现在还不是很懂的可以结合后面再仔细看看。 我们先来分析分析这些类，然后2.7节给出了整个AttentionWrapper的代码流程图。 2.2 _BaseAttentionMechanism先来看看最基础的attention类_BaseAttentionMechanism。它的初始化方法如下：123456789def __init__(self, query_layer, memory, probability_fn, memory_sequence_length=None, memory_layer=None, check_inner_dims_defined=True, score_mask_value=None, name=None): 这里有很多参数，下面一一说明这些参数的作用： query_layer: 一个tf.layers.Layer实例，query会首先经过这一层； memory: 解码时用到的所有上下文信息，可简单理解为编码器的所有隐藏态，维度一般为[batch, max_time, enc_rnn_size]； probability_fn: 将score $e_{ij}$ 计算成概率用的函数，默认使用softmax，还可以指定hardmax等函数； memory_sequence_length: 即memory变量的实际长度信息，类似dynamic_rnn中的sequence_length，维度为[batch]，这会被用作mask来去除超过实际长度的无用信息； memory_layer: 类似query_layer，也是一个tf.layers.Layer实例（或None），memory会经过这一层然后得到keys。需要注意的是，（经过memory_layer处理后得到的）key应该和（经过query_layer处理得到的）query的维度相匹配，用式$(1.5)$为例就是 $W_a h_{i-1}’$ 要和 $U_ah_j$ 的维度要一致，不然没法相加。 check_inner_dims_defined: bool型，是否检查memory除了最外面两维其他维度是否是有定义的。 score_mask_value: 在使用probability_fn计算概率之前，对score预先进行mask使用的值，默认是负无穷。但这个只有在memory_sequence_length参数定义的时候有效。 其构造函数完成的主要功能就是将输入的memory进行mask然后经过memory_layer处理称为keys方便后面使用，如下面代码所示：123self._values = _prepare_memory(memory, memory_sequence_length, check_inner_dims_defined=check_inner_dims_defined)self._keys = (self.memory_layer(self._values) if self.memory_layer else self._values) 2.3 BahdanauAttentionBahdanauAttention是继承自2.2节的_BaseAttentionMechanism，它的构造函数如下所示：123456789def __init__(self, num_units, memory, memory_sequence_length=None, normalize=False, probability_fn=None, score_mask_value=None, dtype=None, name=\"BahdanauAttention\"): 这些参数中，除了num_units和normalize其他都在_BaseAttentionMechanism出现过这里不再赘述。先说一下num_units，我们知道在计算式$(1.5)$的时候，需要使用 $h_{i-1}’$ 和 $h_i$ 来进行计算，而二者的维度可能并不是统一的，需要进行变换和统一，所以就有了 $W_a$ 和 $U_a$ 这两个系数，对应在代码中就是用num_units来声明了两个全连接 Dense 网络，用于统一二者的维度：12345678super(BahdanauAttention, self).__init__( query_layer=layers_core.Dense(num_units, name=\"query_layer\", use_bias=False, dtype=dtype), memory_layer=layers_core.Dense(num_units, name=\"memory_layer\", use_bias=False, dtype=dtype), memory=memory, probability_fn=wrapped_probability_fn, memory_sequence_length=memory_sequence_length, score_mask_value=score_mask_value, name=name) 即这里的num_units设置成任何值都可以，它确定了需要传进其父类_BaseAttentionMechanism构造函数的参数query_layer和memory_layer。 然后normalize即是否要在计算分数score时实现标准化，出自论文[5]，默认设为False。这个参数在接下来要说的__call__方法中用到。 接下来就是__call__方法了:1234567def __call__(self, query, state): with variable_scope.variable_scope(None, \"bahdanau_attention\", [query]): processed_query = self.query_layer(query) if self.query_layer else query score = _bahdanau_score(processed_query, self._keys, self._normalize) # 前面定义了query_layer是一个Dense层 alignments = self._probability_fn(score, state) next_state = alignments return alignments, next_state 输入的是query和state(先不管这里的state是啥)，然后先把query用query_layer（即前面说的全连接层）进行处理，然后再按照Bahdanau Attention的规则调用函数_bahdanau_score计算分数score，这个计算过程中可设置是否需要标准化。得到分数后再调用_probability_fn(这里就是softmax，所以第二个参数state没有用到)计算得到权重向量alignments，然后最后返回的next_state其实也是这个alignments，所以__call__的参数state其实就是上个时间步的alignments向量。 总结一下就是，BahdanauAttention（调用__call__）就是根据此刻的query（即 $h_i’$）和每个key根据式 $(1.4)(1.5)$ 计算得到每个key的权重 alignments。 2.4 LuongAttentionLuongAttention同样是继承自2.2节的_BaseAttentionMechanism，它的构造函数如下所示：123456789def __init__(self, num_units, memory, memory_sequence_length=None, scale=False, probability_fn=None, score_mask_value=None, dtype=None, name=\"LuongAttention\"): 出现了一个新参数scale，该参数在计算分数的函数_luong_score中会用到，代表是否对得到的分数进行scale操作。2.3节中提到BahdanauAttention构造函数中参数num_units设置成任何值都可以，但是这里并不是这样，因为：12345678super(LuongAttention, self).__init__( query_layer=None, memory_layer=layers_core.Dense(num_units, name=\"memory_layer\", use_bias=False, dtype=dtype), memory=memory, probability_fn=wrapped_probability_fn, memory_sequence_length=memory_sequence_length, score_mask_value=score_mask_value, name=name) 注意这里只传入了memory_layer（对应式$(1.6)$中的 $\\boldsymbol { W_a }$），所以只对memory（即 式子$(1.6)$中的 $h_j$）进行了变换得到 $\\boldsymbol {W_a}h_j$，因此这里num_units必须等于query的深度（即query.get_shape()[-1]）。 总结一下，和BahdanauAttention类似的，LuongAttention（调用__call__）就是根据此刻的query（即 $h_i’$）和每个key根据式 $(1.6)(1.4)$ 计算得到每个key的权重 alignments。和BahdanauAttention不同的是这里要合理设置参数 num_units否则query和key维度不匹配。 2.5 AttentionWrapperState接下来我们再看下 AttentionWrapperState 这个类，这个类其实类似RNNCell有隐藏态（hidden state），就是定义了attention计算过程中可能需要保存的变量，如 cell_state（这个cell_state就是被AttentionWrapper包裹的内部RNNCell的隐藏态）、attention、time、alignments 等内容，同时也便于后期的可视化呈现，代码实现如下：1234class AttentionWrapperState( collections.namedtuple(\"AttentionWrapperState\", (\"cell_state\", \"attention\", \"time\", \"alignments\", \"alignment_history\", \"attention_state\"))): 可见它就是继承了namedtuple这个数据结构，其实可以把这个 AttentionWrapperState看成一个结构体，可以传入需要的字段生成这个对象。 2.6 AttentionWrapper为了方便使用了attention，TensorFlow提供了一个wrapper，这和其他的Wrapper例如DropoutWrapper、ResidualWrapper 等等类似，它们都是 RNNCell的实例。即AttentionWrapper它对RNNCell进行了封装，封装后依然还是RNNCell的实例。如果你想给一个普通的RNN模型加入attention功能，只需要在RNNCell外面套一层AttentionWrapper并指定 AttentionMechanism的实例就好了。 我们还是来看看其构造函数：1234567891011class AttentionWrapper(rnn_cell_impl.RNNCell): def __init__(self, cell, attention_mechanism, attention_layer_size=None, alignment_history=False, cell_input_fn=None, output_attention=True, initial_cell_state=None, name=None, attention_layer=None): 下面对其参数一一说明： cell: 被包裹的RNNCell实例； attention_mechanism: attention机制实例，例如BahdanauAttention，也可以是多个attention实例组成的列表； attention_layer_size: 是数字或者数字做成的列表，如果是 None（默认），直接使用加权求和得到的上下文向量 $c_i$ 作为输出（详见本小节最后的_compute_attention代码），如果不是None，那么将 $c_i$ 和cell的输出 cell_output进行concat并做线性变换（输出维度为attention_layer_size）再输出。 这里所说的”输出”在代码里是用”attention”表示的，见本小节最后的_compute_attention函数代码。 alignment_history: 即是否将之前的alignments存储到 state 中，以便于后期进行可视化展示，默认False，一般设置为True。 cell_input_fn: 怎样处理输入。默认会将上一步的得到的输出与的实际输入进行concat操作作为输入。代码： 12if cell_input_fn is None: cell_input_fn = (lambda inputs, attention: array_ops.concat([inputs, attention], -1)) output_attention: 默认false，如果为true，则输出不是attention的计算结果，而是cell得到的cell_output。 initial_cell_state: 初始状态，默认即可。 attention_layer: 这个参数其实是和attention_layer_size是互斥的，如果设置了attention_layer_size不为None，那么这个参数必须为None。因为他俩功能类似，它也可以是一个tf.layers.Layer的列表，定义输出要经过的变换。若为None，直接使用加权求和得到的上下文向量 $c_i$ 作为输出，如果不是None，那么将 $c_i$ 和cell的输出 cell_output进行concat再经过attention_layer后输出。 构造函数中关于attention_layer的代码如下：123456789101112131415161718192021222324252627if attention_layer_size is not None: attention_layer_sizes = tuple(attention_layer_size if isinstance(attention_layer_size, (list, tuple)) else (attention_layer_size,)) self._attention_layers = tuple(layers_core.Dense( attention_layer_size, name=\"attention_layer\", use_bias=False, dtype=attention_mechanisms[i].dtype) for i, attention_layer_size in enumerate(attention_layer_sizes)) self._attention_layer_size = sum(attention_layer_sizes)elif attention_layer is not None: self._attention_layers = tuple( attention_layer if isinstance(attention_layer, (list, tuple)) else (attention_layer,)) self._attention_layer_size = sum( tensor_shape.dimension_value(layer.compute_output_shape( [None, cell.output_size + tensor_shape.dimension_value( mechanism.values.shape[-1])])[-1]) for layer, mechanism in zip( self._attention_layers, attention_mechanisms))else: self._attention_layers = None self._attention_layer_size = sum( tensor_shape.dimension_value(attention_mechanism.values.shape[-1]) for attention_mechanism in attention_mechanisms) 可见参数attention_layer_size和attention_layer都会影响self._attention_layers的值，只有在它俩都为None（默认）时self._attention_layers才为None。 接下来看看其call方法，其输入输出和RNNCell中的call其实是类似的，都是通过上一步的inputs和state计算得到output和next_state。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def call(self, inputs, state): # Step 1: 根据输入和上一步的输出计算真正的输入 cell_inputs = self._cell_input_fn(inputs, state.attention) # 默认是concat操作 # Step 2: 调用内部被包裹的RNNCell得到cell_output和next_cell_state cell_state = state.cell_state cell_output, next_cell_state = self._cell(cell_inputs, cell_state) if self._is_multi: previous_attention_state = state.attention_state previous_alignment_history = state.alignment_history else: previous_attention_state = [state.attention_state] previous_alignment_history = [state.alignment_history] all_alignments = [] # 用列表存放，因为attention_mechanism是列表 all_attentions = [] all_attention_states = [] maybe_all_histories = [] # Step 3: 根据attention_mechanism计算得到attention, alignments for i, attention_mechanism in enumerate(self._attention_mechanisms): attention, alignments, next_attention_state = _compute_attention( attention_mechanism, cell_output, previous_attention_state[i], self._attention_layers[i] if self._attention_layers else None) alignment_history = previous_alignment_history[i].write( state.time, alignments) if self._alignment_history else () all_attention_states.append(next_attention_state) all_alignments.append(alignments) all_attentions.append(attention) maybe_all_histories.append(alignment_history) # Step 4: 组合成 AttentionWrapperState 作为下一步的状态 attention = array_ops.concat(all_attentions, 1) next_state = AttentionWrapperState( time=state.time + 1, cell_state=next_cell_state, attention=attention, attention_state=self._item_or_tuple(all_attention_states), alignments=self._item_or_tuple(all_alignments), alignment_history=self._item_or_tuple(maybe_all_histories)) # Step 5: 输出 if self._output_attention: return attention, next_state else: return cell_output, next_state 来一步一步地分析： Step 1: 调用了_cell_input_fn()方法，对inputs和state.attention进行处理，默认是使用concat函数拼接，作为当前时间步的输入。 Step 2: 调用其内部被包裹的RNNCell的call方法，得到cell的输出和下一状态。 Step 3: 这一步就是调用_compute_attention进行计算操作，如下面的代码所示，先调用了attention_mechanism进行对应类型的注意力计算得到 $\\alpha_{ij}$，然后进行加权求和操作得到上下文向量 $c_i$，然后再通过attention_layer进行对应的变换操作，最后再返回。 12345678910111213141516def _compute_attention(attention_mechanism, cell_output, attention_state, attention_layer):\"\"\"Computes the attention and alignments for a given attention_mechanism.\"\"\"# 这里的(next_)attention_state其实就是alignments, 详见2.3节中的call方法alignments, next_attention_state = attention_mechanism(cell_output, state=attention_state)# Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]expanded_alignments = array_ops.expand_dims(alignments, 1)context = math_ops.matmul(expanded_alignments, attention_mechanism.values) # 加权求和操作, 即式(1.3)context = array_ops.squeeze(context, [1])if attention_layer is not None: attention = attention_layer(array_ops.concat([cell_output, context], 1))else: attention = contextreturn attention, alignments, next_attention_state Step 4: 根据前面的构建新的state作为next_state。 Step 5: 若output_attention为True，则输出attention和next_state，否则输出cell_output和next_state。 综上，AttentionWrapper的call函数接收input和state然后输出output和下一个state，这就符合RNNCell的调用函数，即1output, next_state = RNNCell(input, state) 所以就可以像使用普通RNNCell一样使用带注意力机制的RNNCell了。 2.7 图解 图2.1 AttentionWrapper工作流程 参考文献[1] Cho K, Van Merriënboer B, Gulcehre C, et al. Learning phrase representations using RNN encoder-decoder for statistical machine translation[J]. arXiv preprint arXiv:1406.1078, 2014. [2] Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural networks[C]//Advances in neural information processing systems. 2014: 3104-3112. [3] Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014. [4] Luong M T, Pham H, Manning C D. Effective approaches to attention-based neural machine translation[J]. arXiv preprint arXiv:1508.04025, 2015. [5] Salimans T, Kingma D P. Weight normalization: A simple reparameterization to accelerate training of deep neural networks[C]//Advances in Neural Information Processing Systems. 2016: 901-909.","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://tangshusen.me/categories/Deep-Learning/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://tangshusen.me/tags/tensorflow/"},{"name":"attention","slug":"attention","permalink":"https://tangshusen.me/tags/attention/"},{"name":"seq2seq","slug":"seq2seq","permalink":"https://tangshusen.me/tags/seq2seq/"}]},{"title":"统计学习理论之VC维究竟是什么","slug":"vc-dimension","date":"2018-12-09T04:23:52.000Z","updated":"2018-12-30T09:16:22.473Z","comments":true,"path":"2018/12/09/vc-dimension/","link":"","permalink":"https://tangshusen.me/2018/12/09/vc-dimension/","excerpt":"学习机器学习不可避免的会接触到VC维，它在机器学习领域是一个很基础但很重要的概念，它给机器学习提供了坚实的理论基础。但直到在我写这篇博客之前，我对VC的理解还只停留在它能刻画假设空间的复杂度这样浅显的层次。本文就来理一理VC维(Vapnik–Chervonenkis dimension)的来龙去脉，搞清楚其本质。","text":"学习机器学习不可避免的会接触到VC维，它在机器学习领域是一个很基础但很重要的概念，它给机器学习提供了坚实的理论基础。但直到在我写这篇博客之前，我对VC的理解还只停留在它能刻画假设空间的复杂度这样浅显的层次。本文就来理一理VC维(Vapnik–Chervonenkis dimension)的来龙去脉，搞清楚其本质。 1. 可学习的条件既然说VC维给机器学习提供了坚实的理论基础，那么就有必要来看看机器学习算法可学习的条件是什么。 1.1 学习的过程一个基本的机器学习过程如图1.1所示(本文图片若无特别说明即来自于台大机器学习基石课程课件，Coursera课程地址)。解释一下下图中的一些概念：$\\mathcal{A}$ 表示学习算法，$f$ 表示学习的目标假设(可以是一个函数，也可以是一个分布)，$\\mathcal{H}$ 表示假设空间，$g$ 表示我们求解的用来预测的假设，$g$ 是属于 $\\mathcal{H}$ 的。机器学习的过程就是：通过算法 $\\mathcal{A}$，在假设空间 $\\mathcal{H}$ 中，根据训练样本集 $\\mathcal{D}$，选择最好的假设作为 $g$ 使 $g$ 近似于 $f$。 图1.1 图1.1中的 $E_{out}(g)$ 和 $E_{in}(g)$ 是两个重要的概念： $E_{out}(g)$，学到的假设 $g$ 在除了训练样本外的其他所有样本(out-of-sample)上的损失，称为期望误差，也称泛化误差。 $E_{in}(g)$，学到的假设 $g$ 在训练样本(in-of-sample)上的损失，称为经验误差。 我们的目标是选择最好的假设作为 $g$ 使 $g$ 近似于 $f$，而 $E_{out}(f) = 0$，也即我们的目标是使 $E_{out}(g) \\approx 0$。但我们是没法获得训练样本外的其他所有样本的，那也就没法计算 $E_{out}(g)$ 了，这该怎么办呢？ 1.2 Hoeffding不等式在回答1.1最后的问题之前，先来看看Hoeffding不等式。来看图1.2所述的问题: 设瓶子里的橙色球占比为 $\\mu$，从瓶子中随机抽取出N个样本，这N个样本中橙色球占比是 $\\nu$。我们可以将 $\\mu$ 看作1.1节中的$E_{out}(g)$，将 $\\nu$ 看作是 $E_{in}(g)$，我们现在并不知道 $\\mu$ 和 $E_{out}(g)$，只知道 $\\nu$ 和 $E_{in}(g)$，我们可以从 $\\nu$ 推断出关于 $\\mu$ 的什么吗？ 可以将 $\\nu$ 看作是样本期望，$\\mu$ 则是总体期望。 图1.2 直觉上，如果我们有更多的样本(抽出很多的球)，则 $\\nu$ 应该越来越接近总体期望 $\\mu$。事实上，这里可以用hoeffding不等式表示如下：$$\\mathbb{P}[|\\nu - \\mu| &gt; \\epsilon] \\leq 2 \\exp \\left(-2 \\epsilon^2 N \\right) \\tag{1.2.1}$$ 从hoeffding不等式可以看出，当N越来越大时，$\\nu$ 和 $\\mu$ 之差大于 $\\epsilon$ 的概率的上界越来越接近0，所以样本期望 $\\nu$ 越来越接近总体期望 $\\mu$，即 $\\nu$ 和 $\\mu$ 概率近似相等(probably approximately correct, PAC)了。 1.3 可学习的条件有了1.2节的铺垫，我们就可以来回答1.1节的问题了。 对于任意固定的假设 $h$，当训练样本量N足够大，类比于1.2节的例子，可以通过样本集上的经验误差 $E_{in}(h)$ 推测总体的期望误差 $E_{out}(h)$。基于hoeffding不等式，我们得到下面式子：$$\\mathbb{P}[|E_{in}(h) - E_{out}(h)| &gt; \\epsilon] \\leq 2 \\exp(-2 \\epsilon^2 N) \\tag{1.3.1}$$ 根据上面不等式，我们可以推断，当N足够大时，$E_{in}(h)$ 和 $E_{out}(h)$ 将非常接近。 注意在上面推导中，我们是针对某一个特定的假设 $h$。在我们的假设空间 $\\mathcal{H}$ 中，往往有很多个假设(甚至于无穷多个)。那么对于假设空间 $\\mathcal{H}$ 中的任意的假设 $h$，$E_{in}(h)$ 和 $E_{out}(h)$ 之差大于 $\\epsilon$ 的概率的上界会是什么呢？ 发生概率很小的事件在很多次实验中发生概率就会变得很大。例如连续丢5次硬币，事件”五次都是正面朝上”的概率是 $\\frac 1 {32}$。但是如果100个人做这个实验，事件”五次都是正面朝上”的发生的概率就是 $1 - ({\\frac {31} {32}})^{100} &gt; 0.95$。所以对于特定的假设 $h$，$E_{in}(h)$ 和 $E_{out}(h)$ 很接近，但是对于 $\\mathcal{H}$ 中任意的假设这就不一定了。 这里假定 $\\mathcal{H}$ 中有 $M$ 个假设 $h_1,h_2,…h_M$，则有如下推导:$$\\mathbb{P}[\\mathbf{E}(h_1)&gt; \\epsilon \\cup \\mathbf{E}(h_2)&gt; \\epsilon \\space … \\cup \\mathbf{E}(h_M)&gt; \\epsilon] \\\\\\leq \\mathbb{P}[\\mathbf{E}(h_1)&gt; \\epsilon] + \\mathbb{P}[\\mathbf{E}(h_2)&gt; \\epsilon] \\space … + \\mathbb{P}[\\mathbf{E}(h_M)&gt; \\epsilon] \\\\\\leq 2M\\exp(-2 \\epsilon^2 N) \\tag{1.3.2}$$其中 $\\mathbf{E}(h_i) = |E_{in}(h_i) - E_{out}(h_i)|$。 根据式 $(1.3.2)$ 知$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 2M \\exp(-2 \\epsilon^2 N) \\tag{1.3.3}$$ 上面式子的含义就是：在假设空间 $\\mathcal{H}$ 中，对于任意一个假设 $g$，$E_{in}(g)$ 和 $E_{out}(g)$ 之差大于 $\\epsilon$ 的概率的上界是 $2M \\exp(−2 \\epsilon^2 N)$。注意这个上界与训练样本数 $N$ 和假设空间假设数 $M$ 密切相关。 本文的所有讨论都是围绕式(1.3.3)进行的!!! 所以，根据式 $(1.3.3)$，我们就知道了可学习的两个核心条件是: 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。再结合条件2即达到了 $E_{out}(g) \\approx 0$ 的目标。 假设空间 $\\mathcal{H}$ 中假设数 $M$ 是有限的且训练样本数 $N$ 足够大。此时可保证式(1.3.3)右边上界趋于0，即学习算法 $\\mathcal{A}$ 从 $\\mathcal{H}$ 选出的任意假设 $g$ 都满足 $E_{in}(g) \\approx E_{out}(g)$。 上面这两个核心条件，也正好对应着train和test这两个过程: train过程希望经验误差$E_{in}(g)$ 尽可能小； test过程希望在真实环境中的期望误差$E_{out}(g)$也尽可能小，即$E_{out}(g)$接近于$E_{in}(g)$。 所以我们不应该只关心如何利用学习算法找到使 $E_{in}(g)$ 很小的 $g$。因为如果想让学习可行，也要保证$E_{out}(g)$接近于$E_{in}(g)$。 来分析一下 $M$ 的大小对于两个条件的满足情况： 当 $M$ 较小时，由式$(1.3.3)$知条件2很容易满足，但是由于可选的 $g$ 的数目 $M$ 较小，所以条件1不容易满足； 当 $M$ 较大时，由于可选的 $g$ 的数目 $M$ 较大，所以条件1很容易满足，但是条件2不容易满足。 由此可见，假设数 $M$ 在这两个核心条件中有着重要作用，应该合理选取。但是往往一个假设空间(如二维平面的所有直线)的假设数是很大的甚至是无穷的，此时式$(1.3.3)$中的上界就成了无穷大没有任何约束意义，也即不满足条件2，学习变得不可行，这该怎么办呢？ 2. VC维2.1 有效假设数在式$(1.3.2)$的推导中，我们用到了这样一个概率不等式:$$\\mathbb{P}(A_1 \\cup A_2 \\space … \\cup A_M) \\leq \\sum_{i=1}^M\\mathbb{P}(A_i) \\tag{2.1.1}$$我们知道，当 $A_i$ 相互独立时上式取等号。但事实上，假设空间里的 $h_i$ 之间并不是完全独立的，它们是有很大的重叠的，也就是在 $M$ 个假设中，有很多假设都可以归为同一类。 下面用二维假设空间为例解释一下上述重叠性。我们知道二维假设空间的所有假设数(即直线条数)为 $\\infty$，但是如图2.1所示，可以将这些假设分为两类，一类是把x1判断为正例，另一类是把x1判断为负例。 图2.1 那如果在平面上有两个不同的数据点x1,x2，这样的话，假设空间 $\\mathcal{H}$ 中的无数条直线可以分为4类。那依次类推，3个数据点情况下，$\\mathcal{H}$ 中最多有8类(当三个点在同一直线上时只有6类)。4个数据点时，$\\mathcal{H}$ 中最多有14类(注意不是16类)，如下图所示。 图2.2 从上面的分析可知，虽然假设空间假设数 $M$ 一般非常大(甚至无穷)，但在特定的样本集上，有效的假设数目是有限的，也即式$(1.3.3)$中的 $M$ 是有限的，所以可以重写式$(1.3.3)$如下:$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 2\\cdot \\text{effective}(M) \\exp(-2 \\epsilon^2 N) \\tag{2.1.2}$$ 2.2 对分和增长函数为了探究式$(2.1.2)$中的 $\\text{effective}(M)$ ，先引入对分(dichotomy) 的概念: 对于假设空间 $\\mathcal{H} = \\lbrace h: \\mathcal{X} \\to \\lbrace+1,-1\\rbrace \\rbrace$，我们称$$h(X_1, X_2,…,X_N) = (h(X_1), h(X_2),…,h(X_n)) \\in \\lbrace+1,-1 \\rbrace ^N$$为一个对分，即一个对分表示样本的一种标记结果，$\\mathcal{H}(X_1, X_2,…,X_N)$ 表示假设空间 $\\mathcal{H}$ 在训练集 $\\mathcal{D}$ 上的所有对分。 例如，若 $N = 4$且数据为二维时，参见图2.2，有如下表格: 假设空间 $\\mathcal{H}$ $\\mathcal{H}(X_1, X_2,X_3,X_4)$ 所有元素 平面上的所有直线 {+1,+1,+1,+1}, {+1,+1,+1,-1}… 元素个数 $\\infty$ 最大为14 (不会超过 $2^N$) 我们知道， $\\mathcal{H}(X_1, X_2,…,X_N)$ 的元素个数(即 $|\\mathcal{H}(X_1, X_2,…,X_N)|$ )是取决于具体的数据集 $\\mathcal{D}$ 的，例如当 $N=3$ 时且三个点不在一条直线时对分数为8，而在一条直线时对分数是6。为了去掉对具体 $\\mathcal{D}$ 的依赖性，我们引入 增长函数(growth function): 假设空间 $\\mathcal{H}$ 的增长函数 $m_{\\mathcal{H}}(N)$ 为$$m_{\\mathcal{H}}(N) = \\underset{X_1,X2,…,X_N \\in \\mathcal{X}}{max} |\\mathcal{H}(X_1, X_2,…,X_N)|$$增长函数 $m_{\\mathcal{H}}(N)$ 表示假设空间 $\\mathcal{H}$ 对个任意 $N$ 个样本所能赋予标记的的最大可能结果数，其上界为 $2^N$ 。 显然，$m_{\\mathcal{H}}(N)$ 越大，$\\mathcal{H}$ 的表示能力越强。因此，增长函数描述了假设空间 $\\mathcal{H}$ 的表示能力，由此反映出假设空间的复杂度。既然如此，那我们可不可以用 $m_{\\mathcal{H}}(N)$ 直接替换掉式$(2.1.2)$ 中的 $\\text{effective}(M)$ 呢，即$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\overset{?}{\\leq} 2 m_{\\mathcal{H}}(N) \\exp(-2 \\epsilon^2 N) \\tag{2.2.1}$$我们将在在2.3节回答这个问题。 2.3 VC界2.3.1 打散(shatter)在介绍VC维界(VC bound)之前，先引入打散(shatter)的概念, 当假设空间 $\\mathcal{H}$ 作用于大小为 $N$ 的样本集 $\\mathcal{D}$ 时，产生的对分数量等于 $2^N$ 即 $m_{\\mathcal{H}}(N)=2^N$ 时，就称 $\\mathcal{D}$ 被 $\\mathcal{H}$ 打散了。 shatter的原意是打碎，在此指 $N$ 个点的所有(碎片般的)可能情形都被 $\\mathcal{H}$ 产生了。 图2.3 如上图所示，二维空间上的的三个点(不在一条直线上)可以被平面上所有直线这个假设空间打碎,此时 $m_{\\mathcal{H}}(3)= 8 = 2^3$。但如下图所示的四个点就不能被这个假设空间打碎了，可知此时 $m_{\\mathcal{H}}(4)=14 \\neq 2^4$。 图2.4 2.3.2 break point尽管增长函数把假设数从无穷缩小到 $2^N$，但是这个量级还是太大了，很难保证式$(1.3.3)$右边这个上界趋于0，所以能不能把量级再缩小一点? 为了回答这个问题，先给出break point的定义: 对于假设空间 $\\mathcal{H}$ 的增长函数 $m_{\\mathcal{H}}(N)$ ，从 $N=1$ 出发逐渐增大，当增大到 $k$ 时，出现 $m_{\\mathcal{H}}(N) &lt; 2^N$ 的情形，则我们说 $k$ 是该假设空间的break point。换句话说，对于任何大小为 $N(N \\ge k)$ 的数据集， $\\mathcal{H}$ 都没有办法打碎它。 举例来讲，由2.3.1节知，当假设空间 $\\mathcal{H}$ 定义为平面上所有直线时，其break point就为4。 有了break point的概念，再经过一系列归纳证明(详见台大机器学习课程lecture6)，我们有这样一个结论: 设break point存在且为 $k$ 的假设空间的增长函数上界为 $B(N,k)$，则 $B(N,k)$ 满足$$m_{\\mathcal{H}}(N) \\le B(N,k) \\le \\sum_{i=0}^{k-1}{N \\choose i} \\le N^{k-1}$$注: 上式的证明可见这个知乎回答，另外最后一个不等号仅在 $N \\ge 2$ 且 $k \\ge 2$ 时成立。即break point存在时增长函数上界是一个多项式，多项式的最高幂次项为 $N^{k–1}$。 所以我们得到结论：如果break point存在，则增长函数 $m_{\\mathcal{H}}(N)$ 是多项式的。多项式的量级就比 $2^N$ 小多了，这就很容易保证式$(1.3.3)$右边这个上界很小，学习就可行了! 2.3.3 VC界上一小节提到如果break point存在，学习是可行的。既然如此，我们来回答一下2.2节最后提出的问题: 可不可以用 $m_{\\mathcal{H}}(N)$ 直接替换掉式$(2.1.2)$ 中的 $\\text{effective}(M)$ 呢，即式$(2.2.1)$是否成立。 答案是不能直接替换,正确的不等式是$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 4 m_{\\mathcal{H}}(2N) \\exp(-\\frac18 \\epsilon^2 N) \\tag{2.3.1}$$ 上式其实和式 $(2.2.1)$ 差不多，其证明略显复杂我们暂不去探究，可参考此处。 式$(2.3.1)$就是VC界，这个公式的意义在于：如果假设空间 $\\mathcal{H}$ 存在有限的break point $k$，即 $m_{\\mathcal{H}}(2N)$ 会被最高幂次为 $k–1$ 的多项式上界给约束住，那么，随着 $N$ 的逐渐增大，指数式 $exp(\\cdot)$ 的下降会比多项式 $m_{\\mathcal{H}}(2N)$ 的增长速度更快，所以此时可以推断出VC界是有界的。更进一步，当 $N$ 足够大时，对于 $\\mathcal{H}$ 中的任意一个假设 $g$ ，$E_{in}(g)$ 都将接近于 $E_{out}(g)$，即学习是可行的。 2.4 VC维现在，我们终于可以定义VC维了: 假设空间 $\\mathcal{H}$ 的VC维是能被 $\\mathcal{H}$ 打散的最大数据集的大小，即$$VC(\\mathcal{H}) = max \\lbrace N: m_{\\mathcal{H}}(N) = 2^N\\rbrace$$根据此定义，有 $VC(\\mathcal{H}) = k-1$，其中 $k$ 是 $\\mathcal{H}$ 的break point。 $VC(\\mathcal{H}) = d$ 表明存在大小为 $d$ 的数据集能被假设空间 $\\mathcal{H}$ 打散，需要注意的是这并不意味着所有大小为 $d$ 的数据集都能被 $\\mathcal{H}$ 打散，例如二维平面上的所有直线构成的假设空间 $\\mathcal{H}$ 的VC维为3，但是它并不能打散位于同一条直线上的三个点。事实上，VC维的定义与数据具体分布是无关的。 因为 $VC(\\mathcal{H}) = k-1$，所以由2.3.2节可知当 $N \\ge 2$ 且 $k \\ge 2$ 时，有$$m_{\\mathcal{H}}(N) \\le N^{VC(\\mathcal{H})} \\tag{2.4.1}$$ 将上式代入$(2.3.1)$的右边VC界有$$\\forall g \\in \\mathcal{H}, \\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq 4 (2N)^{VC(\\mathcal{H})} \\exp(-\\frac18 \\epsilon^2 N) \\tag{2.4.2}$$ 所以，1.3节的可学习的两个核心条件等价于: 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。再结合条件2即达到了 $E_{out}(g) \\approx 0$ 的目标。 假设空间 $\\mathcal{H}$ 的VC维 $VC(\\mathcal{H})$ 是有限的且训练样本数 $N$ 足够大。此时可保证式(2.4.2)右边上界趋于0，即学习算法 $\\mathcal{A}$ 从 $\\mathcal{H}$ 选出的任意假设 $g$ 都满足 $E_{in}(g) \\approx E_{out}(g)$。 VC维反映了函数集的学习能力，VC维越大，能学到的模型越复杂。根据前面的推导，我们知道VC维的大小与学习算法无关，与数据集的具体分布无关，与我们求解的目标函数也无关，只与模型和假设空间有关。另外，实践中有这样一个规律：一般情况下，假设空间的VC维约等于假设自由变量的数目。 2.5 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系令式$(2.4.2)$右边的 $4 (2N)^{VC(\\mathcal{H})} \\exp(-\\frac18 \\epsilon^2 N) = \\delta$，即坏事发生的概率$$\\mathbb{P}[|E_{in}(g) - E_{out}(g)| &gt; \\epsilon] \\leq \\delta \\tag{2.5.1}$$则可反解出$$\\epsilon = \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\tag{2.5.2}$$由(2.5.1)可得出，有 $1-\\delta$ 的概率好事情会发生，好事情即$$E_{in}(g) - \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\le E_{out}(g) \\le E_{in}(g) + \\sqrt{\\frac 8 N \\ln \\left( \\frac {4(2N)^{VC(\\mathcal{H})}} \\delta \\right)} \\tag{2.5.3}$$上式就是 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系。其中，根号部分也可以看做模型的复杂度 $\\Omega$，模型越复杂，$E_{in}(g)$ 与 $E_{out}(g)$ 离得越远。如图2.5所示，当固定样本数 $N$ 时，随着VC维的上升，$E_{in}(g)$ 会不断降低，而复杂度 $\\Omega$ 会不断上升，其上升与下降的速度在每个阶段都有所不同，因此我们要寻找一个二者兼顾的比较合适的VC维使 $E_{out}(g)$ 最小。 图2.5 此外，由上面的分析易知，样本数 $N$ 也会影响 $E_{out}(g)$。例如，当前有一个 $VC(\\mathcal{H})=3$ 的假设空间，要使 $\\epsilon=0.1$ 且 $\\delta=0.1$，则要想满足式$(2.5.2)$，可计算出理论上样本数 $N$ 需要达到 $10000VC(\\mathcal{H})$ 这个量级，但实际应用中我们发现 $N$ 达到 $10VC(\\mathcal{H})$ 就够了。这是因为，VC界是一个及其宽松的上界，因为它需要对任何学习算法，对任何数据分布，对任何目标函数都要成立,所以实际应用中的上界要比VC界小很多。 3. 总结总结一下本文的行文思路， 先用Hoeffding不等式说明了可学习的两个条件: (1) 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。 (2) 假设空间 $\\mathcal{H}$ 中假设数 $M$ 是有限的且训练样本数 $N$ 足够大。 但假设空间 $\\mathcal{H}$ 中假设数 $M$ 往往是无穷大的。幸运的是，在推导出条件(2)时，我们要求假设空间的所有假设都是独立的，而假设空间 $\\mathcal{H}$ 中独立假设数 $\\text{effective}(M)$ 却是有限的，增长函数告诉我们 $\\text{effective}(M)$ 的上界为 $2^N$ 。 $2^N$ 这个上界还是太大了，学习还是很难可行。所以我们又引入了break point的概念，使 $2^N$ 的量级降为 $N^{k-1}$, 由此得到了VC界。 然后我们给出了VC维的定义，可学习的两个条件转变为: (1) 学习算法 $\\mathcal{A}$ 能够从 $\\mathcal{H}$ 选出的假设 $g$ 满足 $E_{in}(g) \\approx 0$。 (2) 假设空间 $\\mathcal{H}$ 的VC维 $VC(\\mathcal{H})$ 是有限的且训练样本数 $N$ 足够大。 最后我们讨论了 $E_{in}(g)$ 与 $E_{out}(g)$ 的关系，发现为了使学习器更好($E_{out}(g)$更小)，要选择合适的VC维，不能太大也不能太小。 因笔者自身水平实在有限，如果文章有任何的不妥，还请读者告之。此外，VC维可以说是机器学习中的一大核心，并非一篇博客就可以讲解透彻，所以本文也省略了一些复杂的证明，如果想深入理解可以去查阅相关书籍或论文。 参考 周志华《机器学习》第12章.计算学习理论 台大机器学习基石课程 ECE 901 Lecture 19: The Proof of the Vapnik-Chervonenkis (VC) Inequality Computational Learning Theory - VC Dimension [陆勤学习]解读机器学习基础概念：VC维的来龙去脉","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"VC维","slug":"VC维","permalink":"https://tangshusen.me/tags/VC维/"}]},{"title":"实际应用中关于size_t的一个容易忽略的坑","slug":"size-t","date":"2018-12-08T13:42:13.000Z","updated":"2018-12-30T09:15:20.196Z","comments":true,"path":"2018/12/08/size-t/","link":"","permalink":"https://tangshusen.me/2018/12/08/size-t/","excerpt":"今天在LeetCode上做3Sum的时候，遇到了一个一开始令我百思不得其解的bug，最后发现还是自己太菜了😭，在此记录一下以加深印象。","text":"今天在LeetCode上做3Sum的时候，遇到了一个一开始令我百思不得其解的bug，最后发现还是自己太菜了😭，在此记录一下以加深印象。 起因如下图所示，下面这段代码是过不了输入为空的测试样例的。 但是如果我加上一个”多余的”提前判断的语句就能过，如下图所示。 为什么看似等价的代码一个能过一个不能过呢？ 分析考虑这样一段代码:123456789101112131415#include &lt;iostream&gt;#include &lt;typeinfo&gt;#include&lt;vector&gt;using namespace std;int main()&#123; vector&lt;int&gt;ar; cout &lt;&lt; \"数组ar的size是\" &lt;&lt; ar.size()&lt;&lt; endl; for(int i = 0; i &lt; ar.size() - 1; i++)&#123; cout &lt;&lt; \"进入了for循环！\" &lt;&lt; endl; break; &#125; cout &lt;&lt; \"ar.size() - 1: \" &lt;&lt; ar.size() - 1 &lt;&lt; endl; return 0;&#125; 运行结果是:123数组ar的size是0进入了for循环！ar.size() - 1: 18446744073709551615 其中 $18446744073709551615 = 2^{64} - 1$。仿佛知道问题大概出在哪儿了。 结论这才突然想起C++ primer讲过，size()返回的是一个类型为size_t的量，那什么是size_t型呢？来看标准库的定义: size_tUnsigned integral typeAlias of one of the fundamental unsigned integer types. 原来size_t是无符号型的，但是为什么 ar.size() - 1 没有自动转换为带符号型的呢？ C++ primer第五版中文版P35还讲过： 提示：切勿混用带符号类型和无符号类型如果表达式里既有带符号类型又有无符号类型，当带符号类型取值为负时会出现异常结果，这是因为带符号数会自动转换为无符号数。 原来在同时存在无符号型数和有符号型数的表达式中，带符号型数是会自动转换为无符号型的! 所以，当无符号的ar.size()减去1时，结果自然不是-1而是 $2^{n} - 1$，$n$ 表示size_t型的位数。 值得提一点的是，size_t的位数并不一定等于unsigned的位数的: size_t和unsigned int有所不同,size_t的取值range是目标平台下最大可能的数组尺寸。一些平台下size_t的范围小于int的正数范围,又或者大于unsigned int.最典型的,在x64下,int还是4B,但size_t是8B.这意味着你在x64下最大可能开辟的数组尺寸是2^64.作者：KE meng链接：https://www.zhihu.com/question/24773728/answer/28920149来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 总结以后一定要注意，size()是返回的无符号型的数！所以对于第一个图中代码，for循环内部是会执行的，结果自然不对了(越界)。以后要用到数组的size时，还是先定义int len = ar.size()，这样不仅不会反犯这次这个错误，还能方便多次使用。","categories":[{"name":"C++","slug":"C","permalink":"https://tangshusen.me/categories/C/"}],"tags":[{"name":"语法","slug":"语法","permalink":"https://tangshusen.me/tags/语法/"},{"name":"坑","slug":"坑","permalink":"https://tangshusen.me/tags/坑/"}]},{"title":"Quick, Draw! Doodle Recognition Challenge 总结","slug":"kaggle-doodle-reco","date":"2018-12-05T13:58:29.000Z","updated":"2019-01-04T12:28:03.949Z","comments":true,"path":"2018/12/05/kaggle-doodle-reco/","link":"","permalink":"https://tangshusen.me/2018/12/05/kaggle-doodle-reco/","excerpt":"这个比赛于12.05早上结束，最终结果是排在69/1316、铜牌，离银牌区差4名，还是比较遗憾的。不过这是我第一次花大量时间和精力在图像分类问题上，作为一个小菜鸡能拿到牌还算满意。现在作个总结。另外本次比赛我的所有代码（带注释）已经开源(戳我)，有兴趣的可以看看，顺便给个star。","text":"这个比赛于12.05早上结束，最终结果是排在69/1316、铜牌，离银牌区差4名，还是比较遗憾的。不过这是我第一次花大量时间和精力在图像分类问题上，作为一个小菜鸡能拿到牌还算满意。现在作个总结。另外本次比赛我的所有代码（带注释）已经开源(戳我)，有兴趣的可以看看，顺便给个star。 这篇博客主要记录我在这次比赛过程中学到的一些东西，由于是第一次花精力认真做图像类的比赛所以学到的东西还是很多的。此外还会总结一下排在前列的大佬们在讨论区分享的他们的方案，留作日后参考。 1. 赛题简述1.1 数据集还记得前段时间很火的微信小程序“猜画小歌”吗，这个比赛的数据就来自这个小程序的网页版Quick, Draw!，游戏提示用户绘制描绘特定类别的涂鸦，例如“香蕉”，“桌子”等，所以Google通过这个小游戏收集了来自世界各地的涂鸦数据, 数据集所有信息都可见此数据集的官方仓库。本次比赛使用了340类一共约五千万个样本。 主办方给了两个版本的训练集，raw 和 simplified，都是以csv文件的形式给出的。raw版本就是原始收集到的数据各字段如下所示: Key Type Description key_id 64-bit unsigned integer 独一无二的样本ID word string 样本所属类别 recognized bool 样本是否被游戏识别 timestamp datetime 样本创建时间 countrycode string player所在国家代码(ISO 3166-1 alpha-2) drawing string 涂鸦数据信息 其中drawing字段就是涂鸦数据，包含坐标和时间信息，示例如下:12345678910111213[ [ // First stroke [x0, x1, x2, x3, ...], [y0, y1, y2, y3, ...], [t0, t1, t2, t3, ...] ], [ // Second stroke [x0, x1, x2, x3, ...], [y0, y1, y2, y3, ...], [t0, t1, t2, t3, ...] ], ... // Additional strokes] raw版本的数据集很大而且很多冗余信息，所以大多数选手(包括我)都是用的simplified版本作为主要训练集，simplified数据集去掉了时间信息和冗余的坐标信息(比如两点确定一条线段，那么线段中间的点就是冗余的)并将坐标进行了scale，具体处理方式如下: scaled 的坐标数据进行了左上对齐，最小值为0最大值为255. 进行了重采样使坐标都是0-255的整数. 去除冗余坐标使用的是Ramer–Douglas–Peucker算法，epsilon设为2.0； simplified数据集示例如下图所示: 图1.1 更多信息可见此数据集的官方仓库，这里就不赘述了。 1.2 赛题任务本题的任务就是预测测试集涂鸦属于哪个类别，是一个单分类问题。此题的难度在于，由于训练数据来自游戏本身，涂鸦样本可能不完整而且可能与标签不符，噪声比较多，如图1.2所示(图片来源)。选手需要构建一个识别器，可以有效地从这些噪声数据中学习得到模型。 图1.2 上图就是训练集中属于“蚊子”类别的数据示例，绿色是被标记为”可识别”的样本，红色是被标记为”不可识别”的样本，可以看到不管是可识别还是不可识别的样本，都存在噪声的情况。 1.3 评价指标虽然是一个单分类问题，但是对于每一个样本，我们需要提交最有可能的3个预测结果(按可能性从大到小排)，评价指标是Mean Average Precision @ 3 (MAP@3):$$\\text{MAP@3} = \\frac { 1 } { U } \\sum _ { u = 1 } ^ { U } \\sum _ { k = 1 } ^ { m i n ( n , 3 ) } P ( k )$$其中 $U$ 是测试集样本总数，$n$ 是每个样本的预测值总数，$P(k)$ 是前 $k$ 个结果中准确率, 具体可参见这个kernel，另外计算代码可参考这里。简单点讲，在提交的三个预测结果中，真实结果越靠前分数就越高。 2. 我的方案可见此题的数据是序列数据，所以最先想到可以用RNN，当然把数据渲染成图片也可以用CNN。根据我的实际实验，RNN的效果并不好（应该是我网络结构没设计好，讨论区有人提到用RNN也可以达到不错的效果），所以就采用了CNN相关模型，后来又merge了队友，最终的69名(PB 0.94223)是队友的提交结果，我的提交结果(PB 0.94185)应该是73名。 2.1 数据相关2.1.1 打乱原始文件题目给的数据是每一类一个csv文件，一共有340类，每一类有十多万个样本，即使是使用simplified数据集，总的csv文件大小也达到了20G+的级别，所以一次性读进内存肯定是不行的。我首先采用了这个kernel将340个csv文件混合在一起然后再随机分成100份分别存储，这样每一份里面的每一个样本的类别都是随机的。思路就是根据key_id的值产生一个0-99的伪随机数cv，然后cv就觉定当前样本应该放在哪个文件，最后再将每个文件里的样本顺序打乱。其核心代码如下: (1) 决定某个样本应该存放在哪个文件:1234567891011121314151617181920212223for y, cat in tqdm(enumerate(categories)): # 共340个类别 df = s.read_training_csv(cat) # df就为当前类别的csv df['y'] = y # y为 0~339 的数字，相当于对类别进行了LabelEncode df['cv'] = (df.key_id // 10 ** 7) % NCSVS # NCSVS = 100, cv决定了应该放在哪一个文件中 for k in range(NCSVS): filename = INPUT_PATH + '/shuffled_csv/train_%d_%d.csv'%(k+1, NCSVS) chunk = df[df.cv == k] # 得到df中cv=k的样本，应该存放在当前文件中 chunk = chunk.drop(['key_id'], axis=1) if y == 0: # 新建文件 chunk.to_csv(filename, index=False) else: # mode='a': 附加写 方式打开文件 chunk.to_csv(filename, mode='a', header=False, index=False) ``` (2) 将每个文件中的样本顺序打乱:``` pythonfor k in tqdm(range(NCSVS)): filename = INPUT_PATH + '/shuffled_csv/train_%d_%d.csv'%(k+1, NCSVS) if os.path.exists(filename): df = pd.read_csv(filename) df['rnd'] = np.random.rand(len(df)) # 给每个样本一个随机数 df = df.sort_values(by='rnd').drop('rnd', axis=1) df.to_csv(filename + '.gz', compression='gzip', index=False) # 以压缩的方式存储csv os.remove(filename) 这样处理后，原始simplified数据集中340个共20G+的csv文件被处理成100个csv共7G+，而且每个文件里的样本不是属于同一类而是随机的，这就方便后续的数据读取了。上面完整的代码见我的仓库。 2.1.2 多进程读取经过2.1.1处理后的数据就可以很方便地直接用了，我们可以考虑并行读取使读取更快:1234567891011121314151617181920212223242526def read_one_df_file(df_file): \"\"\"定义一个读取一个csv的函数，这个函数会当做参数传入下面的并行处理的函数\"\"\" unused_cols = [\"countrycode\", \"recognized\", \"timestamp\", \"cv\"] name = df_file.split('_')[-2] print('%s ' % (name), end = ' ', flush=True) df = pd.read_csv(df_file) drop_cols = [col for col in unused_cols if col in df.columns] if len(drop_cols) &gt; 0: df = df.drop(drop_cols, axis=1) return dfdef multi_thread_read_df_files(df_files, processes=32): \"\"\"并行读取多个csv并组成一个大的bigdf\"\"\" start = dt.datetime.now() pool = Pool(processes=processes) # from multiprocessing import Pool dfs = pool.map(read_one_df_file, df_files) pool.close() pool.join() end = dt.datetime.now() print(\"\\nTotal time:\", (end - start).seconds, \"seconds\") big_df = pd.concat(dfs, ignore_index=False, sort=False) big_df.reset_index(drop=True, inplace=True) return big_df 上面的完整代码见我的仓库里的data_loader.py，另外多进程的学习可参考此处。 2.1.3 outliers由图1.2知训练数据中有很多噪声，如何衡量噪声并去除这些噪声数据（outliers）呢？kernel sketch entropy提出用熵（entropy）来找出这些outliers, 即把entropy低于和高于某阈值的样本视为outliers。 先来看看如何计算entropy：12345def entropy_it(x): counts = np.bincount(x) # 计算x中 0-255这些数字的出现次数 p = counts[counts &gt; 0] / float(len(x)) # 归一化成概率 # compute Shannon entropy in bits return -np.sum(p * np.log2(p)) 直观理解，如果一张图片上的信息很少例如像素值几乎完全一样，那么归一化后的概率p就几乎是一个one hot的向量，这样 -np.sum(p * np.log2(p)) 就几乎得0；相反地，如果图片上的信息很丰富，像素分布比较均匀，那么p就是一个每个元素几乎都相等的向量，这样算出来的entropy就比较大。 例如训练集样本entropy低于和高于99%样本的示例分别如下： 图2.1 但是我最终并没有按照此方法去掉这些“outliers”，主要是出于以下考虑： 训练集很大，接近五千万，所以数据噪声对模型的影响应该有限； 按照此方法可得出测试集中也有一些噪声； 按照此方法得出的不一定就是噪声，例如图2.1第一排第一个应该是‘雨滴’，最后一排第三个应该是‘龙卷风’。 时间不够了，如果时间够的话我肯定会试一下。 这个kernel的作者也在讨论中提到： Be careful, do not remove unusual samples from training. In my recipe I use a curriculum learning, i.e. increase the amount of outliers at each new epoch. 虽然我最后并没有用这个方法，但是却提供了一个去噪的好思路。本节的完整代码见我的仓库中的sketch_entropy notebook。 2.2 模型2.2.1 模型结构本次比赛我最后采用的结构是xception（完整代码见此处），用的是pretrainedmodels库,这个库有主流模型的pytorch的实现，直接用就是，特别方便。代码如下1234567891011121314from pretrainedmodels.models.xception import Xceptionxception_path = \"/YOUR_PATH/pytorch/xception-43020ad28.pth\"def create_model(num_classes=340, model_func=Xception, pretrained_path=xception_path): model = model_func(num_classes=1000) # imageNet预训练参数，真的有用吗？ model.load_state_dict(torch.load(pretrained_path)) # 修改最后的fc层 fc_in_feas = model.fc.in_features model.fc = nn.Linear(fc_in_feas, num_classes) model.last_linear = model.fc # pretrainedmodels这个包里的模型作forward时使用的是last_linear return model 2.2.2 梯度累积trick我们知道，一般来说，增大batch size会使最终的预测效果变得更好，但是GPU显存是有限的不可能无限增大batch size，这时候梯度累积就派上用场了。简单来说，梯度累积就是累积多个batch的梯度然后一次更新参数，而不是常用的一个batch更新一次，亲测在小数据集上是有效果提升的（本次比赛数据集size很大，但我也用了这个trick，没有和不用这个trick做比较）。参考这里Gopal_Sharma的系列回答，我写了如下代码：12345678910111213141516171819202122# loss, preds, step_acc = train_step(model, inputs, labels, criterion, optimizer)################# 将batch_accumulate_size个batch的梯度积累起来,只在最后一次更新网络参数 ###################inputs = inputs.to(DEVICE, dtype=torch.float)labels = labels.to(DEVICE, dtype=torch.float)if step % batch_accumulate_size == 0: optimizer.zero_grad()with torch.set_grad_enabled(True): # forward outputs = model(inputs) loss = criterion(outputs, labels.long()) / batch_accumulate_size # 一定要除以这个size,原因见上面链接的讨论 loss.backward() _, preds = torch.max(outputs, 1)correct_num = torch.sum(preds == labels.long())step_acc = correct_num.double() / inputs.size(0) if (step + 1) % batch_accumulate_size == 0: optimizer.step() # 只在最后一次更新网络参数loss = batch_accumulate_size * loss.item() # 转换为数字方便后面用visdom画图step_acc = step_acc.item()######################################################################################## 2.2.3 多GPUpytorch实现多GPU还是比较方便的，只需要加上一行代码即可：12model = create_model()multi_gpu_model = nn.DataParallel(model) 需要注意的是，使用了DataParallel(model)的模型在保存的时候会在参数的key前面加上“module.”，所以如果使用单GPU时加载多GPU保存的模型参数时会报错KeyError: &#39;unexpected key &quot;module.xx.weight&quot; in state_dict&#39;，正确的处理方式如下：12345678910111213from collections import OrderedDictpretrained_net_dict = torch.load(best_model_path)if hps.gpus == 1 and list(pretrained_net_dict.keys())[0][:6] == \"module\":# 如果当前是单GPU但是保存的模型是多GPU，那就要去掉每个key的前缀\"module.\" new_state_dict = OrderedDict() for k, v in pretrained_net_dict.items(): name = k[7:] # remove \"module.\" new_state_dict[name] = v # load params model.load_state_dict(new_state_dict)else: model.load_state_dict(pretrained_net_dict) 2.2.4 图像数据的一个坑本节的notebook见此处。 事情的起因是这样的，我在训练的时候没有进行数据增强(只用了toTensor和Normalize两个transform)，而我在测试的时候想用一下用torchvision自带的一些图片增强的transform(例如CenterCrop、RandomHorizontalFlip、RandomRotation等等)，但是这些transform要求输入的是PIL图片，所以我在测试的时候就用了如下代码将image array转成了PIL图片：1PIL_image = Image.fromarray(image_array.astype('uint8'), 'RGB') 但最后测试出来的结果与验证时完全不一样，模型基本上是靠猜。这是为什么呢？仔细看看下面这个图就知道了。 图2.2 由图2.2可知，训练和测试的时候数据取值范围都变了，网络预测结果当然就很差了。先来看看ToTensor的官方文档: 123torchvision.transforms.ToTensorConvert a PIL Image or numpy.ndarray to tensor.Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]. 可见ToTensor将输入的0-255的数据scale到0-1并且还调整了一下维度顺序，那为什么图2.2的训练输入还是0-255呢? 问题就出在数据的类型上面，训练时，原始图片数据iamge_array的类型是float64(而不是ToTensor期待的uint8)，经过ToTensor转换后数值大小不会变依然是0-255只是调了一下维度顺序。而测试的时候，由于ToPILImage强制要求输入类型是uint8，所以先将输入转换成了uint8格式，所以就正确的被scale到了0-1。 总结一下，由于像素值为0到255的整数，所以刚好是uint8所能表示的范围，而很多关于图片的函数就默认输入的是uint8型，若不是，可能不会报错但的可能得不到想要的结果。所以，如果用像素值(0-255整数)表示图片数据，那么一律将其类型设置成uint8，避免不必要的bug 。 3. top方案3.1 1st place solution第一名的方案由现在排在所有kaggle用户第五的超级大佬Pavel Pleskov贡献，原文见此处。 3.1.1 模型结构刚开始，Pavel训练了很多分类模型：resnet18, resnet34, resnet50, resnet101, resnet152, resnext50, resnext101, densenet121, densenet201, vgg11, pnasnet, incresnet, polynet, nasnetmobile, senet154, seresnet50, seresnext50, seresnext101。此外，数据预处理尝试了1个和3个通道的输入、image size从112逐渐增大到256。大约40个模型中，最优的模型得到了0.946的分数，这个单一模型就可以拿到金牌了。 可以看到，这种类型的比赛如果前期能花大量时间尝试不同的模型，那基本就能保证奖牌了，甚至金牌。 3.1.2 ensemble为了将多个模型的输出集成起来，粗暴一点就是直接将输出的概率值求平均再取top3即得到最终的输出(也就是blend)。怎样将多个模型的结果ensemble在一起呢？因为一共340类，所以每一个模型对每个样本都会输出340个概率值，如果将每个概率值作为ensemble的feature，假设一共有8个模型，那么一个样本就有340x8个feature，这个特征维度有点大了而且其中很多都是接近0的值。 Pavel的思路是: for each sample and for each model you collect top 10 probabilities with the labels, then convert them into 10 samples with the binary outcome - whether this is a correct label or not (9 negative examples + 1 positive). It’s easy to feed such a dataset to any booster because the number of features will be small (equal to the number of models). 大概意思是将ensemble转换成一个二分类问题: 根据8(模型数)个概率值判断是不是label(例如这8个概率值都大于0.8，那么几乎可以肯定这就是label)。详细来讲，LGBM的特征维度等于模型数(每个特征就代表一个模型的输出概率)，而样本数将会是原始样本数的10倍。21st place solution也用到了这个方法，比直接平均得到的分数要高。 但是我有一点不明白的是如何找这个top10，因为对于mode1它的输出概率值top10可能是class0-9，对于model2它的输出概率值top10可能是class1-10，这样就对应不上了。但是我倒是有一个思路那就是先对8个模型的输出概率求个平均再取top10(21st place solution貌似使用的最好的model来预测出top10)。例如8个模型对于某张涂鸦图片的平均输出概率top10是O1、O2…O10，那么这就能产生10个LGBM的输入样本，会得到10个输出(是0-1的概率值)，取最大的三个即最终这个涂鸦样本的结果。 3.1.3 Predictions balancing trickHeng CherKeng发现，测试集中的groundtruth分布应该是均匀的，而且发现 (112199+1)/340=330 (训练集样本数加1除以类别数得330)。这一点很重要，通过对模型输出的概率按照此规律进行后处理，平均给每个模型带来了0.7%的提升。那么如何进行后处理呢? Pavel给出的算法是：对于当前最多的预测类别,将所有这个类别对应的概率不断减去一个很小的数直到这个类别不是最多的，重复上述过程直到预测类别差不多均匀。Pavel在之前的比赛也用到了这个算法(代码见此处)，代码原理和刚刚说的略有不同，算法步骤如下: 先对每一种类别赋一个初始为1的系数coefficients，当前预测概率等于实际概率乘以对应的系数； 计算每种类别的数目，按照这个数目再计算一个score，逻辑是预测越均匀score就越大; 对最多的类别label，执行coefficients[label] -= alpha； 若还没达到最大迭代次数，就继续执行2、3，执行过程中记录最大的score对应的coefficients，迭代完成后返回这个coefficients。 上述的score计算过程如下:12345678def _compute_score_with_coefficients(predicts, coefficients): _, counter = _get_labels_distribution(predicts, coefficients) # 计算每种类别的数目 # 按照下面的计算过程，当预测是均匀的时，score达到最大340 score = 0. for label in range(NCATS): # NCATS=340 score += min(NCATS * float(counter[label]) / len(predicts), 1.0) return score Pavel Ostyakov写的此算法的pytorch版见此处。 3.2 5th place solution3.2.1 总体流程第五名的方案由Artur Ispiriants和Mykhailo Matviiv贡献，原文见此处。 Artur Ispiriants先将每个样本从CSV文件提取出来，每个样本用一个二进制文件存放，这占用了大约400G的SSD，比较耗空间，但是方便后续各种模型的使用。 Artur一共训练了三个模型: Se-Resnext50 DPN-92 Se-Resnext101 每个模型都使用了在ImageNet上预训练的权重。图片尺寸使用了128、192、224、256，实验显示图片尺寸越大分数就越高，但是由于显存限制，尺寸越大就越难训练了。使用128的尺寸就能达到0.944的LB。 后来Artur Ispiriants merge了队友Mykhailo Matviiv，LB达到了约0.948，后来又使用了完整数据集里的时间信息: 延迟时间 每一笔的时间 笔画数量 上述三个数据都被scale到0-255。使用了这三个信息后，LB提升到了0.951。 3.2.2 训练流程由于数据集巨大，所以训练一个epoch就需要很长的时间，所以要经常保存模型，大约4-6个小时保存一下checkpoint。下面是Mykhailo Matviiv训练SE-ResNext101的流程： 图片尺寸取128x128训练网络直到收敛，这大概需要20个checkpoint，能达到0.945. 上一步得不到提升时，使用2.2.2节的梯度累积技术使batch size达到约3-4k，继续训练，模型进一步提升； 更进一步的提升就是在更大的图片尺寸(192然后256)进行fine tune。 3.2.3 trick比赛使用的一些trick如下： 经常保存checkpoint带来的一个提升就是snapshot ensembling，即一个模型最终的预测输出是这个模型的几个checkpoint的综合。最后的输出是多个模型的平均blend。 伪标签。这个方法是比赛最后阶段的主要提分点。此时blend模型的分数为0.951，使用这个输出给测试集加上了label（预测的top1），然后(只)用这些带label的测试集fine tune所有模型10个epoch，挑选3个最佳的epoch blend得到了0.952的LB。然后再用新的输出给测试集加上label，再fine tune，分数就达到了0.953，然后由于种种原因没再进行了(作者说再进行可能会进一步提升)。我认为这个方法要避免过拟合，作者也说了要谨慎使用，可以考虑将带伪标签的测试集混合在训练集进行训练以减少过拟合的风险。 3.3 其他3.3.1 RNN模型单模型0.941的RNN模型: 1d CNN+LSTM 3.3.2 11th place solution资源有限的情况下达到第11名的方案。 3.3.3 21st place solution也使用了3.1.2所示的ensemble方法，评论处有具体的ensemble方法。 3.3.4 24th place solution24th solution, 用的keras，并用了keras封装好的梯度累积trick 3.3.5 10 lessons46th的团队在这里给出了参加这个比赛得出的10条教训，有兴趣的可以去看看。 4. 总结 比赛前期应该多多尝试不同的网络结构； 这种超大数据集的图像类比赛，一般来讲就是网络越深、图片尺寸越大、batchsize越大，效果就越好； 注意积累一些trick，例如梯度累积、伪标签、Predictions balancing等等； 由于训练一个epoch时间漫长，所以每隔几个小时就保存一下模型是很有必要的，一个模型的预测输出应该是该模型几个checkpoint的输出的融合； 多逛逛讨论区。","categories":[{"name":"Competitions","slug":"Competitions","permalink":"https://tangshusen.me/categories/Competitions/"}],"tags":[{"name":"kaggle,classification","slug":"kaggle-classification","permalink":"https://tangshusen.me/tags/kaggle-classification/"}]},{"title":"Longest Palindromic Substring(最长回文子串)","slug":"Longest-Palindromic-Substring","date":"2018-12-01T14:23:15.000Z","updated":"2019-11-18T13:30:09.130Z","comments":true,"path":"2018/12/01/Longest-Palindromic-Substring/","link":"","permalink":"https://tangshusen.me/2018/12/01/Longest-Palindromic-Substring/","excerpt":"1. 问题描述Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.给定一个字符串s，找出s中的最长回文子串。s的长度不超过1000.","text":"1. 问题描述Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.给定一个字符串s，找出s中的最长回文子串。s的长度不超过1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer. Example 2: Input: “cbbd”Output: “bb” 2. 题解2.1 暴力法2.1.1 思路暴力穷举所有子字符串的可能，然后依次按位判断其是否是回文。虽然其时间复杂度很高，但它对空间的要求很低。 2.1.2 复杂度空间复杂度显然为 $O(1)$ ；穷举所有字符串复杂度为 $O(n^2)$ ，再加上判断是否是回文的，所以总的时间复杂度为 $O(n^3)$ 。 2.1.3 代码代码就不给了，给了你也不会看😀 2.2 动态规划2.2.1 思路我们知道，当某个字符串是回文的时候，在它两边同时增加一个相同字符后肯定依然是回文的，例如 bccb -&gt; abccba。基于这个特点，我们可以将暴力法中的判断是否为回文这一步用动态规划解决。 具体的，我们可以先把所有长度为1的子字符串计算出来，这些必定是回文的；然后计算出所有长度为2的子字符串并判断是否为回文。到长度为3的时候，我们就可以利用上次的计算结果：如果中心对称的短字符串不是回文，那长字符串也不是，如果短字符串是回文，那就要看长字符串两头是否一样。这样，一直到长度最大的子字符串，我们就把整个字符串集穷举完了。在这个过程中用一个 n x n 的二维bool型数组isOK记录是否会回文，其中n是字符串s的长度，isOK[i][j] == true就表示子串s[i...j]是回文的。 2.2.2 复杂度由于要申请一个二维数组isOK, 所以空间复杂度为 $O(n^2)$ ;由于使用动态规划，时间复杂度从暴力法的 $O(n^3)$ 减少到 $O(n^2)$。实测: Runtime: 244 ms, faster than 14.67% of C++ online submissions for Longest Palindromic Substring. 2.2.3 代码123456789101112131415161718192021class Solution &#123;public: string longestPalindrome(string s) &#123; if(!s.size()) return \"\"; vector&lt;vector&lt;bool&gt;&gt;isOK(s.size(), vector&lt;bool&gt;(s.size(), false)); string res = \"\"; for(int len = 1; len &lt;= s.size(); len++)&#123; // len代表子串长度 for(int start = 0; start + len &lt;= s.size(); start++)&#123; // start代表子串起始位置 if(len == 1) isOK[start][start] = true; else if(len == 2) isOK[start][start + 1] = (s[start] == s[start + 1]); else isOK[start][start + len - 1] = isOK[start + 1][start + len - 2] \\ &amp;&amp; s[start] == s[start + len - 1]; // 更新结果 if(isOK[start][start + len - 1] &amp;&amp; len &gt; res.size()) res = s.substr(start, len); &#125; &#125; return res; &#125;&#125;; 2.3 中心扩散法2.3.1 思路上面讲的动态规划虽然优化了时间，但也浪费了很多空间。实际上我们并不需要一直存储所有子字符串的回文情况，我们需要知道的只是中心对称的较小一层是否是回文。所以如果我们从小到大连续以某点为个中心的所有子字符串进行计算，就能省略这个空间。需要注意的是，由于中心对称有两种情况: 长度为奇数，则以中心字母对称； 长度为偶数，则以两个字母中间为对称。 所以我们要分别计算这两种对称情况。 2.3.2 复杂度相较于2.2的动态规划，空间复杂度缩小为 $O(1)$；时间复杂度一样，都是 $O(n^2)$。实测: Runtime: 20 ms, faster than 57.88% of C++ online submissions for Longest Palindromic Substring. 2.3.3 代码1234567891011121314151617181920212223class Solution &#123;public: string longestPalindrome(string s) &#123; if(!s.size()) return \"\"; string res = s.substr(0, 1); for(int mid = 0; mid &lt; s.size(); mid++)&#123; // mid为中心字母或者对称轴的前一个字母的下标 // mid为中心字母下标，即子串长度为奇数 for(int half_len = 1; mid + half_len &lt; s.size() &amp;&amp; mid - half_len &gt;= 0; half_len++)&#123; if(s[mid + half_len] != s[mid - half_len]) break; if(2 * half_len + 1 &gt; res.size()) res = s.substr(mid - half_len, 2*half_len + 1); &#125; // mid为对称轴的前一个字母，即子串长度为偶数 for(int half_len = 1; mid + half_len &lt; s.size() &amp;&amp; mid - half_len &gt;= -1; half_len++)&#123; if(s[mid + half_len] != s[mid - half_len + 1]) break; if(2 * half_len &gt; res.size()) res = s.substr(mid - half_len + 1, 2 * half_len); &#125; &#125; return res; &#125;&#125;; 2.4 马拉车(Manacher)算法下面要出场的就是大名鼎鼎的马拉车算法了，前面介绍的算法最快也不过 $O(n^2)$ 的时间复杂度，而马拉车的时间复杂度为逆天的 $O(n)$ 😨，是此题最理想的复杂度了。 本节主要参考LeetCode对此算法的详细解释。 2.4.1 思路首先，为了避免2.3那样将子串分为长度为奇数和偶数两种情况，我们先将字符串简单处理一下, 在s中的每个字符两边插入一个字符“#”得到字符串(在具体实现中，为了避免越界检查，通常还会在首尾额外插入两个与所有可能的字符都不同的字符如^、$),例如： s = abaaba —插入字符–&gt; T = #a#b#a#a#b#a# 为了找到最长的回文子串，我们先计算出以每个字符为中心的最长回文子串，然后比较之后找出最长的。我们使用数组P来保存以T中每个字符为中心的最长回文子串的半径(既长度的一半)。紧接着上面的例子: T : # a # b # a # a # b # a #P : 0 1 0 3 0 1 6 1 0 3 0 1 0 通过数组P，找到其中最大的数字6，我们可以马上得出最长的回文字符串就是s本身abaaba，即问题转换为如何高效地求解数组P。 我们仔细观察一下上面这个特殊的例子，我们会发现不仅T是对称的，就连P都是对称的，由于我们的目的就是计算出P的所有元素值，那么如果P是对称的，岂不是可以大大减少计算量！马拉车算法就是基于这样一个想法展开的。 为了详细介绍马拉车算法，我们来看一个稍微复杂的例子s = babcbabcbaccba: 如上图所示,假设已经完成了P数组的部分数值的计算，当前需要计算的是P[i]。我们引入变量 R，表示当前访问到的所有回文子串中所能触及的最右一个字符的位置。另外还要记录下R对应的回文串的对称轴所在的位置，记为C。另外也可推断出该回文串的左边位置L。图中的实线即表示C，两条虚线(L和R)分别表示以C为中心的回文串的边界。现在需要计算的是 P[i] 的值，图中 i’ 表示的是 i 关于 C 对称的点。那么问题来了，怎么高效地算出P[i]。 当前 i 的值是 13，我们需要得到P[13]的值，我们首先看下 i 关于 C对称的 i&#39; = 9的值。 如上图所示，两条绿色实线覆盖的区域分表表示的是 以 i’ 和 i 为中心的最长回文子串。我们已经知道了 P[i&#39;] = 1, 那么由于回文子串的对称性(即上图L~C和C~R对应的子串是关于C对称的)，我们可以推断出 P[i] = p[i&#39;] = 1。实际上，C之后的三个元素都遵循了这种对称性（既 P[12] = P[10] = 0, P[13] = P[9] =1, P[14] = P[8] = 0)。 如上图所示，现在我们到了 i = 15 这个点，i 关于 C对称的点是 i&#39; = 7, 那么这里 P[15] = P[7] = 7 还会不会成立呢？ 很显然是不成立的，我们凭肉眼观察可知 p[15] = 5 而 P[7] = 7。这是为什么呢？ 上图中，绿色实线表示的是以C为中心的最长回文子串所覆盖的区域，红色实线表示的是与绿色区域不匹配的部分，左边的红色实线是以T[i&#39;]为中心的最长回文子串所覆盖区域超出绿色实线的部分。右边的红色实线是以T[i]为中心的最长回文子串所覆盖区域超出绿色实线的部分。而绿色的虚线部分则是分别以T[i]和T[i&#39;]为中心最长回文子串与绿色实线部分的重叠部分。 从图中我们可以明显的看出被两条绿色实线所覆盖的区域中，C两边的子串是完全相同的。同时绿色虚线的那部分也是关于中心对称的。当 i = 12,13,14 即 i&#39; = 10,9,8 时，以T[i&#39;]为中心的最大回文子串全落在了L和R之间，这就使得我们能够使用LR的对称性直接得出关于T[i]对称的最大回文子串；但当 i&#39; = 7 即 P[i&#39;] = 7，此时以T[i&#39;]为中心的最长回文子串超出了以C为中心的最长回文子串的左边界(图中L左边红色实线)，正是因为这个原因，此时无法再按照对称性直接得出 P[i] 的值了，但是可以推出 P[i] &gt;= 5。 现在我们知道的是P[i] &gt;= 5, 为了找出P[i]最终的值，我们只有继续以P[i]为中心向两边扩展进行比较，在这个例子中P[21] != P[1],那么我们最终推断是P[i] = 5。 总结一下，在每一步中，都存在两种可能: R &gt; i，也就是刚刚我们讨论的情况，此时又细分为两种情况:(1) 若 P[i&#39;] &lt; R – i, 则令 P[i] = P[i&#39;];(2) 否则， 先令P[i] = P[i&#39;]，再以i为中心扩展回文串并P[i]++，直到左右两边字符不同或者到达边界。并更新变量R、C。 R &lt;= i，即i移动到R右边了，此时也应该以i为中心扩展回文串。类似情况1(2),只是P[i]初始为0。 2.4.2 复杂度空间复杂度显然是O(n).下面讨论一下时间复杂度，虽然代码中存在两个循环for和while，但是需要注意是： 当R不需要进行扩展时，不会进入while循环； R需要进行扩展时，会进入while循环，但整个算法过程while一共循环最多n次，即R从0不断扩展到n。 由此可见，马拉车算法是线性的时间复杂度，即O(n)。 亲测: Runtime: 8 ms, faster than 88.39% of C++ online submissions for Longest Palindromic Substring. 2.5.1 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123;private: // 将字符串S转换成T，例如S = \"abba\", T = \"^#a#b#b#a#$\". // ^ 和 $ 是为了避免越界检查 string preProcess(string s) &#123; int n = s.size(); if (n == 0) return \"^$\"; string t = \"^\"; for (int i = 0; i &lt; n; i++) t += \"#\" + s.substr(i, 1); t += \"#$\"; return t; &#125; public: string longestPalindrome(string s) &#123; string T = preProcess(s); int n = T.size(); vector&lt;int&gt;P(n); int C = 0, R = 0; for (int i = 1; i &lt; n-1; i++) &#123; int i_mirror = 2 * C - i; // i' = C - (i-C) P[i] = (R &gt; i) ? min(R - i, P[i_mirror]) : 0; // 尝试扩展以i为中心的回文串 while (T[i + 1 + P[i]] == T[i - 1 - P[i]]) P[i]++; // 如果以i为中心的回文串的右边界超过了R，则应该更新R和C if (i + P[i] &gt; R) &#123; C = i; R = i + P[i]; &#125; &#125; // 找出P中最大的元素 int maxLen = 0; int centerIndex = 0; for (int i = 1; i &lt; n-1; i++) &#123; //注意跳过首尾 if (P[i] &gt; maxLen) &#123; maxLen = P[i]; centerIndex = i; &#125; &#125; return s.substr((centerIndex - 1 - maxLen)/2, maxLen); // 减一是因为去掉第一个字符^ &#125;&#125;; 更多我的LeetCode中文题解，可前往GitHub查看：https://github.com/ShusenTang/LeetCode","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"https://tangshusen.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"https://tangshusen.me/tags/动态规划/"},{"name":"马拉车算法","slug":"马拉车算法","permalink":"https://tangshusen.me/tags/马拉车算法/"},{"name":"字符串","slug":"字符串","permalink":"https://tangshusen.me/tags/字符串/"}]},{"title":"AdaBoost算法详解与python实现","slug":"adaboost","date":"2018-11-18T14:05:04.000Z","updated":"2018-12-30T09:14:14.935Z","comments":true,"path":"2018/11/18/adaboost/","link":"","permalink":"https://tangshusen.me/2018/11/18/adaboost/","excerpt":"目前网上大多数博客只介绍了AdaBoost算法是什么，但是鲜有人介绍为什么Adaboost长这样，本文对此给出了详细的解释。","text":"目前网上大多数博客只介绍了AdaBoost算法是什么，但是鲜有人介绍为什么Adaboost长这样，本文对此给出了详细的解释。 1. 概述1.1 集成学习目前存在各种各样的机器学习算法，例如SVM、决策树、感知机等等。但是实际应用中，或者说在打比赛时，成绩较好的队伍几乎都用了集成学习(ensemble learning)的方法。集成学习的思想，简单来讲，就是“三个臭皮匠顶个诸葛亮”。集成学习通过结合多个学习器(例如同种算法但是参数不同，或者不同算法)，一般会获得比任意单个学习器都要好的性能，尤其是在这些学习器都是”弱学习器”的时候提升效果会很明显。 弱学习器指的是性能不太好的学习器，比如一个准确率略微超过50%的二分类器。 下面看看西瓜书对此做的一个简单理论分析。考虑一个二分类问题 $y \\in {-1, +1}$ 、真实函数 $f$ 以及奇数 $M$ 个犯错概率相互独立且均为 $\\epsilon $ 的个体学习器(或者称基学习器) $h_i$ 。我们用简单的投票进行集成学习，即分类结果取半数以上的基学习器的结果:$$H(x) = sign(\\sum_{i=1}^M h_i(x)) \\tag{1.1.1}$$由Hoeffding不等式知，集成学习后的犯错(即过半数基学习器犯错)概率满足$$P(H(x) \\neq f(x)) \\leq exp(- \\frac 1 2 M (1-2\\epsilon)^2) \\tag{1.1.2}$$ 式 $（1.1.2）$ 的证明是周志华《机器学习》的习题8.1，题解可参考此处 式 $（1.1.2）$ 指出，当犯错概率独立的基学习器个数 $M$ 很大时，集成后的犯错概率接近0，这也很符合直观想法: 大多数人同时犯错的概率是比较低的。 就如上面加粗字体强调的，以上推论全部建立在基学习器犯错相互独立的情况下，但实际中这些学习器不可能相互独立，而如何让基学习器变得“相对独立一些”，也即增加这些基学习器的多样性，正是集成学习需要考虑的主要问题。 按照每个基学习器之间是否存在依赖关系可以将集成学习分为两类： 基学习器之间存在强依赖关系，一系列基学习器需要串行生成，代表算法是Boosting； 基学习器之间不存在强依赖关系，一系列基学习器可并行生成，代表算法是Bagging和随机森林。 Boosting系列算法里最著名算法主要有AdaBoost和提升树(Boosting tree)系列算法，本文只介绍最具代表性的AdaBoost。提升树、Bagging以及随机森林不在本文介绍范围内，有时间了再另外介绍。 1.2 BoostingBoosting指的是一类集成方法，其主要思想就是将弱的基学习器提升(boost)为强学习器。具体步骤如下: 先用每个样本权重相等的训练集训练一个初始的基学习器； 根据上轮得到的学习器对训练集的预测表现情况调整训练集中的样本权重(例如提高被错分类的样本的权重使之在下轮训练中得到更多的关注), 然后据此训练一个新的基学习器； 重复2直到得到 $M$ 个基学习器，最终的集成结果是 $M$ 个基学习器的组合。 由此看出，Boosting算法是一个串行的过程。 Boosting算法簇中最著名的就是AdaBoost，下文将会详细介绍。 2. AdaBoost原理2.1 基本思想对于1.2节所述的Boosting算法步骤，需要回答两个问题: 如何调整每一轮的训练集中的样本权重？ 如何将得到的 $M$ 个组合成最终的学习器？ AdaBoost(Adaptive Boosting, 自适应增强)算法采取的方法是: 提高上一轮被错误分类的样本的权值，降低被正确分类的样本的权值； 线性加权求和。误差率小的基学习器拥有较大的权值，误差率大的基学习器拥有较小的权值。 Adaboost算法结构如下图(图片来源)所示。 图2.1 下面先给出AdaBoost算法具体实现步骤，至于算法解释（为什么要这样做）将在下一大节阐述。 2.2 算法步骤考虑如下形式的二分类（标准AdaBoost算法只适用于二分类任务）训练数据集:$${(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$$其中 $x_i$是一个含有$d$个元素的列向量, 即 $x_i\\in \\mathcal{X} \\subseteq \\mathbf{R}^d$ ; $y_i$是标量, $y\\in{+1,-1}$。 Adaboost算法具体步骤如下: 初始化样本的权重$$D_1=(w_{11}, w_{12},…w_{1N}), w_{1i}=\\frac 1 N, i = 1,2…N \\tag{2.2.1}$$ 对$m = 1,2,…M$,重复以下操作得到 $M$ 个基学习器:(1) 按照样本权重分布 $D_m$ 训练数据得到第 $m$ 个基学习器 $G_m(x)$:$$G_m(x): \\mathcal{X} \\to {-1, +1}$$(2) 计算 $G_m(x)$ 在加权训练数据集上的分类误差率:$$e_m = \\sum_{i=1}^NP(G_m(x_i) \\neq y_i)=\\sum_{i=1}^N w_{mi} I(G_m(x_i) \\neq y_i) \\tag{2.2.2}$$上式中 $I(\\cdot)$ 是指示函数，考虑更加周全的AdaBoost算法在这一步还应该判断是否满足基本条件(例如生成的基学习器是否比随机猜测好), 如果不满足，则当前基学习器被抛弃，学习过程提前终止。(3) 计算 $G_m(x)$ 的系数(即最终集成使用的的基学习器的权重):$$\\alpha_m = \\frac 1 2 log \\frac {1-e_m} {e_m} \\tag{2.2.3}$$(4) 更新训练样本的权重$$D_{m+1}=(w_{m+1,1}, w_{m+1,2},…w_{m+1,N}) \\tag{2.2.4}$$$$w_{m+1, i} = \\frac{w_{mi}} {Z_m} exp(-\\alpha_my_iG_m(x_i)) ,i=1,2,…N \\tag{2.2.5}$$其中 $Z_m$ 是规范化因子，目的是为了使 $D_{m+1}$ 的所有元素和为1。即$$Z_m=\\sum_{i=1}^N w_{mi} exp(-\\alpha_my_iG_m(x_i)) \\tag{2.2.6}$$ 构建最终的分类器线性组合$$f(x) = \\sum_{i=1}^M \\alpha_m G_m(x) \\tag{2.2.7}$$得到最终的分类器为$$G(x) = sign(f(x))=sign(\\sum_{i=1}^M \\alpha_m G_m(x)) \\tag{2.2.8}$$ 由式 $(2.2.3)$ 知，当基学习器 $G_m(x)$ 的误差率 $e_m \\le 0.5$ 时，$\\alpha_m \\ge 0$，并且 $\\alpha_m$ 随着 $e_m$ 的减小而增大，即分类误差率越小的基学习器在最终集成时占比也越大。即AdaBoost能够适应各个弱分类器的训练误差率，这也是它的名称中”适应性(Adaptive)”的由来。 由式 $(2.2.5)$ 知， 被基学习器 $G_m(x)$ 误分类的样本权值得以扩大，而被正确分类的样本的权值被得以缩小。 需要注意的是式 $(2.2.7)$ 中所有的 $\\alpha_m$ 的和并不为1(因为没有做一个softmax操作)，$f(x)$ 的符号决定了所预测的类，其绝对值代表了分类的确信度。 3. AdaBoost算法解释有没有想过为什么AdaBoost算法长上面这个样子，例如为什么 $\\alpha_m$ 要用式 $(2.2.3)$ 那样计算？本节将探讨这个问题。 3.1 前向分步算法在解释AdaBoost算法之前，先来看看前向分步算法。 就以AdaBoost算法的最终模型表达式为例:$$f(x) = \\sum_{i=1}^M \\alpha_m G_m(x) \\tag{3.1.1}$$可以看到这是一个“加性模型(additive model)”。我们希望这个模型在训练集上的经验误差最小，即$$min \\sum_{i=1}^N L(y_i, f(x)) \\iff min \\sum_{i=1}^N L(y_i, \\sum_{i=1}^M \\alpha_m G_m(x)) \\tag{3.1.2}$$通常这是一个复杂的优化问题。前向分步算法求解这一优化问题的思想就是: 因为最终模型是一个加性模型，如果能从前往后，每一步只学习一个基学习器 $G_m(x)$ 及其权重 $\\alpha_m$ , 不断迭代得到最终的模型，那么就可以简化问题复杂度。具体的，当我们经过 $m-1$ 轮迭代得到了最优模型 $f_{m-1}(x)$ 时，因为 $$f_m(x)= f_{m-1}(x) + \\alpha_mG_m(x) \\tag{3.1.3}$$所以此轮优化目标就为$$min \\sum_{i=1}^N L(y_i, f_{m-1}(x) + \\alpha_mG_m(x)) \\tag{3.1.4}$$求解上式即可得到第 $m$ 个基分类器 $G_m(x)$ 及其权重 $\\alpha_m$ 。这样，前向分步算法就通过不断迭代求得了从 $m=1$ 到 $m=M$ 的所有基分类器及其权重，问题得到了解决。 3.2 AdaBoost算法证明上一小结介绍的前向分步算法逐一学习基学习器，这一过程也即AdaBoost算法逐一学习基学习器的过程。但是为什么2.2节中的公式为什么长那样还是没有解释。本节就证明前向分步算法的损失函数是指数损失函数(exponential loss function)时，AdaBoost学习的具体步骤就如2.2节所示。 指数损失函数即$$L(y, f(x)) = exp(-yf(x))$$周志华《机器学习》p174有证明，指数损失函数是分类任务原本0/1损失函数的一致(consistent)替代损失函数，由于指数损失函数有更好的数学性质，例如处处可微，所以我们用它替代0/1损失作为优化目标。 将指数损失函数代入式 $(3.1.4)$ ，优化目标就为$$\\underset{\\alpha_m,G_m}{argmin} \\sum_{i=1}^N exp[-y_i(f_{m-1}(x) + \\alpha_mG_m(x))] \\tag{3.2.1}$$因为 $y_if_{m-1}(x)$ 与优化变量 $\\alpha$ 和 $G$ 无关，如果令$$w_{m,i} = exp[-y_i f_{m-1}(x)] \\tag{3.2.2}$$ 这个 $w_{m,i}$ 其实就是2.2节中归一化之前的权重 $w_{m,i}$ 那么式 $(3.2.1)$ 等价于$$\\underset{\\alpha_m,G_m}{argmin} \\sum_{i=1}^N w_{m,i}exp(-y_i\\alpha_mG_m(x)) \\tag{3.2.3}$$ 我们分两步来求解式 $(3.2.3)$ 所示的优化问题的最优解 $\\hat{\\alpha}_m$ 和 $\\hat{G}_m(x)$ : 对任意的 $\\alpha_m &gt; 0$, 求 $\\hat{G}_m(x)$：$$\\hat{G}_m (x) = \\underset{G_m}{argmin} \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) \\tag{3.2.4}$$ 上式将指数函数换成指示函数是因为前面说的指数损失函数和0/1损失函数是一致等价的。 式子 $(3.2.4)$ 所示的优化问题其实就是AdaBoost算法的基学习器的学习过程，即2.2节的步骤2(1)，得到的 $\\hat{G}_m(x)$ 是使第 $m$ 轮加权训练数据分类误差最小的基分类器。 求解 $\\hat{\\alpha}_m$ ： 将式子 $(3.2.3)$ 中的目标函数展开$$\\begin{aligned}\\sum_{i=1}^N w_{m,i}exp(-y_i\\alpha_mG_m(x)) &amp;= \\sum_{y_i=G_m(x_i)} w_{m,i}e^{- \\alpha} + \\sum_{y_i \\neq G_m(x_i)}w_{m,i}e^{\\alpha} \\\\\\\\&amp; = (e^{\\alpha} - e^{-\\alpha}) \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) + e^{-\\alpha} \\sum_{i=1}^N w_{m,i}\\end{aligned} \\tag{3.2.5}$$ 注：为了简洁，上式子中的$\\hat{G}_m(x)$ 被略去了 $\\hat{\\cdot}$ ， $\\alpha_m$ 被略去了下标 $m$ ，下同 将上式对 $\\alpha$ 求导并令导数为0，即 $$(e^{\\alpha} + e^{-\\alpha}) \\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)) - e^{-\\alpha} \\sum_{i=1}^N w_{m,i} = 0 \\tag{3.2.6} $$ 解得 $$ \\hat{\\alpha}_m = \\frac 1 2 log \\frac {1-e_m} {e_m} \\tag{3.2.7} $$ 其中, $e_m$ 是分类误差率： $$ e_m = \\frac {\\sum_{i=1}^N w_{m,i} I(y_i \\neq G_m(x_i)} {\\sum_{i=1}^N w_{mi}} \\tag{3.2.8} $$ 如果式子 $(3.2.8)$ 中的 $w_{mi}$ 归一化成和为1的话那么式 $(3.2.8)$ 也就和2.2节式 $(2.2.2)$ 一模一样了，进一步地也有上面的 $\\hat{\\alpha}_m$ 也就是2.2节的 $\\alpha_m$ 。 最后来看看每一轮样本权值的更新，由 $(3.1.3)$ 和 $(3.2.2)$ 可得 $$ w_{m+1,i} = w_{m,i} exp[-y_i \\alpha_m G_{m}(x)] \\tag{3.2.9} $$ 如果将上式进行归一化成和为1的话就和与2.2节中 $(2.2.5)$ 完全相同了。 由此可见，2.2节所述的AdaBoost算法步骤是可以经过严密推导得来的。总结一下，本节推导有如下关键点: AdaBoost算法是一个加性模型，将其简化成前向分步算法求解； 将0/1损失函数用数学性质更好的指数损失函数替代。 4. python实现4.1 基学习器首先需要定义一个基学习器，它应该是一个弱分类器。弱分类器使用库 sklearn 中的决策树分类器DecisionTreeClassifier, 可设置该决策树的最大深度为1。12# Fit a simple decision tree(weak classifier) firstclf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1) 4.2 AdaBoost实现然后就是完整AdaBoost算法的实现了，如下所示。12345678910111213141516171819202122232425262728293031323334353637def my_adaboost_clf(Y_train, X_train, Y_test, X_test, M=20, weak_clf=DecisionTreeClassifier(max_depth = 1)): n_train, n_test = len(X_train), len(X_test) # Initialize weights w = np.ones(n_train) / n_train pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)] for i in range(M): # Fit a classifier with the specific weights weak_clf.fit(X_train, Y_train, sample_weight = w) pred_train_i = weak_clf.predict(X_train) pred_test_i = weak_clf.predict(X_test) # Indicator function miss = [int(x) for x in (pred_train_i != Y_train)] print(\"weak_clf_%02d train acc: %.4f\" % (i + 1, 1 - sum(miss) / n_train)) # Error err_m = np.dot(w, miss) # Alpha alpha_m = 0.5 * np.log((1 - err_m) / float(err_m)) # New weights miss2 = [x if x==1 else -1 for x in miss] # -1 * y_i * G(x_i): 1 / -1 w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2])) w = w / sum(w) # Add to prediction pred_train_i = [1 if x == 1 else -1 for x in pred_train_i] pred_test_i = [1 if x == 1 else -1 for x in pred_test_i] pred_train = pred_train + np.multiply(alpha_m, pred_train_i) pred_test = pred_test + np.multiply(alpha_m, pred_test_i) pred_train = (pred_train &gt; 0) * 1 pred_test = (pred_test &gt; 0) * 1 print(\"My AdaBoost clf train accuracy: %.4f\" % (sum(pred_train == Y_train) / n_train)) print(\"My AdaBoost clf test accuracy: %.4f\" % (sum(pred_test == Y_test) / n_test))","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"AdaBoost","slug":"AdaBoost","permalink":"https://tangshusen.me/tags/AdaBoost/"},{"name":"集成学习(ensemble)","slug":"集成学习-ensemble","permalink":"https://tangshusen.me/tags/集成学习-ensemble/"}]},{"title":"TensorFlow实现多层RNN的一个大坑","slug":"tf-multi-rnn-bug","date":"2018-11-13T14:30:02.000Z","updated":"2018-12-30T09:15:56.162Z","comments":true,"path":"2018/11/13/tf-multi-rnn-bug/","link":"","permalink":"https://tangshusen.me/2018/11/13/tf-multi-rnn-bug/","excerpt":"","text":"起因事情的起因是这样的，我已经用tensorflow实现了一个带attention的encoder-decoder(都是单层的RNN)的结构，代码组织结构如下所示1234567891011121314151617encoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)def Encoder(cell, inputs): '''根据输入得到输出''' ...... return outputs# shape: (batch_size, max_seq_len, rnn_size)encoder_outputs = Encoder(encoder_cell, inputs)# 下面是attentionattn_mech = tf.contrib.seq2seq.LuongAttention(...) decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attn_mech, attention_layer_size=attn_size,...)# 下面的就不重要了...... 上面这段代码在attn_size为任何值的时候都是可以正常执行的。这也很符合预期，因为上面这段代码所干的事情如下: 用encoder将input编码成encoder_output(即attention的keys或者memory)； 对于decode的每一个时刻t，将t-1时刻得到的attention context(shape[-1]为attn_size)和decoder的输入合并在一起输入到decoder；…… 可以看到attn_size确实是任何值都可以, 也即decoder的输入维度(attn_size + input_x_size)为任何都可以。 注意TensorFlow中的RNN cell不需要显式指定输入的维度(而是自己推断出来)，这和pytorch不一样:pytorch_rnn = torch.nn.LSTM(input_size = attn_size + input_x_size, hidden_size=rnn_size) 经过后来我又想将decoder改成多层的RNN，decoder结构就像下面右边这样： 于是我将decoder_cell的定义做了如下修改:12345......one_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell for _ in range(dec_num_layers)])...... 除非把attn_size设置成rnn_size - input_x_size，否则会报类似下面的维度不对的错误(假设rnn_size=256, attn_size + input_x_size = 356)1ValueError: Dimensions must be equal, but are 256 and 356 for &apos;rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/MatMul_1&apos; (op: &apos;MatMul&apos;) with input shapes: [30,256], [356,1200]. 这是为什么呢？明明按照前面的分析，明明attn_size设置成任何值都可以的啊。 解决一开始我一直以为是我的attention写得不对，于是google了好久都没发现attention问题在哪？直到我看到了这个issue才发现是我的多层RNN没写对，还是自己太菜了😭 正确的多层decoder_cell应该是如下定义:1234......cell_list = [tf.nn.rnn_cell.LSTMCell(num_units=rnn_size) for _ in range(dec_num_layers)]decoder_cell = tf.nn.rnn_cell.MultiRNNCell(cell_list)...... 咋一看上面这段代码貌似和之前的错误代码没什么区别，但是如下代码你就应该意识到哪儿不对了12345678&gt;&gt;&gt; str = \"bug\"&gt;&gt;&gt; strs = [str for _ in range(2)]&gt;&gt;&gt; print(strs)['bug', 'bug']&gt;&gt;&gt; for str in strs: print(id(str)) # id()函数用于获取对象的内存地址43670492004367049200 注意到上面输出的两个地址都是一样的。因此，我们就知道问题出在哪儿了:对于前面错误的多层rnn实现, 每一层的LSTMCell其实都是同一个(指向它们的指针是相同的)，那么每一层的LSTMCell的weights维度就也是一样的，但其实第一层的输入维度(attn_size + input_x_size)和其它层的（rnn_size)一般都是不一样的，如下图所示，这样就会报维度错误了。 而正确代码中，每一个LSTMCell都是通过tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)定义的，因此可以有不同的结构，自然不会报错。 总结 TensorFlow中错误的多层RNN实现方式: 123one_cell = tf.nn.rnn_cell.LSTMCell(num_units=rnn_size)decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell for _ in range(dec_num_layers)])# decoder_cell = tf.nn.rnn_cell.MultiRNNCell([one_cell]*dec_num_layers])也是错误的 TensorFlow中正确的多层RNN实现方式: 12cell_list = [tf.nn.rnn_cell.LSTMCell(num_units=rnn_size) for _ in range(dec_num_layers)]decoder_cell = tf.nn.rnn_cell.MultiRNNCell(cell_list) 参考 Cannot stack LSTM with MultiRNNCell and dynamic_rnn using dynamic_rnn with multiRNN gives error","categories":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://tangshusen.me/categories/Deep-Learning/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://tangshusen.me/tags/tensorflow/"},{"name":"RNN","slug":"RNN","permalink":"https://tangshusen.me/tags/RNN/"},{"name":"attention","slug":"attention","permalink":"https://tangshusen.me/tags/attention/"},{"name":"seq2seq","slug":"seq2seq","permalink":"https://tangshusen.me/tags/seq2seq/"}]},{"title":"看了这篇文章你还不懂SVM你就来打我","slug":"SVM","date":"2018-10-27T15:19:45.000Z","updated":"2018-12-30T09:15:43.822Z","comments":true,"path":"2018/10/27/SVM/","link":"","permalink":"https://tangshusen.me/2018/10/27/SVM/","excerpt":"","text":"支持向量机(Support Vector Machine, SVM)1. 概要1.1 简介自从大半年前接触到SVM以来，感觉一直没怎么把SVM整明白。直到最近上的《模式识别》课程才仿佛打通了我的任督二脉，使我终于搞清楚了SVM的来龙去脉，所以写个博客作个总结。 SVM是什么? 先来看看维基百科上对SVM的定义: 支持向量机（英语：support vector machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。 如果从未接触SVM的话，维基的这一大段解释肯定会让你一头雾水。简单点讲，SVM就是一种二类分类模型，他的基本模型是的定义在特征空间上的间隔最大的线性分类器，SVM的学习策略就是间隔最大化。 1.2 直观理解我们先来看看下面这个图: 图1.1 图中有分别属于两类的一些二维数据点和三条直线。如果三条直线分别代表三个分类器的话，请问哪一个分类器比较好？ 我们凭直观感受应该觉得答案是H3。首先H1不能把类别分开，这个分类器肯定是不行的；H2可以，但分割线与最近的数据点只有很小的间隔，如果测试数据有一些噪声的话可能就会被H2错误分类(即对噪声敏感、泛化能力弱)。H3以较大间隔将它们分开，这样就能容忍测试数据的一些噪声而正确分类，是一个泛化能力不错的分类器。 对于支持向量机来说，数据点若是$p$维向量，我们用$p-1$维的超平面来分开这些点。但是可能有许多超平面可以把数据分类。最佳超平面的一个合理选择就是以最大间隔把两个类分开的超平面。因此，SVM选择能够使离超平面最近的数据点的到超平面距离最大的超平面。 以上介绍的SVM只能解决线性可分的问题，为了解决更加复杂的问题，支持向量机学习方法有一些由简至繁的模型: 线性可分SVM 当训练数据线性可分时，通过硬间隔(hard margin，什么是硬、软间隔下面会讲)最大化可以学习得到一个线性分类器，即硬间隔SVM，如上图的的H3。 线性SVM 当训练数据不能线性可分但是可以近似线性可分时，通过软间隔(soft margin)最大化也可以学习到一个线性分类器，即软间隔SVM。 非线性SVM 当训练数据线性不可分时，通过使用核技巧(kernel trick)和软间隔最大化，可以学习到一个非线性SVM。 2. 线性可分SVM——硬间隔考虑如下形式的线性可分的训练数据集:$${(X_1,y_1),(X_2,y_2),…,(X_n,y_n)}$$其中 $X_i$是一个含有$d$个元素的列向量, 即$X_i\\in \\mathbf{R}^d$; $y_i$是标量, $y\\in{+1,-1}$, $y_i = +1$时表示$X_i$属于正类别, $y_i = -1$时表示$X_i$属于负类别。 注: 本文中, $X$、$X_i$、$W$等都是(列)向量，有的文章一般用 $x_i$ 表示一个向量而用 $X$ 表示所有 $x_i$ 组成的一个矩阵，注意区分。 回忆一下感知机的目标: 找到一个超平面使其能正确地将每个样本正确分类。感知机使用误分类最小的方法求得超平面，不过此时解有无穷多个(例如图1.1的H2和H3以及它俩的任意线性组合)。而线性可分支持向量机利用间隔最大化求最优分离超平面,这时解是唯一的。 2.1 超平面与间隔一个超平面由法向量$W$和截距$b$决定,其方程为$X^TW+b=0$, 可以规定法向量指向的一侧为正类,另一侧为负类。下图画出了三个平行的超平面，法方向取左上方向。 注意: 如果$X$和$W$都是列向量,即$X^TW$会得到$X$和$W$的点积(dot product, 是一个标量),等价于$X \\cdot W$和$W \\cdot X$。 图2.1 为了找到最大间隔超平面，我们可以先选择分离两类数据的两个平行超平面，使得它们之间的距离尽可能大。在这两个超平面范围内的区域称为“间隔(margin)”，最大间隔超平面是位于它们正中间的超平面。这个过程如上图所示。 2.2 间隔最大化将高数里面求两条平行直线的距离公式推广到高维可求得图2.1中margin的$\\rho$:$$margin = \\rho = \\frac 2 {||W||} \\tag{2.2.1}$$我们的目标是使$\\rho$最大, 等价于使$\\rho^2$最大:$$\\underset{W,b}{max} \\rho \\iff \\underset{W,b}{max} \\rho^2 \\iff \\underset{W,b}{min}\\frac 1 2 ||W||^2 \\tag{2.2.2}$$上式的$\\frac 1 2$是为了后续求导后刚好能消去，没有其他特殊意义。 同时也不要忘了有一些约束条件:$$X_i^TW+b \\ge +1, y_i=+1 \\\\\\\\X_i^TW+b \\le -1, y_i=-1 \\tag{2.2.3}$$总结一下，间隔最大化问题的数学表达就是$$\\underset{W,b}{min}J(W) = \\underset{W,b}{min}\\frac 1 2 ||W||^2 \\\\\\\\s.t.\\quad y_i(X_i^TW+b) \\ge 1, i=1,2,…n. \\tag{2.2.4}$$ 通过求解上式即可得到最优超平面 $ \\hat{W} $ 和 $ \\hat{b} $ 。具体如何求解见2.4和2.5节。 2.3 支持向量在线性可分的情况下，训练数据集的样本点中与分离超平面距离最近的数据点称为支持向量(support vector)，支持向量是使$(2.2.4)$中的约束条件取等的点，即满足$$ y_i(X_i^TW+b) = 1 \\tag{2.3.1}$$的点。也即所有在直线$ X^TW+b = 1$或直线$ X^TW+b = -1$的点。如下图所示: 图2.2 在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用(具体推导见2.4节最后)。如果移动非支持向量，甚至删除非支持向量都不会对最优超平面产生任何影响。\u001c也即支持向量对模型起着决定性的作用，这也是“支持向量机”名称的由来。 2.4 对偶问题如何求解式 $(2.2.4)$ 呢？ 我们称式 $(2.2.4)$ 所述问题为原始问题(primal problem), 可以应用拉格朗日乘子法构造拉格朗日函数(Lagrange function)再通过求解其对偶问题(dual problem)得到原始问题的最优解。转换为对偶问题来求解的原因是: 对偶问题更易求解，由下文知对偶问题只需优化一个变量$\\alpha$且约束条件更简单； 能更加自然地引入核函数，进而推广到非线性问题。 首先构建拉格朗日函数。为此需要引进拉格朗日乘子(Lagrange multiplier) $\\alpha_i \\ge 0, i=1,2,…n$。则拉格朗日函数为:$$L(W,b,\\alpha)=\\frac 1 2 ||W||^2 - \\sum_{i=1}^n \\alpha_i [y_i(X_i^TW+b)-1]\\tag{2.4.1}$$因此，给定一个$W$和$b$, 若不满足式$(2.2.4)$的约束条件，那么有$$\\underset{\\alpha}{max} L(W,b,\\alpha) = +\\infty \\tag{2.4.2}$$否则，若满足式$(2.2.4)$的约束条件，有$$\\underset{\\alpha}{max} L(W,b,\\alpha) = J(W) = \\frac 1 2 ||W||^2 \\tag{2.4.3}$$结合式$(2.4.2)$和$(2.4.3)$知，优化问题$$\\underset{W, b}{min} \\underset{\\alpha}{max} L(W,b,\\alpha)\\tag{2.4.4}$$与式$(2.2.4)$所述问题是完全等价的。 根据拉格朗日对偶性，式$(2.4.4)$所述问题即原始问题的对偶问题是:$$\\underset{\\alpha}{max} \\underset{W, b}{min} L(W,b,\\alpha) \\tag{2.4.5}$$ 以上具体推导细节可参见书籍《统计学习方法》或者知乎文章拉格朗日对偶性 为了求得对偶问题的解，需要先求得$L(W,b,\\alpha)$对$W$和$b$的极小再求对$\\alpha$的极大。 (1) 求$\\underset{W, b}{min} L(W,b,\\alpha)$:对拉格朗日函数求导并令导数为0，有:$$\\nabla_W L(W,b,\\alpha) = W - \\sum_{i=1}^n \\alpha_i y_i X_i = 0 \\implies W= \\sum_{i=1}^n \\alpha_i y_i X_i\\tag{2.4.6}$$$$\\nabla_b L(W,b,\\alpha) = - \\sum_{i=1}^n \\alpha_i y_i = 0 \\implies \\sum_{i=1}^n \\alpha_i y_i = 0 \\tag{2.4.7}$$将上面两式代入$L(W,b,\\alpha)$： 所以，$$\\underset{W, b}{min} L(W,b,\\alpha) = -\\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ + \\ \\sum_{i=1}^n \\alpha_i \\tag{2.4.8}$$ (2) 求$\\underset{W, b}{min} L(W,b,\\alpha)$ 对$\\alpha$的极大:等价于式$(2.4.8)$对$\\alpha$求极大，也等价于式$(2.4.8)$取负数后对$\\alpha$求极小，即$$\\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ - \\ \\sum_{i=1}^n \\alpha_i \\tag{2.4.9}$$同时满足约束条件:$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\\\alpha_i \\ge 0, i=1,2,…,n. \\tag{2.4.10}$$ 至此，我们得到了原始最优化问题$(2.2.4)$和对偶最优化问题$(2.4.9)$、$(2.4.10)$。 由slater条件知，因为原始优化问题的目标函数和不等式约束条件都是凸函数，并且该不等式约束是严格可行的(因为数据是线性可分的), 所以存在 $ \\hat{W} $, $ \\hat{b}$ ,$\\hat{\\alpha} $，使得$ \\hat{W} $, $ \\hat{b}$是原始问题的解，$\\hat{\\alpha} $是对偶问题的解。这意味着求解原始最优化问题$(2.2.4)$可以转换为求解对偶最优化问题$(2.4.9)$、$(2.4.10)$。 slater 条件:原始问题一般性表达为$$\\underset{x}{min} \\quad f(x) \\\\\\\\s.t. \\ c_i(x) \\le 0, i=1,2,…k \\\\\\\\\\quad \\quad h_j(x) = 0, j=1,2,…,l$$则其拉格朗日函数为$$L(x,\\alpha,\\beta)=f(x) + \\sum_{i=1}^k \\alpha_i c_i(x) +\\sum_{j=1}^l \\beta_j h_j(x), \\quad \\alpha_i \\ge 0$$假设原始问题目标函数 $f(x)$ 和不等式约束条件 $c_i(x)$都是凸函数，原始问题等式约束$h_j(x)$都是仿射函数，且不等式约束 $c_i(x)$是严格可行的，即存在 $x$ ，对所有 $i$ 都有 $c_i(x) &lt; 0$ ，则存在 $\\hat{x} $, $\\hat{\\alpha} $, $\\hat{\\beta} $，使 $\\hat{x} $ 是原始问题的解， $\\hat{\\alpha} $, $\\hat{\\beta} $是对偶问题的解。 那么如何求解优化问题$(2.4.9)$、$(2.4.10)$的最优解 $\\hat{\\alpha}$ 呢？不难发现这是一个二次规划问题，有现成的通用的算法来求解。 事实上通用的求解二次规划问题的算法的复杂度正比于训练数据样本数，所以在实际应用中需要寻求更加高效的算法，例如序列最小优化(Sequential Minimal Optimiation, SMO)算法。 假设我们现在求得了$(2.4.9)$、$(2.4.10)$的最优解 $\\hat{\\alpha}$，则根据式$(2.4.6)$可求得最优$\\hat{W}$：$$\\hat{W}= \\sum_{i=1}^n \\hat{\\alpha}_i y_i X_i \\tag{2.4.11}$$因为至少存在一个 $\\hat{\\alpha}_j &gt; 0$(若不存在，即 $\\hat{\\alpha}$ 全为0，则 $\\hat{W}=0$, 即 $margin = \\frac 2 {||\\hat{W}||}= \\infty $,显然不行), 再根据KKT条件，即$$\\begin{cases}乘子非负: \\alpha_i \\ge 0 (i=1,2,…n.下同) \\\\\\\\约束条件: y_i(X_i^TW+b) - 1\\ge 0 \\\\\\\\互补条件: \\alpha_i (y_i(X_i^TW+b) - 1)=0\\end{cases}$$所以至少存在一个 $j$ , 使 $ y_j(X_j^T \\hat{W}+\\hat{b}) - 1=0$, 即可求得最优 $\\hat{b}$:$$\\begin{aligned}\\hat{b} &amp; = \\frac 1 {y_j} -X_j^T \\hat{W} \\\\\\\\&amp; = y_j -X_j^T \\hat{W} \\\\\\\\&amp; = y_j-\\sum_{i=1}^n \\hat{\\alpha}_i y_i X_j^T X_i\\end{aligned} \\tag{2.4.12}$$至此，所以我们就求得了整个线性可分SVM的解。求得的分离超平面为:$$\\sum_{i=1}^n \\hat{\\alpha}_i y_i X^TX_i + \\hat{b}=0 \\tag{2.4.13}$$则分类的决策函数为$$f(X) = sign(\\sum_{i=1}^n \\hat{\\alpha}_i y_i X^TX_i + \\hat{b})\\tag{2.4.14}$$再来分析KKT条件里的互补条件，对于任意样本 $(X_i, y_i)$ ，总会有 $ \\alpha_i=0 $ 或者 $y_if(X_i)=y_i(X_i^T \\hat{W}+b) = 1$。则有 若$ \\alpha_i=0$，此样本点不是支持向量，对模型没有任何作用； 若$ \\alpha_i&gt;0$，此样本点位于最大间隔边界上，是一个支持向量，如下图所示。 图2.3 此外，当样本点是非支持向量时，因为$ \\alpha_i=0$, 所以SVM的解中的求和项中第 $i$ 项就为0，所以SVM的解$(2.4.11)$、$(2.4.12)$可简化为如下形式:$$\\hat{W}= \\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_i \\tag{2.4.15}$$$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_j^T X_i\\tag{2.4.16}$$类似的，判别函数也可转换成如下形式:$$f(X) = sign(\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X^TX_i + \\hat{b})\\tag{2.4.17}$$所以，整个SVM的解只与支持向量SV有关，与非支持向量无关。这也就解释了2.3节的结论，即在决定最佳超平面时只有支持向量起作用，而其他数据点并不起作用。 3. 线性SVM——软间隔在前面的讨论中，我们一直假定训练数据是严格线性可分的，即存在一个超平面能完全将两类数据分开。但是现实任务这个假设往往不成立，例如下图所示的数据。 图3.1 3.1 软间隔最大化解决该问题的一个办法是允许SVM在少量样本上出错，即将之前的硬间隔最大化条件放宽一点，为此引入“软间隔(soft margin)”的概念。即允许少量样本不满足约束$$y_i(X_i^TW+b) \\ge 1 \\tag{3.1.1}$$为了使不满足上述条件的样本点尽可能少，我们需要在优化的目标函数$(2.2.2)$里面新增一个对这些点的惩罚项。最常用的是hinge损失:$$l_{hinge}(z) = max(0, 1-z) \\tag{3.1.2}$$即若样本点满足约束条件损失就是0, 否则损失就是 $1-z$ ,则优化目标 $(2.2.2)$ 变成$$\\underset{W,b}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n max(0, 1 - y_i(X_i^TW+b))\\tag{3.1.3}$$其中 $C &gt; 0$ 称为惩罚参数，$C$ 越小时对误分类惩罚越小，越大时对误分类惩罚越大，当 $C$ 取正无穷时就变成了硬间隔优化。实际应用时我们要合理选取 $C$，$C$ 越小越容易欠拟合，$C$ 越大越容易过拟合。 如果我们引入“松弛变量” $ \\xi_i \\ge 0$, 那么式 $(3.1.3)$ 可重写成$$\\underset{W,b,\\xi}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i\\\\\\\\s.t.\\ y_i(X_i^TW+b) \\ge 1-\\xi_i \\\\\\\\\\xi_i \\ge 0, i=1,2,…n. \\tag{3.1.4}$$上式所述问题即软间隔支持向量机。 3.2 对偶问题式 $(3.1.4)$ 表示的软间隔支持向量机依然是一个凸二次规划问题，和硬间隔支持向量机类似，我们可以通过拉格朗日乘子法将其转换为对偶问题进行求解。式 $(3.1.4)$ 对应的拉格朗日函数为$$L(W,b,\\xi,\\alpha,\\beta)=\\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i - \\sum_{i=1}^n \\alpha_i [y_i(X_i^TW+b) - 1 + \\xi_i] - \\sum_{i=1}^n \\beta_i \\xi_i\\tag{3.2.1}$$类似2.4节，为了求得对偶问题的解，我们需要先求得$L(W,b,\\xi,\\alpha,\\beta)$对 $W$、$b$ 和 $\\xi$ 的极小再求对 $\\alpha$ 和 $\\beta$ 的极大。 以下两步和2.4节几乎完全一样，除了最后对 $\\alpha$ 的约束条件略有不同。 (1) 求$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta)$:将 $L(W,b,\\xi,\\alpha,\\beta)$ 分别对 $W$、$b$ 和 $\\xi$ 求偏导并令为0可得$$W=\\sum_{i=1}^n \\alpha_i y_i X_i \\tag{3.2.2}$$$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\tag{3.2.3}$$$$C = \\alpha_i + \\beta_i \\tag{3.2.4}$$将上面三个式子代入式 $(3.2.1)$ 并进行类似式 $(2.4.8)$ 的推导即得$$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta) =-\\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ + \\ \\sum_{i=1}^n \\alpha_i \\tag{3.2.5}$$注意其中的 $\\beta$ 被消去了。 (2) 求$\\underset{W, b, \\xi}{min} L(W,b,\\xi,\\alpha,\\beta)$对 $\\alpha$ 的极大：式$(3.2.5)$对$\\alpha$求极大，也等价于式$(3.2.5)$取负数后对$\\alpha$求极小，即$$\\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j X_i^T X_j \\ - \\ \\sum_{i=1}^n \\alpha_i \\tag{3.2.6}$$同时满足约束条件:$$\\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\\\quad 0 \\le \\alpha_i \\le C, i=1,2,…,n. \\tag{3.2.7}$$ 至此，我们得到了原始最优化问题$(3.1.4)$和对偶最优化问题$(3.2.6)$、$(3.2.7)$。 类似2.4节地，假设我们现在通过通用的二次规划求解方法或者SMO算法求得了$(3.2.6)$、$(3.2.7)$的最优解 $\\hat{\\alpha}$，则根据式$(3.2.2)$可求得最优$\\hat{W}$：$$\\hat{W}= \\sum_{i=1}^n \\hat{\\alpha}_i y_i X_i \\tag{3.2.8}$$再根据KKT条件，即$$\\begin{cases}乘子非负: \\alpha_i \\ge 0 ,\\enspace \\beta_i \\ge 0 (i=1,2,…n.下同)\\\\\\\\约束条件: y_i(X_i^TW+b) - 1\\ge \\xi_i \\\\\\\\互补条件: \\alpha_i [y_i(X_i^TW+b) - 1+\\xi_i]=0, \\enspace \\beta_i \\xi_i=0\\end{cases}$$可求得整个软间隔SVM的解，即:$$\\hat{W}= \\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_i \\tag{3.2.9}$$$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i X_j^T X_i\\tag{3.2.10}$$其中 $j$ 需满足 $0 &lt; \\hat{\\alpha}_j &lt; C$ 。 对于任意样本 $(X_i, y_i)$ ， 若 $ \\alpha_i=0$，此样本点不是支持向量，该样本对模型没有任何的作用； 若 $ \\alpha_i&gt;0$，此样本是一个支持向量。 若满足 $ \\alpha_i&gt;0$ ，进一步地， 若 $ 0 &lt; \\alpha_i &lt; C$, 由式 $(3.2.4)$ 得 $\\beta_i = 0$，即刚好 $y_i(X_i^TW+b) =1$，样本恰好在最大间隔边界上； 若 $\\alpha_i = C$，有$\\beta_i &gt; 0$，此时若 $\\beta_i &lt; 1$则该样本落在最大间隔内部，若 $\\beta_i &gt; 1$ 则该样本落在最大间隔内部即被错误分类。 如下图所示。 图3.2 因此，我们有与2.4节相同的结论，最优超平面只与支持向量有关而与非支持向量无关。 3.3 惩罚参数 $C$对于不同惩罚参数 $C$，SVM结果如下图所示。 图3.3 再来看看我们的原始目标函数:$$\\underset{W,b,\\xi}{min} \\quad \\frac 1 2 ||W||^2 + C \\sum_{i=1}^n \\xi_i$$ 对于更加一般化的问题，可将上述式子抽象成：$$\\underset{f}{min} \\quad \\Omega(f) + C \\sum_{i=1}^n l(f(x_i),y_i) \\tag{3.3.1}$$前一项可以理解为“结构风险(structural risk)”，用来描述所求模型的某些性质(SVM就是要求间隔最大)；第二项称为“经验风险(empirical risk)”，用来描述模型与训练数据的契合程度(即误差)。而参数 $C$ 就是用于对二者的折中,即我们一方面要求模型要满足某种性质另一方面又想使模型与训练数据很契合。 从正则化角度来讲， $\\Omega(f)$ 称为正则化项，$C$ 称为惩罚参数，$C$ 越大即对误分类的惩罚越大(要求模型对训练模型更契合)，这可能会存在过拟合；$C$ 越小即相对更加看重正则化项，此时可能存在欠拟合。 4. 非线性SVM——核技巧前面介绍的都是线性问题，但是我们经常会遇到非线性的问题(例如异或问题)，此时就需要用到核技巧(kernel trick)将线性支持向量机推广到非线性支持向量机。需要注意的是，不仅仅是SVM，很多线性模型都可以用核技巧推广到非线性\u001c模型，例如核线性判别分析(KLDA)。 4.1 核函数如下图所示，核技巧的基本思路分为两步: 使用一个变换将原空间的数据映射到新空间(例如更高维甚至无穷维的空间)； 然后在新空间里用线性方法从训练数据中学习得到模型。 图4.1 怎样映射到特征空间？ 先来看看核函数的定义， 设 $\\mathcal{X}$ 是输入空间(欧式空间$R^n$的子集或离散集合)，又设 $\\mathcal{H}$ 是特征空间(希尔伯特空间)，如果存在一个 $\\mathcal{X}$ 到 $\\mathcal{H}$ 的映射$$\\phi(x): \\mathcal{X} \\to \\mathcal{H}$$使得对所有 $x,z \\in \\mathcal{X}$，函数 $K(x,z)$ 满足条件$$K(x,z)=\\phi(x) \\cdot \\phi(z)$$则称 $K(x,z)$ 为核函数， $\\phi(x)$ 为映射函数，式中 $\\phi(x) \\cdot \\phi(z)$ 为 $\\phi(x)$ 和 $\\phi(z)$ 的內积。 通常，直接计算 $K(x,z)$ 比较容易而通过 $\\phi(x)$ 和 $\\phi(z)$ 计算 $K(x,z)$ 并不容易。而幸运的是，在线性支持向量机的对偶问题中，无论是目标函数还是决策函数都只涉及到输入样本与样本之间的內积，因此我们不需要显式地定义映射 $\\phi(x)$ 是什么而只需事先定义核函数 $K(x,z)$ 即可。也就是说，在核函数 $K(x,z)$ 给定的情况下，可以利用解线性问题的方法求解非线性问题的支持向量机，此过程是隐式地在特征空间中进行的。 4.2 正定核由上面的介绍可知，我们只需要定义核函数就可以了。但是如何不通过映射 $\\phi(x)$ 判断给定的一个函数 $K(x,z)$ 是不是核函数呢？或者说，$K(x,z)$ 需要满足什么条件才是一个核函数。 通常所说的核函数就是正定核函数，下面不加证明的给出正定核的充要条件，具体证明略显复杂，有兴趣的可以参考《统计学习方法》。 设 $\\mathcal{X} \\subset R^n$ ,$K(x,z)$ 是定义在 $\\mathcal{X} \\times \\mathcal{X}$ 上的对称函数，如果对任意的 $x_i \\in \\mathcal{X}, i=1,2,…,m$，$K(x,z)$ 对应的Gram矩阵$$K = [K(x_i, x_j)]_{m \\times m}$$是半正定矩阵，则 $K(x,z)$ 是正定核。 虽然有了上述定义，但是实际应用时验证 $K(x,z)$ 是否是正定核依然不容易，因此在实际问题中一般使用已有的核函数，下面给出一些常用的核函数。 多项式核函数(polynomial kernel function)$$K(x,z) = (x \\cdot z + 1)^p \\tag{4.2.1}$$ 高斯核函数(Guassian kernel function)$$K(x,z) = exp(- \\frac {||x-z||^2} {2 \\sigma^2} ) \\tag{4.2.2}$$ 4.3 非线性支持向量机如前4.1、4.2所述，利用核技巧可以很简单地把线性支持向量机扩展到非线性支持向量机，只需将线性支持向量机中的內积换成核函数即可。下面简述非线性支持向量机学习算法。 首先选取适当的核函数 $K(x,z)$ 和适当的参数 $C$，构造最优化问题$$\\begin{aligned}&amp; \\underset{\\alpha}{min} \\quad \\frac 1 2 \\sum_{i=1}^n \\sum_{j=1}^n \\alpha_i \\alpha_j y_i y_j K(X_i,X_j) \\ - \\ \\sum_{i=1}^n \\alpha_i \\\\\\\\&amp; s.t. \\quad \\sum_{i=1}^n \\alpha_i y_i = 0 \\\\\\\\&amp; \\qquad 0 \\le \\alpha_i \\le C, i=1,2,…,n.\\end{aligned} \\tag{4.3.1}$$再利用现成的二次规划问题求解算法或者SMO算法求得最优解 $\\hat{\\alpha}$ 。 选择 $\\hat{\\alpha}$ 的一个满足 $0 &lt; \\hat{\\alpha}_j &lt; C$ 的分量 $\\hat{\\alpha}_j$ ，计算$$\\hat{b} = y_j-\\sum_{i \\in SV} \\hat{\\alpha}_i y_i K(X_j,X_i)\\tag{4.3.2}$$ 构造决策函数：$$f(x)=sign(\\sum_{i \\in SV}\\hat{\\alpha}_i y_i K(X_j,X_i) + \\hat{b}) \\tag{4.3.3}$$ 5. 总结5.1 SVM优缺点任何算法都有其优缺点，支持向量机也不例外。 支持向量机的优点是: 由于SVM是一个凸优化问题，所以求得的解一定是全局最优而不是局部最优。 不仅适用于线性线性问题还适用于非线性问题(用核技巧)。 拥有高维样本空间的数据也能用SVM，这是因为数据集的复杂度只取决于支持向量而不是数据集的维度，这在某种意义上避免了“维数灾难”。 理论基础比较完善(例如神经网络就更像一个黑盒子)。 支持向量机的缺点是: 二次规划问题求解将涉及m阶矩阵的计算(m为样本的个数), 因此SVM不适用于超大数据集。(SMO算法可以缓解这个问题) 只适用于二分类问题。(SVM的推广SVR也适用于回归问题；可以通过多个SVM的组合来解决多分类问题) 5.2 SVM调参经验SVM很适合做分类任务，但是如果刚开始接触SVM而不知道如何进行合理的参数选择的话可能得不到满意的结果。下面简介运用SVM的基本步骤，或者说调参经验。 主要参考:Hsu C W, Chang C C, Lin C J. A practical guide to support vector classification[J]. 2003. 将原始数据转换为SVM算法期待的格\u001c\u001c式； 将数据进行scaling(很重要)； 一般考虑用高斯核RBF(如果特征维度太高，建议直接用线性SVM)； 交叉验证寻找最优的RBF的参数以及参数 $C$ ; 用上面找到的最优参数在整个训练集上训练；","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://tangshusen.me/categories/Machine-Learning/"}],"tags":[{"name":"SVM","slug":"SVM","permalink":"https://tangshusen.me/tags/SVM/"},{"name":"kernel trick","slug":"kernel-trick","permalink":"https://tangshusen.me/tags/kernel-trick/"},{"name":"classification","slug":"classification","permalink":"https://tangshusen.me/tags/classification/"}]}]}